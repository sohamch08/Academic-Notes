\chapter{Fractional Matroid Matching}\label{fractional-matroid-matching}
Fractional Matroid Matchings generalizes the case for Matroid Matching or Matroid Parity problem with allowing fractional solutions for the polytope which we will show below. We start with the same kind of state like Matroid Parity Problem
\section{Fractional Matroid Matchings Polytope}
Let $M=(E,\mcI)$ is a matroid  with ground set $E$ of even cardinality and with elements $E$ is partitioned  into lines or pairs. Let $L$ is the  set of lines.  Let $r:\mcP(E)\to \bbZ$ be the rank function and $sp:\mcP(E)\to \mcP(E)$ be the span function. Assume that $\forall\ l\in L$, $r(L)=2$. With this setting (same as matroid parity problem) we now define the polytope following \cite{VandeVate_1992_Fmm}
\dfn[fracmatmatch]{Fractional Matroid Matching Polytope}{Let $\sL$ denote the lattice of flats  in $M$ wtih  $S_1\wedge S_2=S_1\cap S_2$ and $S_1\vee S_2 = sp(S_1\cup S_2)$  and for each line $l\in L$  let $a_l:\sL\to \{0,1,2\}$ be the function $a_l(S)=r(sp(l)\cap S)$. Now for any $S\in \sL$ and $x\in \bbR^{|L|}_+$ let $a(S)\cdot x$ denote the vector $(a(S)\cdot x)_l=a_l(S)x_l$ for any $l\in L$. Then the set $$FP(M)=\{x\in \bbR^{|L|}_+\mid \colon a(S)\cdot x\leq r(S) \text{ for each }S\in\sL\}$$ is fractional matroid matching polytope for $M$ and each vector $x\in FP(M)$ is called a fractional matroid matching. }
We take $|L|=m$ to imply that originally the ground set has $2m$ elements. Now we can also allow $x$ to be from $\bbR^{m}$, not restricting only to positive vectors. This polytope is a subset of $[0,1]^m$. We will explain the setting wtih the following example:
\begin{example}{}{}
	Consider the matroid $M$ with ground set $$E=\{a_1,a_2,b_1,b_2,c_1,c_2,d_1,d_2\}$$where every 4 element subset of $E$ is a base except these 4 sets \begin{align*}
		\{a_1,a_2,b_1,b_2\}, &  & \{a_1,a_2,c_1,c_2\}, &  & \{a_1,a_2,d_1,d_2\}, \\
		\{b_1,b_2,c_1,c_2\}, &  & \{b_1,b_2,d_1,d_2\}, &  & \{c_1,c_2,d_1,d_2\}
	\end{align*}Now the lines are  defined to be \begin{align*}
		l_1=\{a_1,a_2\} &  & l_2=\{b_1,b_2\}, &  & l_3=\{c_1,c_2\}, &  & l_4=\{d_1,d_2\}
	\end{align*} Now the flats of $M$ are empty set, individual elements, every pair of elements, set consists of one element from each of three lines, pair of line and $E$. Hence $FP(M)$ is the set of $x\in\bbR^{|L|}_+$ satisfying \begin{align*}
		2x_1+2x_2\leq 3 &  & 2x_1+2x_3\leq 3 &  & 2x_1+2x_4\leq 3 \\
		2x_2+2x_3\leq 3 &  & 2x_2+2x_4\leq 3 &  & 2x_3+2x_4\leq 3 \\
		\shortintertext{\centering $2x_1+2x_2+2x_3+2x_4\leq 4$}   \\
		\shortintertext{\centering $2x_i\leq 2\quad \text{for each $i\in[4]$}$}
	\end{align*}
\end{example}
Now the we show the theorem \thrmref{th:fracmatmatch-matparity} which states that the fractional matroid matching polytope arises
as a linear relaxation of the matroid matching problem.
\begin{Theorem}{\cite[Theoerm 2.1]{VandeVate_1992_Fmm}}{fracmatmatch-matparity}
	An integer vector $x\in\bbR^{m}_+$ is the incidence  vector of a matroid matching iff $x$ is a fractional matroid matching.
\end{Theorem}
You can clearly see this theorem by comparing the Matroid Matching Polytope and Fractional Matroid Matching Polytope so we are omitting the proof.
\begin{Theorem}{\cite[Theorem 1]{GijswijtPap_2013_Aaf}}{weighted-fracmatmatch}
	The vertices of the fractional matroid matching are half-integral
\end{Theorem}
\subsection{Weighted Fractional Matroid Matching}
\dfn{Weighted Fractional Matroid Matching Problem}{It is to find a fractional matroid matching $x$ that maximizes $w\cdot x$ for a non-negative weight assignment $w:L\to \bbZ_+$.\parinn

	For plain Fractional Linear Matroid Matching Problem we need to find a fractional matroid matching $x$ which maximizes the size i.e. $L_1$ norm of $x$ which is  $\sum\limits_{l\in L}|x_l|$.}
Gijswijt and Pap in \cite{GijswijtPap_2013_Aaf} gave a polynomial time algorithm for weighted fractional linear matroid matching. They also gave the following characterization for maximizing face of the polytope with respect to a weight function.
\begin{Theorem}{\cite[Prood of Theorem 1]{GijswijtPap_2013_Aaf}}{fracmatmatch-matrixcharac}
	Let $L=\{l_1,\dots, l_m\}$ be a set of lines with $l_i\subseteq \bbF^n$ and $w:L\to \bbZ$ be a weight assignment on $L$. Let $F$ denote the set of fractional linear matroid matchings maximizing and $S\subseteq [m]$ such that every $x\in F$ has $y_e=0$ for all $e\in S$. Then for some $k\leq n$, $\exs$ a $k\times m$ matrix $D_F$ and $b_F\in \bbZ^k$ such that \begin{itemize}
		\item $D_F\in\{0,1,2\}^{k\times m}$
		\item The sum of entries in any column of $D_F$ is exactly 2
		\item A fractional matroid matching $x$ is in $F$ iff $y_e=0$ for $e\in S$ and $D_Fx=b_F$.
	\end{itemize}
\end{Theorem}
\section{Isolating Weight Assignment for Fractional Matroid Matching}
In this section we will describe how we can construct an isolating weight assignment for fractional matroid matching with just the number of lines as input.

Now for a face $F$ of a polytope, let $\mcL_F$ denote the lattice $$\mcL_F=\{v\in\bbZ^{m}\mid v=\alpha(x_1-x_2)\text{  for some $x_1,x_2\in F$ and $\alpha\in\bbR$}\}$$and $\lm(\mcL_F)$ denote the length of the shortest vector of $\mcL_F$. Hence $\mcL_F$ consistes of all integral vectors parallel to the face $F$.

Now by \thrmref{th:fracmatmatch-matrixcharac} the face maximizing the size is described by the equation $D_Fx=b_F$ where $D_F\in \{0,1,2\}^{k\times m}$ with column sum 2. Hence $\mcL_F$ is exactly the set of integral vectors in the null space of $D_F$. Therefore $$\mcL_F=\{v\in\bbZ^{m}\mid D_Fv=0\}$$So we will prove that the number of vectors in $\mcL_F$ with size less than twice the length of shortest vector is polynomially bounded in Subsection 1.2.2.

First we will show how we can interpret $D_F$ an incidence matrix for a graph instead of general matrix. $D_F\in \{0,1,2\}^{k\times m}$ where every column sum is 2. Hence we can thing of a graph $G_D$ with vertex set $[k]$ and the $m$ edges defined as follows: for every $e\in [m]$ the $e$-th edge of $G_D$ is drawn between the vertices $s,t\in[k]$ if $D_F[s,e]=D_F[t,e]=1$ and $e$-th edge is a self look on the vertex $s\in[k]$ if $D_F[s,e]=2$.
\subsection{Alternating Circuits}
First we will define some elements called alternating indicator vetors and alternating circuits following the \cite{SvenssonTarnawski_2017_TMP_CONF} for the proof of \thrmref{th:latticevector-polybounded}.
\dfn[altcircuit]{Alternating Indicator Vector \& Alternating Circuit}{Let $C=v_0\xrightarrow{e_0}v_1\xrightarrow{e_1}v_2\cdots \xrightarrow{e_{k-2}}v_{k-1}\xrightarrow{e_{k-1}}v_0$ be a closed walk of even length in a multigraph $G$ with loops. Then the \textit{Alternating Indicator Vector} of $C$ denoted by $(\pm \mathbbm{1})_C$ is the vector $$(\pm \mathbbm{1})_C\coloneqq \sum_{i=0}^{k-1}(-1)^i\mathbbm{1}_{e_i}$$

$C$ is called \textit{Altenating Circuit} if its alternating indicator vector is nonzero}
We can use the parity for $(-1)^{i}$ as direction of movement in $C$. So a closed walk $C$ is a alternating circuti if there exists at least one edge $e\in C$ for which $C$ has moved through $e$ more time in one direction than the other.
\begin{observation*}
	$|(\pm \mathbbm{1})_C|\leq |C|$ for any even length closed walk $C$.
\end{observation*}


Now we will prove a property for all alternating circuits in $G_D$
\begin{lemma}{\cite[Proof of Claim 1, Proof of Theorem 3.4]{GurjarOkiRaj_2024_Flm}}{altcircuit-in-lattice}
	For any alternating circuit $C$ we have $D_F\cdot (\pm \mathbbm{1})_C=0$
\end{lemma}
\begin{proof}
	Suppose $C=v_0\xrightarrow{e_0}v_1\xrightarrow{e_1}v_2\cdots \xrightarrow{e_{k-2}}v_{k-1}\xrightarrow{e_{k-1}}v_0$. We denote the $i$-th column of $D_F$ is denoted by $D_i$. Now $$D_i\cdot (\pm \mathbb{1})_C=\sum_{j=0}^{k-1}(-1)^jD_F[i,e_j]=\sum_{e_j: i\in e_j\in C}(-1)^j D_F[i,e_j]$$Hence only the edges in $C$ which are incident on $i$ contributes to the above sum. Therefore the whole sum is partitioned into distinct subparts of walks where each subpart is of the form $$v_s\xrightarrow{e_s}\underbrace{i \xrightarrow{e_{s+1}}i\xrightarrow{e_{s+2}}\cdots \xrightarrow{e_{s+k-1}}i}_{k\text{ times}}\xrightarrow{e_{s+k}}v_t\qquad \text{where $v_s,v_t\neq i$}$$i.e. the part starts from a vertex not equal to $i$ then goes to $i$ and after looping in $i$ for some times the walk goes to another vertex not equal to $i$. We will show that for each of these parts the contribution to the sum is 0.

	Now for such a subpart their contribution to the sum is $$\delta=(-1)^s+2\sum_{j=1}^{k-1}(-1)^{s+i}+(-1)^{s+k}$$ We will analyze case wise:\parinf

	\textbf{Case 1: $k$ is odd:} Then $k-1$ is even. Hence $$\sum_{j=1}^{k-1}(-1)^{s+i}=(-1)^s\sum_{j=1}^{k-1}(-1)^{i}=0$$Therefore $$\delta=(-1)^s+(-1)^{s+k}=(-1)^s[1+(-1)^k]=0$$ as $k$ is odd.

	\textbf{Case 2: $k$ is even:} Then $k-2$ is even. Hence $$\sum_{j=1}^{k-1}(-1)^{s+i}=\lt[\sum_{j=1}^{k-2}(-1)^{s+i}\rt]+(-1)^{s+k-1}=(-1)^{s+k-1}$$Hence $$\delta=(-1)^s+2(-1)^{s+k-1}+(-1)^{s+k}=(-1)^s[1+2(-1)^{k-1}+(-1)^k]=0$$\parinn

	Therefore we showed that for each such parts their contribution to the sum is 0. Therefore the total sum is 0 i.e. $D_i\cdot (\pm\mathbbm{1})_C=0$. Since this is true for all $i\in[k]$ we have $D_F\cdot (\pm \mathbbm{1})_C=0$.
\end{proof}
Now we will show that any vector in the lattice $\mcL_F$ can be decomposed into finite sum of alternating indicator vectors of alternating circuits with the property that for each such alternating circuit $C$, $|(\pm \mathbbm{1})_C|=|C|$. Before that we introduce a relation between two vectors in $\bbR^m$ this will come in handy for the decomposition.

\dfn[conformal]{Conformal}{For $x,y\in \bbR^m$, $x$ is said to be conformal to $y$ if $x_iy_i\geq 0$ and $|x_i|\leq |y_i|$ $\forall \ i\in[m]$ and it is denoted by $x\sqsubseteq y$}


\begin{lemma}{\cite[Claim 1, Proof of Theorem 3.4]{GurjarOkiRaj_2024_Flm}}{latiice-vector-decomposition}
	For any $x\in\mcL_F$, $\exs$ alternating circuits $C_1,C_2,\dots, C_t$ in $G_D$ such that $$x=\sum_{i=1}^t(\pm \mathbbm{1})_{C_i}$$where $\forall\ i\in[t]$, $(\pm \mathbbm{1})_{C_i}\sqsubseteq x$ and $|(\pm\mathbbm{1})_{C_i}|=|C_i|$.
\end{lemma}
\begin{proof}
	We will decompose a given $x$ into alternating indicator vectors by the following iterative algorithm:


	\begin{algorithm}[H]
		\KwIn{$x\in \mcL_F$}
		\KwOut{$\mcY=\{y_i\}$ where $|\mcY|<\infty$ and $\forall \ y_i\in \mcY$ are alternating indicator vectors}
		\DontPrintSemicolon
		\Begin{
			\While{$|x|\neq 0$}{
				$y\longleftarrow 0$, $j\longleftarrow 1$\;
				Let $e_0\in[m]$ such that $x_{e_0}>0$\;
				$y_{e_0}\longleftarrow 1$ and let $e_0$-th edge in $G_D$ be $\{v_0,v_1\}$\;
				\While{True}{
					\If{$\exs\ e\in[m]$ such that $e$-th edge is $\{v_j,u\}$, $|x_e|>|y_e|$ and $(-1)^jx_e>0$}{
						$y_e\longleftarrow y_e+(-1)^j$, $e_j\longleftarrow e$\;
						$v_{j+1}\longleftarrow u$\;
						$j\longleftarrow j+1$\;
					}
					\Else{\Return{$x\notin \mcL_F$}}
					\If{$j\equiv 0\pmod 2$ and $v_j=v_0$}{$x\longleftarrow x-y$\;
						\Return{$y$} and exit inner while loop}
				}
			}
		}
		\caption{Decomposition of a Lattice Vector}
	\end{algorithm}
	Now suppose $x$ denote the vector at some iteration of the outer while loop. Now forall $e\in[m]$, let at $j$th and $l$th iteration of the inner while loop $(-1)^j$ and $(-1)^l$ are added to $y_e$ respectively. Now both $j$ and $l$ has same parity because since the edge is not changing both times $(-1)^jx_e>0$ and $(-1)^lx_e>0$ has to be satisfies. Therefore we get $j$ and $l$ have same parity. Hence for a full run of the inner while loop for any $e\in[m]$ everytime $y_e$ is changed the same $(-1)^j$ is added. Hence whenever $y_e$ is changed $|y_e|$ is increased. Therefore $|y|$ increases for each iteration of the inner while loop. But $|y|$ cannot exceed $|x|$ since as the addition step works when $\exs \ e\in[m]$ with $|x_e|>|y_e|$ and $(-1)^jx_e>0$, after addition $|y_e+(-1)^j|\leq |y_e|+1\leq |x|$. So if we start with $|y|\leq |x|$ after addition with each iteration of inner while loop we still have $|y|\leq |x|$.  Also since for every such edge we add $(-1)^j$ to $y_e$ when $(-1)^jx_e>0$ and $|x_e|>|y_e|$. So by the first condition we have $y_e$ and $x_e$ has the same sign i.e. $x_ey_e>0$. And we also have $|x_e|\geq |y_e|$. Therefore we have $y\sqsubseteq x$.

	Now since we start the algorithm by adding 1 to $y_{e_0}$ at Line 5 we have initially $|y|>0$ and afterwards with each iteration of the inner while loop $|y|$ increases so we have $|y|>0$.Now if the current iteration of the inner while loop ends at Line 13 then we get a closed walk $C$ since in each iteration of the inner while loop the algorithm follows a walk in $G_D$. So $C$ is an alternating circuit and  we have $|y|=|C|$. Now since $y\sqsubseteq x$ we have $|x-y|=|x|-|y|<|x|$. Since $C$ is alternating circuit by \lemref{th:altcircuit-in-lattice} we have $y\in \mcL_F$. Hence we have $x-y\in\mcL_F$.

	Now all that remains is to show that the algorithm never goes to Line 11 if $x\in\mcL_F$. The only reason the algorithm can go to Line 11 if at some iteration of the inner while loop can not find an edge $e\in [m]$ such that $|x_e|>|y_e|$ and $(-1)^jx_e>0$ where $e\in \delta(v_j)$ where $\delta(v_j)$ denotes te set of edges incident on $v_j$. Suppose at this point we have the walk $$\mcP=v_0\xrightarrow{e_0}v_1\xrightarrow{e_1}\cdots \xrightarrow{e_{j-1}}v_j$$Now by following the proof of \lemref{th:altcircuit-in-lattice} we have that $D_iy=0$ forall $i\in[k]$ except $i\notin \{v_0.v_j\}$.\parinf \vspace*{5mm}

	\textbf{\textit{Claim:}} If $j$ is odd then $D_{v_j}y>0$ and if $j$ is even then $D_{v_j}y<0$.

	\begin{proof} We will prove the case for $j$ is odd. The even case will follow similarly. Since $j$ is odd we have $j-1$ even. Therefore $x_{e_{j-1}}>0$ as $(-1)^{j-1}x_{e_{j-1}}>0$. Therefore for both $e_0$ and $e_{j-1}$, $x_{e_0},x_{e_{j-1}}$ positive. Now take the partitions as described in the proof of \lemref{th:altcircuit-in-lattice}. Now we analyze case wise:\parinf

		\textbf{Case 1: $v_0\neq v_j$:} Then only the partition containing $v_{e_j}$ might contribute something nonzero because other partitions contributes 0 to the sum $D_{v_j}y$. Let the partition be $$v_s\xrightarrow{e_{j-k-1}}\underbrace{v_j \xrightarrow{e_{j-k}}v_j\xrightarrow{e_{j-k+1}}\cdots \xrightarrow{e_{j-1}}v_j}_{k+1\text{ times}}\qquad \text{where $v_s\neq v_{j}$}$$Now $k$ can not be more than 1 since if $e_{j-1}$ and $e_{j-2}$ are both loops in $v_j$ then for $e_{j-1}$, $x_{e_{j-1}}>0$ but $x_{e_{j-2}}<0$ but  $e_{j-1}=e_{j-2}\implies 0<x_{e_{j-1}}=x_{e_{j-2}}<0$. Then this partition contributes $\delta=(-1)^{j-2}+2(-1)^{j-1}=-1+2>0$ to $D_{v_j}y$ if there is a loop and if there is no loop then it also contributes 1 as then the contribution will be only $(-1)^{j-1}=1>0$.

		\textbf{Case 2: $v_0=v_j$:} If $v_0$ and $v_j$ is in same partition i.e. $j=1$ then the it contributes $(-1)^0=1>0$ to the sum. Otherwise $v_0$ is in different partition. By the above case we know that the value contributed by the partition containing $v_j$ is 1. So we have to only find the contribution by the partition containing $v_0$. Again by same logic as the above case from $v_0$ at most one loop starting from $v_0$ and then it moves to some other vertex. Hence the sum contributed is $2(-1)^0+(-1)^1=2-1=1$ if there is a loop and if there is no loop then it contributes $(-1)^0=1$. Hence in both cases the contribution of the partition containing $v_0$ to the sum $D_{v_j}y$ is 1. Hence we have $D_{v_j}y>0$.\parinn

		Hence by above we get that if $j$ is odd then the value $D_{v_j}y>0$. Similarly following the same process in the case of $j$ is even we get $D_{v_j}y<0$.\end{proof}

	\vspace*{5mm}

	Hence by the lemma we have that if $j$ is odd $D_{v_j}y>0$ and if $j$ is even then $D_{v_j}y<0$. So WLOG suppose $j$ is odd. Now define $$\supp^+(x)=\{i\in [m]\mid x_i>0\}\qquad \text{and}\qquad \supp^-(x)=\{i\in[m]\mid x_i<0\}$$Then we have \begin{align*}
		0=D_{v_j}x & = \sum_{e\in \supp^+(x)\cap \dl(v_j)} D_F[v_j,e]\cdot |x_e| -\sum_{e\in \supp^-(x)\cap \dl(v_j)}D_F[v_j,e]\cdot|x_e| \\
		0<D_{v_j}y & = \sum_{e\in \supp^+(x)\cap \dl(v_j)} D_F[v_j,e]\cdot |y_e| -\sum_{e\in \supp^-(x)\cap \dl(v_j)}D_F[v_j,e]\cdot|y_e|
	\end{align*}
	Now be construction of $y$ we have $y\sqsubseteq x\implies |x_e|\geq |y_e|, x_ey_e>0\forall\ e\in[m]$. The algorithm stopped at Line 13 since $\not\exs\ e\in \dl(v_j)$ such that $|x_e|>|y_e|$ and $(-1)^jx_e=-x_e>0$. Therefore $|x_e|=|y_e| $ for all $e\in \supp^+(x)\cap \dl(v_j)$ otherwise the algorithm would have proceeded one more step and $\supp^-(x)\cap\dl(v_j)=\supp^-(y)\cap \dl(v_j)$ since for any $e\in[m]$, $x_ey_e>0$. Therefore $\supp^+(x)\cap \dl(v_j)=\supp^+(y)\cap \dl(v_j)$. Now for all $e\in \supp^+(x)\cap \dl(v_j)$ we have $|x_e|\geq |y_e|$. Hence we have $$0=D_{v_j}y\geq D_{v_j}y>0$$It is a contradiction. Hence if $x\in \mcL_F$ the algorithm never goes to Line 13. And therefore the algorithm successfully decomposes $x$ into sum of alternating circuits.
\end{proof}

\subsection{Bounding vectors in \texorpdfstring{$\mcL_F$}{Lf} with Small Size}
\begin{Theorem}{\cite{GurjarOkiRaj_2024_Flm}}{latticevector-polybounded}
	Let $D\in \{0,1,2\}^{pimes m}$ be a matrix such that the sum of entries of each column equals 2. Let $\mcL_D$ denote the lattice $\{v\in\bbZ^m\mid Dv=0\}$. Then it holds that $$|\{v\in \mcL_D\mid |v|<2\lm(\mcL_D)\}|\leq m^{O(1)}$$
\end{Theorem}
\begin{proof}
	For the given $D$ consider the graph $G_D$ obtained from $D$ as explained at the start of Section 1.2. to show that the number of  vectors in $\mcL_D$ with size less than twice the size of shortest vector in $\mcL_D$ we will show that for any such lattice vector there is only one alternating circuit in the decomposition of the vector in \lemref{th:latiice-vector-decomposition}.\parinf\vspace*{5mm}

	\textbf{\textit{Claim:}} Any lattice vector $x\in \mcL_D$ with $|x|<2\lm(\mcL_D)$ is an alternating vector $(\pm\mathbbm{1})_C$ of some alternating circuit $C$ in $G_D$ such that $|x|=|C|$

	\begin{proof}
		Suppose the contrary. Since $x\in \mcL_D$ by \lemref{th:latiice-vector-decomposition} $\exs\ C_1,\dots, C_t$ with $t\geq 2$ such that $x=\sum\limits_{i=1}^t (\pm\mathbbm{1})_C$ with $(\pm \mathbbm{1})_C\sqsubseteq x$ and $|(\pm \mathbbm{1})_{C_i}|=|C_i|$ for all $i\in[t]$. Then we have $$|x|=\sum_{i=1}^t|(\pm \mathbbm{1})_{C_i}|\geq t\lm(\mcL_D)\geq 2\lm(\mcL_D)$$which is a contradiction since we assumed that $|x|<2\lm(\mcL_D)$. Hence $t=1$ i.e. $x=(\pm\mathbbm{1})_C$ for some alternating circuit $C$ with $|x|=|C|$.
	\end{proof}
	\vspace*{5mm}

	Hence the Claim implies that $\lm(\mcL_D)$ is equal to the size of the smallest alternating circuit of $G_D$. And it also implies that we only need to bound the number of alternating indicator vectors that correspond to alternating circuit of size at most $2\lm(\mcL_D)$ to prove the lemma. For that by the \thrmref{th:ola-altcircuitn17} we get that the number of such alternating indicator vectors are polynomially bounded by $m$.
\end{proof}

In the following theorem I have modified the proof of the theorem since we are not working the general setting like in \cite{SvenssonTarnawski_2017_TMP_CONF}. We are basically taking node-weight for every vertex to be 1.
\begin{Theorem}{\cite[Lemma 5.4]{SvenssonTarnawski_2017_TMP_CONF}}{ola-altcircuitn17}
	Let $G$ be a graph on $n$ vertices such that the size of the smallest alternating circuit $\lm$. Then the cardinality of the set $$\{(\pm \mathbbm{1})_C\mid C\text{ is an alternating circuit in $G$ of size at most $2\lm$}\}$$is at most $n^{17}$.
\end{Theorem}
\begin{proof}
	Like in the proof of \lemref{th:twice-size-cycles-arepolynomially-bounded} we will associate a small signature $\sg(C)$ with each alternating circuit $C$ in $G$ of size at most $2\lm$. The signatures have the property that alternating circuits with different alternating indicator vectors are assigned to different signatures. This will prove that the number of alternating circuits in $G$ of size at most $2\lm$ is  at most the number of possible signatures which we will show polynomially bounded.

	So let $$C=v_0\overset{e_0}{\longrightarrow} v_1\overset{e-1}{\longrightarrow}\cdots \overset{e_{k-2}}{\longrightarrow}v_{k-1}\overset{e_{k-1}}{\longrightarrow}v_0$$be an alternating circuit in $G$ of size at most $2\lm$. Now for $v_i\in C$ define $$ in(v_i)\coloneqq \text{Incoming edge of $v_i$}\qquad out(v_i)\coloneqq\text{Ourgoing edge og $v_i$}$$Now we define the signature $\sg(C)$:\begin{itemize}
		\item Let $i_0=0$ be the first vertex in $C$.
		\item For $j\in [3]$, select $i_j=\left\lceil \frac{j\lm}{4} \right\rceil $. Hence $\sum\limits_{l=i_{j-1}+1}^{i_j-1}1\leq \frac{\lm}2$.
		\item Take $t=\max\{j\mid i_j<k\}$. Output $$\sg(C)=\lt( (-1)^{i_j},in(v_{i_j}), out(v_{i_j}) \rt)_{j\in \{0,1,\dots,t\}}$$
	\end{itemize}
	\nt{We are considering $t$ as an important index because size of $C$ can be small so that $k<i_3<2k$ then to define $i_3$ properly we basically take $v_{i_j}=v_{i_j\bmod k}$.  In that case the index which is still less than $k$ helps us to consider the cycle as joining of $t$ different paths. Also this case can only happen to $i_3$ since $C$ has length at least $\lm$ so both $i_1$ and $i_2$ are same after modulo $k$.}
	The indices $i_0,i_1,\dots,i_t$ partition $C$ into paths:
	\begin{align*}
		 & C_0= v_{i_0}\overset{e_{i_0}}{\longrightarrow}v_{i_0+1}\overset{e_{i_0+1}}{\longrightarrow} \cdots \overset{e_{i_1-1}}{\longrightarrow}v_{i_1} \\
		 & C_1= v_{i_1}\overset{e_{i_1}}{\longrightarrow}v_{i_1+1}\overset{e_{i_1+1}}{\longrightarrow} \cdots \overset{e_{i_2-1}}{\longrightarrow}v_{i_2} \\
		 & C_2= v_{i_2}\overset{e_{i_2}}{\longrightarrow}v_{i_2+1}\overset{e_{i_2+1}}{\longrightarrow} \cdots \overset{e_{i_3-1}}{\longrightarrow}v_{i_3} \\
		 & \qquad\qquad\qquad\qquad\vdots                                                                                                                 \\
		 & C_t= v_{i_t}\overset{e_{i_t}}{\longrightarrow}v_{i_t+1}\overset{e_{i_t+1}}{\longrightarrow} \cdots \overset{e_{i_0-1}}{\longrightarrow}v_{i_0} \\
	\end{align*}So the node-weight of internal vertices for each path is $C_i$ for $i\in \{0,1,\dots,t-1\}$ is at most $ \frac{\lm}2$.Therefore by the maximality of $t$ we have:
	$$\underbrace{\sum\limits_{l=i_0+1}^{i_1}1}_{\geq \frac{\lm}{2}} + \underbrace{\sum\limits_{l=i_1+1}^{i_2}1}_{\geq \frac{\lm}{2}} + \cdots + \underbrace{\sum\limits_{l=i_{t-1+1}^{i_t}1}}_{\geq \frac{\lm}{2}}1$$Each sum is at least $\frac{lm}{2}$ so we have the total node-weight of internal vertices of $C_t$ is at most $\frac{\lm}2$.

	Now we will count the number of possible signatures. For each $j\in \{0,1,\dots,t\}$ in the tuple $\lt( (-1)^{i_j},in(v_{i_j}), out(v_{i_j}) \rt)$ there are 2 possible parity of $i_j$ and both $in(v_{i_j})$ and $out(v_{i_j})$ has at most $n^2$ choices. So for each $j$ there are $2n^4$ many possible tuples. Therefore:
	\begin{center}
		\begin{tabular}{l}
			For  $t=0$ there are  $2n^4$ many signatures     \\
			For  $t=1$ there are  $(2n^4)^2$ many signatures \\
			For  $t=2$ there are  $(2n^4)^3$ many signatures \\
			For  $t=3$ there are  $(2n^4)^4$ many signatures
		\end{tabular}
	\end{center}
	Hence total number of possible signatures is $2n^4+(2n^4)^2+(2n^4)^3+(2n^4)^4<n^{17}$. So number of signatures is polynomially bounded. Now we will show that any 2 alternating circuits $C,D$ of size at most $2\lm$ have different signatures i.e.$$\sg(C)\neq \sg(D)\iff (\pm\mathbbm{1})_C\neq (\pm\mathbbm{1})_D$$\parinf \vspace*{2mm}

	\textbf{\textit{Claim:} } $C$ is the only alternating circuit $C$ of size at most $2\lm$ that is associated to the signature $\sg(C)$.

	\begin{proof}
		So let $C,D$ are two alternating circuits of size at most $2\lm$ and $\sg(C)=\sg(D)$. As described above $C$ is partitioned into paths $C_0,\dots, C_t$ using $i_0,\dots, i_t$ and similarly $D$ is also partitioned into $D_0,\dots, D_t$ using $j_0,\dots, j_t$. Since $\sg(C)=\sg(D)$, $i_k$ and $j_k$ have same parity for all $k\in\{0,1,\dots, t \}$. and since $in(v_{i_k})=in(v_{j_k})$ and $out(v_{i_k})=out(v_{j_k})$ we have $v_{i_k}=v_{j_k}$ for all $k\in \{0,1,\dots, t\}$. Now let $b_k$ denote the parity of $k$th tuple in $\sg(C)$ i.e. $b_k=(-1)^{i_k}=(-1)^{j_k}$. Then we have \[
			(\pm\mathbbm{1} )_C=\sum\limits_{k=0}^{t} b_k(\pm\mathbbm{1} )_{C_k}\qquad (\pm\mathbbm{1} )_D=\sum\limits_{k=0}^{t } b_k(\pm\mathbbm{1} )_{D_k }
		\]Since we know $(\pm\mathbbm{1} )_{C}\neq (\pm \mathbbm{1} )_D$, $\exs\ k\in \{0,1,\dots, t\}	$ such that $(\pm\mathbbm{1} )_{C_k}\neq (\pm\mathbbm{1} )_{D_k}$Now basically we will glue $C_k$ and $D_k$ togather. Now \begin{align*}
			C_k = \underset{\substack{\parallel \\ v_{j_k}}}{v_{i_k}}  = a\to b\to \cdots \to c\to d=\underset{\substack{\parallel \\ v_{j_{k+1\bmod t}}}}{v_{i_{k+1\bmod t}}}
		\end{align*}
		Hence the path $C_k$ and $D_k$ differs in between the path $b\rightsquigarrow c$. Let $P_C$ denotes the path from $b$ to $c$ following $C_k$ and $P_D$ denotes the path from $b$ to $c$ following $D_k$. As $(-1)^{i_k}=(-1)^{j_k}$ and $(-1)^{i_{k+1\bmod t}}=(-1)^{j_{k+1\bmod t}}$. Therefore we have \[
			|C_k|+|D_k|\equiv 0\bmod 2\implies |P_C|+|P_D|\equiv 0\bmod 2
		\]
		So denote the cycle $\mathcal{C}$ to be the closed walk: $$b\overset{f_1}{\longrightarrow} \cdots \overset{f_{|P_C|}}{\longrightarrow} c\overset{g_1}{\longrightarrow} \cdots \overset{g_{|P_D|}}{\longrightarrow} b$$ Where $f_1,\dots, f_{|P_C|}$ are the edges of the path $P_C$ and $g_1,\dots, g_{|P_D|}$ are the edges of the path $P_D$ in reverse. Hence length of the cycle $\mathcal{C } $ is $$|P_C|+|P_D|=|C_k|-2+|D_k|-2<\frac{\lm}2+\frac{\lm}2=\lm$$Therefore if $B$ is an alternating circuit then we have an alternating circuit $(\pm\mathbbm{1}  )_{\mathcal{C} }$ of size less than $\lm$, which is not possible.
	
		Hence all that is left is showing that $(\pm\mathbbm{1}  )_{\mathcal{C} }$ is indeed an alternating circuit i.e. $(\pm\mathbbm{1} )_{\mathcal{C} }\neq 0$. Now:
		\begin{align*}
			-(\pm\mathbbm{1} )_{\mathcal{C} } & = \sum\limits_{i=1}^{|P_C|} (-1)^i\mathbbm{1} _{f_i}+\sum\limits_{i=1}^{|P_D|} (-1)^{|P_C|+i}\mathbbm{1} _{g_i}\\
						                                                                                                                                                     &=\underbrace{\left[ (-1)^0\mathbbm{1} _{out(a)}+\sum\limits_{i=1}^{|P_C|} (-1)^i\mathbbm{1} _{f_i} + (-1)^{|P_C|+1}\mathbbm{1} _{in(d)}\right]}_{=(\pm \mathbbm{1} )_{C_k}}\\ 
																																											 &\qquad\qquad\qquad\qquad -\underbrace{\left[(-1)^{|P_C|+1}\mathbbm{1} _{in(d)}+\sum\limits_{i=1}^{|P_D|} (-1)^{|P_C|+i+2}\mathbbm{1} _{g_i}+(-1)^{{|P_C|+|P_D|}+3}\mathbbm{1} _{out(a)}\right]}_{=-(\pm \mathbbm{1} )_{D_k}}
		\end{align*}
	
		Therefore we have $(\pm \mathbbm{1} )_{\mathcal{C} }=(\pm\mathbbm{1} )_{D_k}-(\pm \mathbbm{1} )_{C_k}\neq 0$. Therefore we have $(\pm \mathbbm{1} )_{\mathcal{C} }$ is an alternating circuit. This leads to a contradiction
	\end{proof}

So there aren't two different alternating circuits of size at most $2\lm$ with same signatures. Therefore number of alternating circuits in $G$ of size at most $2\lm$ is bounded by number of signatures which is at most $n^{17}$.
\end{proof}
\subsection{Algorithm for Finding Isolating Weight Assignment}
With this theorem we have \begin{Theorem}{\cite[Theorem 2.5]{GurjarThieraufVishnoi_2021_IaV}}{}
	Let $k$ be a positive integer and $P\subseteq \bbR^{m}$ a polytope such that its extreme ppoints are in $\lt\{0,\frac1k,\frac2k,\dots,1\rt\}^m$ and there exists a constant $c>1$ with $$|\{v\in \mcL_F\colon |v|<c\lm(\mcL_F)\}|\leq m^{O(1)}$$ for any face $F$ of $P$. Then there exists an algorithm that, given $k$ and $m$, outputs a set $\mcW\subseteq \bbZ^m$ of $m^{O(\log km)}$ weight assignments with weights bounded by $m^{O(\log km)}$ such that there exists at least one $w\in \mcW$ that is isolating for $P$, in time $polylog(km)$ using $m^{O(\log km)}$ many parallel processors.
\end{Theorem}


Using this we finally have an algorithm for isolating a fractional matroid matching polytope:
\begin{Theorem}{\cite[Theorem 3.1]{GurjarOkiRaj_2024_Flm}}{}
	There exists an algorithm that given $m\in \bbZ_+$ outputs a set $\mcW\subseteq \bbZ^m_+$ of $m^{O(\log m)}$ weight assignments with weights bounded by $m^{O(\log m)}$ such that, for any fractional matroid matching polytope $P$ of $m$ lines, there exists at least one $w\in \mcW$ that is isolating for $P$, in time $polylog(m)$ usign $m^{O(\log m)}$ many parallel processors.
\end{Theorem}
