\documentclass[a4paper, 11pt]{article}
\usepackage{comment} % enables the use of multi-line comments (\ifx \fi) 
\usepackage{fullpage} % changes the margin
\usepackage[a4paper, total={7in, 10in}]{geometry}
\usepackage{amsmath,mathtools,mathdots}
\usepackage{amssymb,amsthm}  % assumes amsmath package installed
\usepackage{float}
\usepackage{xcolor}
\usepackage{mdframed,stmaryrd}
\usepackage[shortlabels]{enumitem}
\usepackage{indentfirst}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=black,
	citecolor=myr,
	filecolor=myr,      
	urlcolor=black,
	pdftitle={Assignment}, %%%%%%%%%%%%%%%%   WRITE ASSIGNMENT PDF NAME  %%%%%%%%%%%%%%%%%%%%
}
\usepackage[most,many,breakable]{tcolorbox}
\usepackage{tikz}
\usepackage{caption}
%\usepackage{kpfonts}
%\usepackage{libertine}
\usepackage{physics}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{mathrsfs}
\usepackage{tikz-cd}
\usepackage{float}

\definecolor{mytheorembg}{HTML}{F2F2F9}
\definecolor{mytheoremfr}{HTML}{00007B}
\definecolor{doc}{RGB}{0,60,110}
\definecolor{myg}{RGB}{56, 140, 70}
\definecolor{myb}{RGB}{45, 111, 177}
\definecolor{myr}{RGB}{199, 68, 64}

\usetikzlibrary{decorations.pathreplacing,angles,quotes,patterns}
\definecolor{mytheorembg}{HTML}{F2F2F9}
\definecolor{mytheoremfr}{HTML}{00007B}
\definecolor{doc}{RGB}{0,60,110}
\definecolor{myg}{RGB}{56, 140, 70}
\definecolor{myb}{RGB}{45, 111, 177}
\definecolor{myr}{RGB}{199, 68, 64}

\tcbuselibrary{theorems,skins,hooks}
\newtcbtheorem{problem}{Problem}
{%
	enhanced,
	breakable,
	colback = white,
	frame hidden,
	boxrule = 0sp,
	borderline west = {2pt}{0pt}{black},
	arc=5pt,
	detach title,
	before upper = \tcbtitle\par\smallskip,
	coltitle = black,
	fonttitle = \bfseries,
	description font = \mdseries,
	separator sign none,
	segmentation style={solid, mytheoremfr},
}
{p}

\newtheorem{lemma}{Lemma}
\newtheorem*{definition*}{Definition}
\renewenvironment{proof}{\noindent{\it \textbf{Proof:}}\hspace*{1em}}{\hfill $\blacksquare$\bigskip\\}
% To give references for any problem use like this
% suppose the problem number is p3 then 2 options either 
% \hyperref[p:p3]{<text you want to use to hyperlink> \ref{p:p3}}
%                  or directly 
%                   \ref{p:p3}



\input{../../letterfonts}

\input{../../macros}

\setlength{\parindent}{0pt}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	{\noindent \large\textbf{Soham Chatterjee} \hfill \textbf{Assignment - 1}\\
		Email: \href{soham.chatterjee@tifr.res.in}{soham.chatterjee@tifr.res.in} \hfill Dept: STCS\\
		\normalsize Course: Mathematical Foundations for Computer Sciences \hfill Date: \today}
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
\begin{problem}{%problem statement
	}{p1% problem reference text
}
Let $n=17$ and consider an $n \times n$ grid of switches. A configuration of these switches can be represented by a matrix in $\{\mathrm{OFF}, \mathrm{ON}\}^{n \times n}$. Such a configuration can be modified by flipping any switch and its up to four adjacent switches (e.g., the you can flip the corner $(1,1)$ and the adjacent switches $(1,2)$ and $(2,1))$. Show that there are configurations for which no sequence of modifications will lead the configuration where every switch is $\mathrm{OFF}$. (Open ended) What can you say about other values of $n$?

Hint: This question can be solved with linear algebra.

\end{problem}
\solve{	Since we are doing a switch $\mathrm{ON}$ and $\mathrm{OFF}$ operation we can think we are
	 basically working in $\bbF_2$ where flipping a switch  is just adding $1\bmod 2$. The $\mathrm{ON}$ state correspond to $1\in\bbF_2$ and the $\mathrm{OFF}$ state correspond to $0\in\bbF_2$. So for any state of the $n\times n$ board where some switches are $\mathrm{ON}$ and rest of the switches are $\mathrm{OFF}$ we can encode this configuration by an $n\times n$ matrix with $1$ at $(i,j)$ position if the switch at the $(i,j)$ position of the board is $\mathrm{ON}$ for all $i,j\in[n]$.  Now given that when we flip a switch all its adjacent switches also gets flipped. So we can encode flipping a switch at $(i,j)$ position be a $n\times n$ matrix $A_{i,j}$ where $$A_{i,j}[s,t]=\begin{cases}
		1 & \text{if $(s,t)\in \{(i-1,j),(i,j),(i+1,j), (i,j-1),(i+1,j)\}$}\\
		0 & \text{otherwise}
	\end{cases}$$ for all $s,t\in[n]$. So flipping a switch at $(i,j)$ position means adding $A_{i,j}$ to the configuration of the board modulo 2. We do the addition of matrices in $\bmod 2$. Since flipping a switch is same as adding $1\bmod 2$ i.e working in $\bbF_2$. So  flipping a switch 2 times is same as not flipping a switch at all. And because of $\bbF_2$ operation nature the order of sequence of flipping  switches also doesn't matter. So to reach a configuration by a sequence of flipping switches we can flip any switch at most once.

With this set up to show there exists a configuration for which no sequence of flipping switches lead to every switch with $\mathrm{OFF}$ state with flipping any switch at most once is equivalent to the case that  there exists a configuration where we can not reach by a sequence of flipping switches from every switch is $\mathrm{OFF}$ state with flipping any switch at most once. This is also equivalent to saying there is a $n\times n$ matrix with all entries from $\{0,1\}$ which can be written as sum of some of the $A_{i,j}$ matrices. This is because adding $A_{i,j}$ matrix is same as flipping the $(i,j)$ position switch and since every switch can be flipped at most once it is just the sum of some $A_{i,j}$ matrices. 

Let $\mcM_n(\bbF_2)$ denote the set of all $n\times n$ matrices with each entry from $\bbF_2$. Clearly $\mcM_n(\bbF_2)$ forms a vector space over $\bbF_2$ with just matrix addition modulo $2$ and multiplying a matrix with any $\alpha\in\bbF_2$ is multiplying each element of the matrix with $\alpha$. So the whole problem is to show that $$\exs\ M\in\mcM_n(\bbF_2)\text{ such that }M\notin \lt\la A_{i,j}\mid i,j\in[n]\rt\ra\iff \lt\la A_{i,j}\mid i,j\in[n]\rt\ra\neq \mcM_n(\bbF_2)$$Hence we have to $\lt\{ A_{i,j}\mid i,j\in[n]\rt\}\text{ is not a basis}$. 

Now we have a basis $B=\{B_{i,j}\mid i,j\in[n]\}$ for $\mcM_n(\bbF_2)$ where $B_{i,j}[s,t]=1$ if $s=i,t=j$ and $0$ otherwise. $|B|=n^2$ and $B$ is linearly independent. Clearly $B$ is a basis for $\mcM_n(\bbF_2)$. Therefore $\dim(\mcM_n(\bbF_2))=n^2$. And $|\{A_{i,j}\mid i,j\in[n]\}|=n^2$. Hence to show $\{A_{i,j}\mid i,j\in[n]\}$ is not a basis is same as showing they are linearly dependent. 

So the problem reduced to showing the set of moves we can do on the board is linearly dependent. To show $A_n=\{A_{i,j}\mid i,j\in[n]\}$ is linearly dependent is same as showing $\exs \ M\in\mcM_n(\bbF_2)$ such that $\exs\ \{A_{i_k,j_k}\mid k\in [m_1]\}\neq \{A_{i_k,j_k}\mid k\in [m_2]\}$ such that $$M=\sum_{k\in [m_1]}A_{i_{k},j_{k}}=\sum_{k\in [m_2]}A_{i_{k},j_{k}}$$for some $m_1,m_2\in\bbN$ with $m_1,m_2\leq n^2$. If this happens then we will have $$\sum_{k\in [m_1]}A_{i_{k},j_{k}}+\sum_{k\in [m_2]}A_{i_{k},j_{k}}=O$$where $O$ is all $0$ matrix. So $A_n$ is linearly dependent. 
\begin{lemma}
	For any $n\in\bbN$ for the form $n=6k-1$ where $k\in\bbN$, $A_n$ is linearly dependent.
\end{lemma} 
\begin{proof}
	Let $n=6k-1$ for some $k\in\bbN$. Now we divide the $n\times n$ board into small rectangular boards. Consider a $n\times 2$ and $n\times 3$ boards. So we create two partitions with these rectangular boards.$$P_1=\Big\{[n]\times \{1,2\}\Big\}\cup \Big\{[n]\times \{3i,3i+1,3i+2\}\mid i\in[2k-1] \Big\}$$And  $$ P_2=\Big\{[n]\times \{3i-2,3i-1,3i\}\mid i\in[2k-1] \Big\}\cup \Big\{[n]\times \{n-1,n\}\Big\}$$We will show disjoint set of switches to be pressed for $P_1$ and $P_2$ but for both of them we will reach same configuration which is the board with $(2i-1)^{th}$ row with all $1$'s for all $i\in[3k]$. Call this configuration $J$ where for any $s,t\in[n]$ $$J[s,t]=\begin{cases}
		1& \text{when $s=2i-1$ for some $i\in[3k]$}\\
		0 & \text{otherwise}
	\end{cases}$$
	\begin{itemize}
		\item \textbf{For $\boldsymbol{P_1}$:} For the $[n]\times \{1,2\}$ we press the switches $(2i-1,1)$ for all $i\in[3k]$. This will lead to a row with all $1$'s in every $(2i-1)^{th}$ row for $i\in[3k]$ because the state of swtich at $(2i,1)$ positions for all $i\in[3k-1]$ will be $\mathrm{OFF}$ because they are flipped two times because of flipping $(2(i-1)-1,1)$ and $(2i-1,1)$ and the $(2i,2)$ switch state is not changed as they are unhampered.    So we conclude the rectangular board $[n]\times \{1,2\}$ after pressing all the switches of  $(2i-1,1)$ for all $i\in[3k]$ has the  $(2i-1)^{th}$ row with all $1$'s for all $i\in[3k]$. \parinn
		
		For every $i\in[2k-1]$ the $[n]\times \{3i,3i+1,3i+2\}$ rectangular board we press the switches $(1+2j,3i+1)$ for all $j\in[3k]$. This will lead to $({2j-1})^{th}$ row with all $1$'s for all $j\in[3k]$. Because the state of the switch $(2j,3i+1)$ for all $j\in[3k-1]$ will be $\mathrm{OFF}$ because they are flipped twice because of flipping $(2(j-1)-1,3i+1)$ and $(2j-1,3i+1)$ switches and the switches are $(2j,3i)$, $(2j,3i+2)$ for all $j\in[3k-1]$ are $\mathrm{OFF}$ because they are not hampered because of the switches we pressed. So we conclude that the rectangular board $[n]\times \{3i,3i+1,3i+2\}$ after pressing all the switches  $(2j-1,3i+1)$ for all $j\in[3k]$ has  the $({2j-1})^{th}$ row with all $1$'s for all $j\in[3k]$ for all $i\in[2k-1]$.
		
		Flipping a switch in one of the member of $P_1$ doesn't hamper another member because for switches on left or right edge horizontally it just one neighbor at right or left side respectively and for switches in the $n\times 3$ board we are pressing some switches in the middle column. So they don't have effect on each other.  Therefore after in the $n\times n$ board if we press the switches $$S_1=\{(2j-1,1),(2j-1,3i+1)\colon i\in[2k-1],\ j\in[3k]\}$$ will lead to $(2j-1)^{th}$ row with all $1$'s for all $j\in[3k]$. Therefore we have $$\sum_{j=0}^{3k}\lt[A_{2j-1,1}+ \sum_{i=1}^{2k-1}A_{2j-1,3i+1}\rt]=J$$
		
		
		\item  \textbf{For $\boldsymbol{P_2}$:} For the $[n]\times \{n-1,n\}$ we press the switches $(2i-1,1)$ for all $i\in[3k]$. This will lead to a row with all $1$'s in every $(2i-1)^{th}$ row for $i\in[3k]$ because the state of swtich at $(2i,n)$ positions for all $i\in[3k-1]$ will be $\mathrm{OFF}$ because they are flipped two times because of flipping $(2(i-1)-1,n)$ and $(2i-1,n)$ and the $(2i,n-1)$ switch state is not changed as they are unhampered.    So we conclude the rectangular board $[n]\times \{n-1,n\}$ after pressing all the switches of  $(2i-1,n)$ for all $i\in[3k]$ has the  $(2i-1)^{th}$ row with all $1$'s for all $i\in[3k]$. \parinn
		
		For every $i\in[2k-1]$ the $[n]\times \{3i-2,3i-1,3i\}$ rectangular board we press the switches $(1+2j,3i-1)$ for all $j\in[3k]$. This will lead to $({2j-1})^{th}$ row with all $1$'s for all $j\in[3k]$. Because the state of the switch $(2j,3i-1)$ for all $j\in[3k-1]$ will be $\mathrm{OFF}$ because they are flipped twice because of flipping $(2(j-1)-1,3i-1)$ and $(2j-1,3i-1)$ switches and the switches are $(2j,3i-2)$, $(2j,3i)$ for all $j\in[3k-1]$ are $\mathrm{OFF}$ because they are not hampered because of the switches we pressed. So we conclude that the rectangular board $[n]\times \{3i-2,3i-1,3i\}$ after pressing all the switches  $(2j-1,3i-1)$ for all $j\in[3k]$ has  the $({2j-1})^{th}$ row with all $1$'s for all $j\in[3k]$ for all $i\in[2k-1]$.
		
		Flipping a switch in one of the member of $P_1$ doesn't hamper another member because for switches on left or right edge horizontally it just one neighbor at right or left side respectively and for switches in the $n\times 3$ board we are pressing some switches in the middle column. So they don't have effect on each other.  Therefore after in the $n\times n$ board if we press the switches $$S_2=\{(2j-1,n),(2j-1,3i-1)\colon i\in[2k-1],\ j\in[3k]\}$$ will lead to $(2j-1)^{th}$ row with all $1$'s for all $j\in[3k]$. Therefore we have $$\sum_{j=0}^{3k}\lt[A_{2j-1,n}+ \sum_{i=1}^{2k-1}A_{2j-1,3i-1}\rt]=J$$
	\end{itemize}
Notice that $S_1\cap S_2=\phi$. Hence we get complete disjoint two sets of sequence of flipping switches $S_1$ and $S_2$ with which we reach the same configuration $J$. Therefore $A_n$ is linearly independent.
\end{proof}

Therefore we got that $A_n$ is linearly dependent for all  $n=6k-1$ for any $k\in\bbN$. Therefore $A_n$ is not a basis of $\mcM_n(\bbF_2)$. Hence there exists a configuration where we can not reach by a sequence of flipping switches. Now since the given number $17=6\times 3-1$ i.e. it is of the form $6k-1$ we can conclude that there is an configuration where we can not reach by a sequence of flipping switches or equivalently there is an configuration for which no sequence of modifications will lead the configuration where every switch is $\mathrm{OFF}$.
}\parinf
\vspace*{5mm}

[I understood the solution of this problem from Soumyadeep Paul]
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
		The Isomorphism Theorems
	}{p2% problem reference text
	}
Let $V$ be a vector space over a field $\mathbb{F}$. For $v \in$ $V$ and subsets $S, T \subseteq V$, define the sets $v+S=\{v+s \mid s \in S\}$ and $S+T=$ $\{s+t \mid s \in S, t \in T\}$.

\begin{definition*}[Quotient spaces]
	 Let $U \leq V$. Define the quotient space $V / U$ to be the vector space over $\mathbb{F}$ whose elements are of the form $v+U$ for some $v \in V$. Addition is defined as $(v+U)+\left(v^{\prime}+U\right)=\left(v+v^{\prime}+U\right)$ for all $v, v^{\prime} \in V$ and scalar multiplication is defined as $a(v+U)=a v+U$ for all $v \in V$ and $a \in \mathbb{F}$.

\end{definition*}
Prove that the two operations are well-defined and that $V / U$ is indeed a vector space. Calculate its dimension. Then, prove the following theorems. After you've done so, try reading about similar isomorphism theorems for groups, rings, etc. We will discuss them later in the course.
\begin{enumerate}[label=(\alph*)]
\item (\textbf{First isomorphism theorem}) Let $U$ and $V$ be two vector spaces over the same field $\mathbb{F}$ and let $\theta: U \rightarrow V$ be a linear transformation. Then, $\ker(\theta)$ is a subspace of $U, \Im(\theta)$ is a subspace of $V$, and
$$
\quotient{U}{\ker \theta} \cong \Im\theta
$$
\item (\textbf{Second isomorphism theorem}) Let $V$ be a vector space over a field $\mathbb{F}$ and let $S, T \leq V$. Then, $S+T \leq V$ and we have:
$$
\quotient{S}{S\cap T}\cong \quotient{S+T}{T}
$$
\item (\textbf{Third isomorphism theorem}) Let $T \leq U \leq V$ be a vector spaces over the field $\mathbb{F}$. Then, $\quotient{U}{T}\leq \quotient{V}{T}$ and:
$$
\quotient{\lt(\quotient{V}{T}\rt)}{\lt(\quotient{U}{T}\rt)}\cong \quotient{V}{U}
$$
\item (\textbf{``Fourth" isomorphism theorem}) Let $U \leq V$ be a vector spaces over the field $\mathbb{F}$. There is a bijection between subspaces of $V$ containing $U$ and subspaces of $\quotient{V}{U}$.
\end{enumerate}
\end{problem}
\solve{	
	First we will prove that $\quotient{V}{U}$ is a vector space. We will do this step by step:
	\begin{itemize}
		\item $\boldsymbol{\lt(\quotient{V}{U},+\rt)}$\textbf{ is Abelian:} \begin{itemize}
			\item For any $v,v'\in \quotient{V}{U}$ we have $(v+U)+(v'+U)=(v+v')+U$. Now $v+v'\in V$. Hence it is closed under addition
			\item Let $u,v,w\in V$. Then \begin{multline*}
				((u+U)+(v+U))+(w+U)=((u+v)+U)+(w+U)=((u+v)+w)+U=(u+(v+w))+U\\
				=(w+U)+((v+w)+U)=(u+U)+((v+U)+(w+U))
			\end{multline*}Hence we have the associativity property.
			\item $0\in V$. So for any $v\in V$ $$(v+U)+(0+U)=(v+0)+U=v+U\quad (0+U)+(v+U)=(0+v)+U=v+U$$So we have the identity property as $0+U$ is the identity element.
			\item For any $v\in V$ there is $-v\in V$ since $V$ is a vector space. Then $$(v+U)+((-v)+U)=(v+(-v))+U=0+U=((-v)+v)+U=((-v)+U)+(v+U)$$ Hence $\quotient{V}{U}$ also have additive identity.
			\item For any $v,w\in V$ we have $$(v+U)+(w+U)=(v+w)+U=(w+v)+U=(w+U)+(v+U)$$Therefore addition in $\quotient{V}{U}$ is commutative
		\end{itemize}
	Hence we conclude that $\lt(\quotient{V}{U},+\rt)$ is an abelian group.
	\item \textbf{Multiplication:} For any $\alpha\in\bbF$ , $v\in V$ we have $\alpha(v+U)=\alpha v+U$. So if $\alpha =1$ then $$1\cdot (v+U)=(1\cdot v)+U=v+U$$ and for any $\alpha,\beta\in\bbF$ we have $$\alpha(\beta(v+U))=\alpha((\beta v)+U)=(\alpha(\beta v))+U=((\alpha\cdot \beta)v)+U=(\alpha\cdot \beta)(v+U)$$Therefore it follows the multiplication property.
	\item \textbf{Distributivity:} For all $v,w\in V$ and $\alpha\in \bbF$ we have \begin{multline*}
		\alpha((v+U)+(w+U))=\alpha((v+w)+U)=(\alpha(v+w))+U=(\alpha\cdot  v+\alpha \cdot w)+U\\
		=((\alpha\cdot v)+U)+((\alpha\cdot w)+U)=\alpha(v+U)+\alpha(w+U)
	\end{multline*}And for any $\alpha,\beta\in \bbF$ and $v\in V$ we have $$(\alpha+\beta)(v+U)=((\alpha+\beta)v)+U=(\alpha\cdot v+\beta\cdot v)+U=((\alpha\cdot v)+U)+((\beta\cdot v)+U)=\alpha(v+U)+\beta(v+U)$$
	\end{itemize}
Therefore $\lt(\quotient{V}{U},+,\cdot\rt)$ follows all the properties of a vector space. Hence $\quotient{V}{U}$ is indeed a vector space over $\bbF$. 

Now we will prove all the isomorphism theorems.
	\begin{enumerate}[label=(\alph*)]
		\item Define the map $\vph:\quotient{U}{\ker\theta}\to \Im \theta$ where $\vph(x+\ker\theta)=\theta(x)$ for any $x+\ker\theta\in \quotient{U}{\ker\theta}$ where $x\in U$. Now we will prove first $\vph $ is a well defined map then it is a linear map and then it is a bijection.
	\begin{itemize}
		\item \textbf{{Well Defined:}} Let $x+\ker\theta,y+\ker\theta\in \quotient{U}{\ker\theta}$ for $x,y\in U$. Now suppose we have $x+\ker\theta=y+\ker\theta$. We have to show that $\vph(x+\ker\theta)=\vph(y+\ker\theta)$. Now  $$x+\ker\theta=y+\ker\theta\implies x-y\in\ker\theta\implies \theta(x-y)=0\implies \theta(x)=\theta(y)$$Now we know $\theta(x)=\vph(x+\ker\theta)$ and $\theta(y)=\vph(y+\ker\theta)$. Hence we have $ \vph(x+\ker\theta)=\vph(y+\ker\theta)$. So $\vph$ is a well defined map.
		\item \textbf{Linear Map:} Let $x+\ker\theta,y+\ker\theta\in \quotient{U}{\ker\theta}$ for some $x,y\in U$. Then $$\vph((x+y)+\ker\theta)=\theta(x+y)=\theta(x)+\theta(y)=\vph(x+\ker\theta)+\vph(y+\ker\theta)$$Hence $\vph$ is linear. Now let $\alpha\in \bbF$. Now $$\vph((\alpha x)+\ker\theta)=\theta(\alpha x)=\alpha \theta(x)=\alpha\vph(x+\ker\theta)$$Hence $\vph$  also satisfies the scalar multiplication property of linear maps. Hence $\vph$ is a linear map between $\quotient{U}{\ker\theta}$ and $\Im\theta$. 
		\item \textbf{Injectivity:} Let $x+\ker\theta, y+\ker\theta\in \quotient{U}{\ker\theta}$ for some $x,y\in U$. Now suppose we have $$\vph(x+\ker\theta)=\vph(y+\ker\theta)\implies \theta(x)=\theta(y)\implies \theta(x-y)=0\implies x-y\in\ker\theta$$Since $x-y\in\ker\theta $ we have $y\in x+\ker\theta$ since $x-(x-y)=y$ and similarly we have $x\in y+\ker\theta$. Hence we get $x+\ker\theta=y+\ker\theta$. Therefore $\vph$ is injective. 
		\item \textbf{Surjectivity:} Let $v\in \Im\theta$. Hence $\exs\ x\in U$ such that $\theta(x)=v$. Then consider the vector $x+\ker\theta\in \quotient{U}{\ker\theta}$. Certainly we have $$\vph(x+\ker\theta)=\theta(x)=v$$Hence  for every $v\in \Im\theta$ there is an preimage $x+\ker\theta\in \quotient{U}{\ker\theta}$  where $\vph(x+\ker\theta)=v$. Therefore $\vph$ is surjective. 
	\end{itemize}
Since $\vph$ is injective and surjective we can say $\vph$ is a bijection. And since $\vph$ is also a linear map we conclude $\vph$ is an isomorphism. Therefore we have $$\quotient{U}{\ker\theta}\cong \Im \theta$$
\item Consider the map $\vph:S\to \quotient{S+T}{T}$ where for any $s\in S$, $s\mapsto s+T$. Now we will first show $\vph $ is a well defined surjective linear map and then we will show $\ker\vph=S\cap T$. Then by first isomorphism theorem we will have result.\begin{itemize}
	\item \textbf{Well Defined:} Let $x,y\in S$ and $x=y$. Then we have to show $\vph(x)=\vph(y)$. Now $\vph(x)=x+T$ and $\vph(y)=y+T$. Now any element of $x+T$ is of the form $x+t$ for some $t\in T$. Since $x=y$ we have $x+t=y+t$. Therefore $x+t\in y+T$. And similarly  for any element $y+t$ of $y+T$ for some $t\in T$ we have $y+t\in x+T$. Therefore $x+T=y+T$. Hence $\vph(x)=\vph(y)$. So $\vph$ is well defined.
	\item \textbf{Linear Map:} Let $x,y\in S$. Now $$\vph(x+y)=(x+y)+T=(x+T)+(y+T)=\vph(x)+\vph(y)$$Let $\alpha\in\bbF$. Hence Then we have $$\vph(\alpha x)=(\alpha x)+T=\alpha(x+T)=\alpha\vph(x)$$Therefore $\vph$ is a linear map. 
	\item \textbf{Surjectivity:} Any vector of $\quotient{S+T}T$ is of the form $u+T $ for some $u\in S+T$. Now any vector of $S+T$ is of the form $s+t$ for some $s\in S$ and $t\in T$. Therefore $$u+T=(s+t)+T=s+(t+T)=s+T$$Now $\vph(s)=s+T=u+T$. Therefore $\vph$ is a surjective linear map. 
	\item $\boldsymbol{\ker\vph=S\cap T}$\textbf{:} Let $s\in S$ and $\vph(s)=0$. Now $\vph(s)=s+T$. Hence $s+T=0+T\implies s\in T$. Therefore $s\in S\cap T$. Therefore $\ker\vph\subseteq S\cap T$. Now let $s\in S\cap T\implies s\in T$. So $s+T=0+T$. Therefore $\vph(s)=0$. Hence $s\in \ker\vph$. Therefore $\ker\vph\supseteq S\cap T$. Hence we get $\ker\vph=S\cap T$. 
\end{itemize}
Therefore using the first isomorphism theorem we have $$\quotient{S}{\ker\vph}\cong \Im\vph\iff \quotient{S}{S\cap T}\cong \quotient{S+T}{T}$$
\item Consider the map $\vph:\quotient{V}T\to \quotient{V}{U}$ where $v+T\mapsto v+U$ for some $v+T\in \quotient{V}T$ where $v\in V$. Now we will show $\vph$ is a well defined, linear, surjective map and its kernel is $\quotient{U}T$. Then we will use the first isomorphism theorem
\begin{itemize}
	\item \textbf{Well Defined:} Let $v+T,w+T\in\quotient{V}{T}$ for some $v,w\in V$. Now assume $v+T=w+T$. We will show $\vph(v+T)=\vph(w+T)$. Now $v+T=w+T\implies v-w\in T$. And we have $T\leq U$. Therefore $$v-w\in U\implies v+U=w+U\implies \vph(v)=\vph(w)$$Therefore $\vph$ is well defined.
	\item \textbf{Linear Map:} Let $v+T,w+T\in\quotient{V}{T}$ for some $v,w\in V$. Now $$\vph((v+w)+T)=(v+w)+U=(v+U)+(w+U)=\vph(v+T)+\vph(w+T)$$Let $\alpha\in\bbF$. Then we have $$\vph((\alpha v)+T)=(\alpha v)+U=\alpha(v+U)=\alpha \vph(v)$$Therefore $\vph$ is a well defined linear map.
	\item \textbf{Surjectivity:} Let $v+U\in \quotient{V}{U}$ for some $v\in V$. Since $T\leq U$, $v+T$ is  a vector of $\quotient{V}{T}$. Then $\vph(v+T)=v+U$. Therefore $\vph$ is surjective.
	\item $\boldsymbol{\ker\vph=\quotient{U}{T}}$\textbf{:} Let $v+T\in \ker\vph$ for some $v\in V$. Now $\vph(v+T)=0$. Hence $v+U=0+U\implies v\in U$. Therefore $v+T\in \quotient{U}{T}$ as $\quotient{U}T\leq \quotient{V}{T}$. Hence $\ker\vph\subseteq \quotient{U}{T}$. Now let $u+T\in\quotient{U}{T}$ for some $u\in U$. Since $\quotient{U}T\leq \quotient{V}{T}$, $u+T\in\quotient{V}{T}$. Now $\vph(u+T)=u+U=o+U$. Therefore $u+T\in\ker\vph$. Therefore we have $\ker\vph\supseteq \quotient{U}{T}$. Hence we have $$\ker{\vph}=\quotient{U}{T}$$
\end{itemize}
Therefore using first isomorphism theorem we have $$\quotient{\lt(\quotient{V}{T}\rt)}{\ker\vph}\cong\Im \vph\iff\quotient{\lt(\quotient{V}{T}\rt)}{\lt(\quotient{U}T\rt)}\cong \quotient{V}{U}$$
\item Consider the set $\spec(V)_U=\{W\leq V\mid \text{$W$ subspace of $V$ containing $U$}\}$ for any vector space $V$ over $\bbF$. Also consider the set $\spec(\quotient{V}{U})=\{W\leq \quotient{V}{U}\mid \text{$W$ subspace of $\quotient{V}{U}$}\}$. Now we have to show there is a bijection between $\spec(V)_U$ and $\spec\lt(\quotient{V}{U}\rt)$. Consider the function $f:\spec(V)_U\to \spec\lt(\quotient{V}U\rt)$ where $W\mapsto \quotient{W}{U}$ for any subspace $W\in \spec{V}_U$. Now we will show $f$ is a bijection. \begin{itemize}
	\item \textbf{Injectivity:} Now let $S,T\in \spec(V)_U$ such that $f(S)=f(T)$. Hence we have $\quotient{S}{U}=\quotient{T}{U}$. Let $s\in S$. Then $s+U\in \quotient{S}{U}$. Therefore $s+U\in \quotient{T}{U}$. So $s+U=t+U$ for some $t\in T$. Now we have $s\in t+U\subseteq t+T=T$. So $s\in T$. Therefore $S\subseteq T$. Similarly for any $t\in T$ we have $$t+U\in \quotient{T}{U}=\quotient{S}{U}\implies t+U=s+U\text{ for some $s\in S$}\implies t\in s+U\subseteq s+S=S\implies T\subseteq S$$Therefore we have $S=T$. Hence $f$ is injective.
	\item \textbf{Surjectivity:} Let $W\leq \quotient{V}{U}$. Consider the linear map $\psi: V\to \quotient{V}{U}$ where $v\mapsto v+U$ for all $v\in V$. Now $\psi $ is  indeed a linear map because of the addition and scaler multiplication rules in $\quotient{V}{U}$ explained in defining quotient space as $$\psi(v+w)=(v+w)+U=(v+U)+(w+U)=\psi(v)+\psi(w) \text{ for all $v,w\in V$} $$ and  $$\psi(\alpha v)=(\alpha v)+U=\alpha(v+U)=\alpha\psi(v)\text{ for all $\alpha\in\bbF$ and $v\in V$}$$
	
	Then consider the subspace $\psi^{-1}(W)$ of $V$. Then we  $$\vph\lt(\psi^{-1}(S)\rt)=\vph\lt(\{v\in V\mid v+U\in W\}\rt)=\{\vph(v)\mid v\in V,\ v+U\in W\}=W$$
\end{itemize}
Therefore $f$ is bijective. Hence there is a bijection between subspaces of $V$ containing $U$ and subspaces of $\quotient{V}{U}$. 
\end{enumerate}
}
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
	}{p3% problem reference text
	}
Let $V$ be a vector space over a field $\mathbb{F}$ and $W_1, \ldots, W_k \leq V$ be subspaces. We say that $V$ is the internal direct sum of $W_1, \ldots, W_k$ and write $V=\bigoplus\limits_{i=1}^k W_i$ if for all $v \in V$, there exists unique $w_1 \in W_1, \ldots, w_k \in W_k$ such that $v=\sum\limits_{i=1}^k w_i$. The values $w_1, \ldots, w_k$ are called the projections of $v$ onto $W_1, \ldots, W_k$ respectively.\begin{itemize}
	\item Show that $V=\bigoplus\limits_{i=1}^k W_i$ if and only if $V=\sum\limits_{i=1}^k W_i$, and for all $i \in[k]$, we have $W_i \cap \sum\limits_{i^{\prime} \neq i} W_{i^{\prime}}=\{0\}$.
	\item Let $\theta \in L(V)$. Show that $\theta$ is idempotent (namely, we have $\theta \circ \theta=\theta$ ) if and only if $V=\Im(\theta) \ \oplus \ \ker(\theta)$ and for all $v \in V, \theta(v)$ is just the projection of $v$ onto $\Im(\theta)$.
	\item Let $\theta_1, \ldots, \theta_k \in L(v)$ be idempotent such that $\theta_i \circ \theta_{i^{\prime}}=0$ whenever $i \neq i^{\prime} \in[k]$. Let $\theta_0=I-\sum\limits_{i=1}^k \theta_i$. Show that $\theta_0$ is idempotent and:
	$$
	V=\bigoplus_{i=0}^k \Im\left(\theta_i\right)
	$$
\end{itemize}

\end{problem}
\solve{
	\begin{itemize}
		\item \begin{itemize}
			\item \textbf{Forward Direction $\boldsymbol{(\Rightarrow)}$:} $V=\bigoplus\limits_{i=1}^k W_i$. Then for all $v\in V$, $\exs!\ w_i\in W_i$ such that $v=\sum\limits_{i=1}^nw_i$. So $v\in \sum\limits_{i=1}^k W_i\implies V\subseteq \sum\limits_{i=1}^k W_i$. Now since $W_i$ is a subspace of $V$ for all $i\in[k]$, $\sum\limits_{i=1}^k W_i$ is a subspace of $V$. Therefore we have $V=\sum\limits_{i=1}^k W_i$. 
			
			\parinn Now suppose $\exs\ i\in[k]$ such that $W_i\cap \sum\limits_{i'\neq i}W_{i'}\neq \{0\}$. Let $w\in W_i\cap \sum\limits_{i'\neq i}W_{i'}$ and $w\neq 0$. Since $w\in \sum\limits_{i'\neq i}W_{i'}$ there exists $w_{i'}\in W_{i'}$ for all $i'\in [k]$, $i'\neq i$ such that $w=\sum\limits_{i'\neq i}w_{i'}$. Hence we have two ways of expressing $w\in V$ one is as a vector of $W_i$ and another is $\sum\limits_{i'\neq i}w_{i'}$. This contradicts that for all $v\in V$ there exists unique $w_i\in W_i$ for all $i\in[k]$ such that $v=\sum\limits_{i=1}^kw_i$. Hence contradiction. We have for all $i\in[k]$, $W_i\cap \sum\limits_{i'\neq i}W_{i'}=\{0\}$. 
			\item \textbf{Backward Direction $\boldsymbol{(\Leftarrow)}$:} Let $V=\sum\limits_{i=1}^k W_i$ and for all $i\in[k]$, $W_i\cap \sum\limits_{i'\neq i}W_{i'}=\{0\}$. For all $v\in V=\sum\limits_{i=1}^kW_i$ there exists $w_i\in W_i$ for all $i\in[k]$ such that $v=\sum\limits_{i=1}^k w_i$. Suppose there exists a vector $v\in V$ such that $\exs\ \{w_i\in W_i\mid i\in[k]\}\neq \{w'_i\in W_i\mid i\in[k]\}$ such that $$v=\sum\limits_{i=1}^kw_i=\sum_{i=1}^k w'_i\implies \sum\limits_{i=1}^k (w_i-w'_i)=0\implies w_i-w'_i=\sum_{j\neq i}(w'_j-w_j)$$So denote $w=w_i-w'_i$ Then $w\in W_i$ and $w\in \sum\limits_{j\neq i}W_j$ as $w'_j-w_j\in W_j$ for all $j\in [k]$, $j\neq i$ and $\sum\limits_{j\neq i}(w'_j-w_j)\in \sum\limits_{j\neq i}W_j$. So $W_i\cap \sum\limits_{j\neq i}W_j\neq \{0\}$. Hence contradiction. There doesn't exists any vector in $V$ with more than one representations as summation of $k$ vectors one from each of the $W_i$, $i\in[k]$. Hence for each $v\in V$, $\exs!\ w_i\in W_i\ \forall \ i\in[k]$ such that $v=\sum\limits_{i=1}^k w_i$. Hence  $V=\bigoplus\limits_{i=1}^k W_i$. 
		\end{itemize}
	Hence we have $V=\bigoplus\limits_{i=1}^k W_i\iff V=\sum\limits_{i=1}^k W_i$, and for all $i \in[k]$, we have $W_i \cap \sum\limits_{i^{\prime} \neq i} W_{i^{\prime}}=\{0\}$.
	
	\item \begin{itemize}
		\item \textbf{Forward Direction $\boldsymbol{(\Rightarrow)}$:} Let $\theta\in L(V)$ is idempotent. Suppose $v\in V$ be any vector. Now we have $v=\theta(v)+(v-\theta(v))$. Certainly $\theta(v)\in \Im \theta$. Now $$\theta(v-\theta(v))=\theta(v)-T\circ \theta(v)=\theta(v)-\theta(v)=0\implies v-\theta(v)\in \ker\theta$$ Hence for all $v\in V$, $v$ can be expressed as a sum of a vector from $\Im\theta$ and a vector from $\ker \theta$. Hence $V\subseteq \Im\theta +\ker\theta$ and since $\Im\theta $ and $\ker\theta$ are subspaces of $V$ so we have $V=\Im\theta+\ker\theta$. Now it is enough to show that $\ker\theta\cap \Im\theta=\{0\}$. Now let $v\in\ker\theta\cap \Im\theta$. Since $v\in \ker\theta$ we have $\theta(v)=0$. And $v\in\Im\theta$ so there exists $u\in V$ such that $\theta(u)=v$. Therefore $0=\theta(v)=\theta\circ \theta(u)=\theta(u)=v$. Hence $\ker\theta\cap \Im\theta=\{0\}$. Therefore by the part (a) we have $V=\ker\theta\oplus \Im\theta$. Hence for all $v\in V$, $v=\theta(v)+(v-\theta(v))$ is the only unique representation as a sum of a vector from $\Im\theta $ and a vector from $\ker\theta$. Hence $\theta(v)$ is the projection of $v$ onto $\Im(\theta)$. 
		
	\item 	\textbf{Backward Direction $\boldsymbol{(\Leftarrow)}$:} Suppose $V=\Im\theta\oplus \ker\theta$. For any $v\in V$, $\exs!\ u\in\Im\theta,\ w\in\ker\theta$, such that $v=u+w$. Since $\theta(v)$ is the projection of $v$ onto $\Im\theta$ we have $u=\theta(v)$. Then $v=\theta(v)+w$ where $\theta(w)=0$. Hence we have $$\theta(v)=\theta(\theta(v)+w)=\theta\circ\theta(v)+\theta(w)=\theta\circ\theta(v)$$Hence we have for all $v\in V$, $\theta(v)=\theta\circ\theta(v)$. Therefore $\theta \circ\theta=\theta$ i.e. $\theta$ is idempotent.
	\end{itemize}
Hence we have $\theta $ is idempotent $\iff V=\Im\theta\oplus \ker\theta$ and for all $v\in V$, $\theta(v)$ is just the projection of $v$ onto  $\Im\theta$. 
\item \begin{itemize}
	\item We know for all $i\in[k]$ $\theta_i\circ\theta_i=\theta_i$ and for all $i,j\in[k]$, $i\neq j$ we have $\theta_i\circ\theta_j=0$. Now \begin{align*}
		\theta_0\circ \theta_0 & =  \lt[I-\sum_{i=1}^k\theta_i\rt]\circ\lt[I-\sum_{j=1}^k\theta_j\rt]\\
		& = I\circ I -I\circ\lt(\sum_{i=1}^k\theta_i\rt) - \lt(\sum_{j=1}^k\theta_j\rt)\circ I +\lt(\sum_{i=1}^k\theta_i\rt)\circ \lt(\sum_{j=1}^k\theta_j\rt)\\
		& = I-\sum_{i=1}^k\theta_i-\sum_{i=1}^k\theta_i+\lt(\sum_{i=1}^k\theta_i\rt)\circ \lt(\sum_{j=1}^k\theta_j\rt)\\
		& = I-2\sum_{i=1}^k\theta_i+\sum_{1\leq i,j\leq k}\theta_i\circ \theta_j\\
		& =  I-2\sum_{i=1}^k\theta_i+\sum_{i=1}^k\theta_i\circ\theta_i+\sum_{1\leq i\neq j\leq \leq k}\theta_i\circ \theta_j\\
		& = I-2\sum_{i=1}^k\theta_i+\sum_{i=1}^k\theta_i\circ\theta_i = I-2\sum_{i=1}^k\theta_i+\sum_{i=1}^k\theta_i = I-\sum_{i=1}^k\theta_i=\theta_0
	\end{align*}Hence we have $\theta_0$ is idempotent. 
	
\item 	Now we have to show $V=\bigoplus\limits_{i=0}^k\Im\theta_i$. First of all notice for all $i\in[k]$ we have $$\theta_i\circ \theta_0=\theta_i\circ\lt(I-\sum\limits_{j=1}^k\theta_j\rt)=\theta_i-\sum_{j=1}^k\theta_i\circ\theta_j=\theta_i-\theta_i\circ\theta_i=0$$And similarly $$\theta_0\circ \theta_i=\lt(I-\sum_{j=1}^k \theta_j\rt)\circ \theta_i=\theta_i-\sum_{j=1}^k \theta_j\circ\theta_i=\theta_i-\theta_i\circ\theta_i=0$$Therefore $\forall\ i,j\in\{0,1,\dots,k\}$ we have $\theta_i\circ\theta_j=0$ if $i\neq j$ and $\theta_i\circ\theta_i=\theta_i$. Now by part (b) we have $V=\ker\theta_0\oplus \Im\theta_0$. We will show $\ker\theta_0=\bigoplus\limits_{i=1}^k\Im\theta_i$.  \begin{lemma}\label{vissumimtheta}
	For all $v\in\ker\theta_0$, $v=\sum\limits_{i=1}^k \theta_i (v)$
\end{lemma}
\begin{proof}
	$\theta_0(v)=\lt(I-\sum\limits_{i=1}^k\theta_i\rt)(v)=v-\sum\limits_{i=1}^k\theta_i(v)$. Since $v\in \ker\theta_0$ we have $$v-\sum\limits_{i=1}^k\theta_i(v)=0\iff v=\sum\limits_{i=1}^k\theta_i(v)$$
\end{proof}Now $\theta_i(v)\in \Im\theta_i$. Therefore $\ker\theta_0\subseteq \sum\limits_{i=1}^k \Im\theta_i$. Also for any $v\in \sum\limits_{i=1}^k \Im\theta_i$, $v$ can be written as $\sum\limits_{i=1}^kw_i$ where $w_i\in\Im\theta_i$. Therefore we can think $w_i=\theta_i(v_i)$ for some $v\in V$. Therefore $v=\sum\limits_{i=1}^k\theta_i(v_i)$. Hence $$\theta_0(v)=\sum_{i=1}^k \theta_0\circ \theta_i(v_i)=0$$Hence $v\in \ker\theta_0$. Hence $\sum\limits_{i=1}^k \Im\theta_i\subseteq \ker\theta_0$. Hence we get $\ker\theta_0=\sum\limits_{i=1}^k\Im\theta_i$. Now it is enough to show that $\forall\ i\in[k]$ we have $\Im\theta_i\cap \lt(\sum\limits_{j\neq i}\Im\theta_j\rt)=\{0\}$.
\begin{lemma}\label{novecinthetaimages}
	$\forall\ i\in[k]$ we have $\Im\theta_i\cap \lt(\sum\limits_{j\neq i}\Im\theta_j\rt)=\{0\}$
\end{lemma}
\begin{proof}
	For any $i\in[k]$, let $v\in \Im\theta_i\cap \lt(\sum\limits_{j\neq i}\Im\theta_j\rt)$. Since $v\in\Im\theta_i$ there exists $u\in V$, such that $v=\theta_i(u)$. Now since $v\in \sum\limits_{j\neq i}\Im\theta_j$, $\exs\ u_j\in V$ for all $j\in[k]$ such that $v=\sum\limits_{j\neq i}\theta_j(u_j)$. Now $$\theta_i(v)=\sum\limits_{j\neq i}\theta_i\lt(\theta_j(u_i)\rt)= \sum\limits_{j\neq i}\theta_i\circ\theta_j(u_j)=0$$So $\theta_i(v)=0$ but $\theta_i(v)=\theta_i\lt(\theta_i(u)\rt)=\theta_i\circ\theta_i(u)=\theta_i(u)=v$. Therefore $v=0$. Hence we have $\Im\theta_i\cap \lt(\sum\limits_{j\neq i}\Im\theta_j\rt)=\{0\}$
\end{proof}
Hence by part (a) and \lemref{vissumimtheta}, \lemref{novecinthetaimages} we have $\ker\theta_0=\bigoplus\limits_{i=1}^k \Im\theta_i$. Hence we have $V=\bigoplus\limits_{i=0}^k\Im\theta_i$.
\end{itemize}
	\end{itemize}
}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
	}{p4% problem reference text
	}
 Let $V$ be a 3-dimensional vector space over the field $\mathbb{Q}$ of rationals. Let $\theta \in L(V)$ and $x \neq 0 \in V$ be such that $\theta(x)=y, \theta(y)=z$, and $\theta(z)=x+y$. Show that $x, y, z$ form a basis of $V$.
\end{problem}
\solve{First we will show 2 lemmas. Then using them we will show $x,y,z$ form a basis.
	\begin{lemma}\label{znotgo0}
		$\theta(z)\neq 0$
	\end{lemma}
\begin{proof}
	If $\theta(z)=0$ then we have $x+y=0\implies y=-x$. That means $\theta(x)=y=-x$. Therefore $\theta(y)=\theta(-x)=-\theta(x)=-(-x)=x$. Therefore $z=x$. Then $\theta(z)=\theta(x)=y=-x$. We have $$\theta(z)=0\implies -x=0\implies x=0$$ But given that $x\neq 0$. Hence contradiction. So $\theta(z)\neq 0$.
\end{proof}

By the lemma we also have $y,z\neq 0$ because otherwise we will have $\theta(z)=0$ which is not possible. Hence $x,y=\theta(x),z=\theta(y),\theta(z)$ all of them are nonzero.
\begin{lemma}\label{noeigenvec}
	$x$ is not an eigenvector of $\theta$.
\end{lemma}
\begin{proof}
	Suppose $x$ is an eigenvector of $\theta$. Then $\exs\ \lm\in \bbQ$ such that $\theta(x)=\lm x$. By \lemref{znotgo0} we have $\lm\neq 0$. Hence $\theta(x)=\lm x=y$. $\theta(y)=\theta(\lm x)=\lm^2 x=z$. And we have $\theta(z)=\theta(\lm^2 x)=\lm^3 x$. Therefore we have $$\lm^3 x=x+y=x+\lm x\iff x(\lm^3-\lm-1)=0\iff \lm^3-\lm-1=0$$
	
	Now we will show the polynomial $f(t)=t^3-t-1$ does not have any rational root. Suppose $f(t)$ Let $\frac{p}{q}$ be a rational root of $f(t)$ where $\frac{p}{q}$ is in the lowest form for some $p,q\in\bbZ$ with $q\neq 0$ and $p,q$ coprime. Then $$f\lt(\frac{p}{q}\rt)=\frac{p^3}{q^3}-\frac{p}{q}-1=0\iff p^3-pq^2-q^3=0$$Call $f'=p^3-pq^2-q^3$. Now $q\mid 0$, $q\mid q^3$, $q\mid pq^2$. Hence $$q\mid f'+q^3+pq^2\implies q\mid p^3\implies q=1$$Here $q=\pm1$ since $gcd(p,q)=1$. Similarly $p\mid 0$, $p\mid p^3$, $p\mid pq^2$. Hence $$p\mid p^3-pq^2-f'\implies p\mid q^3\implies p=\pm1$$Hence both $p,q\in \{1,-1\}$. So $1$ or $-1$ should be a root of $f(t)$ but it is not. Hence contradiction. $f(t)$ has no rational root. 
	
	Since $f(t)$ has no rational root there doesn't exists any $\lm\in\bbQ$, $\lm\neq 0$ such that $\lm$ is an eigenvalue of $\theta$. Hence contradiction. Therefore $x$ is not an eigenvector of $\theta$. 
\end{proof}

Now we are ready to prove that $x,y,z$ forms a basis. Showing $x,y,z$ are linearly independent is enough for us. Suppose they are not. Then $\exs\ a,b,c\in \bbQ$  not all zero such that $ax+by+cz=0$. WLOG asssume $c\neq 0$. Hence we can divide $a,b$ by $c$ and still get a rational. So we can think $\exs\ a,b\in \bbQ$ such that $$ax+by-z=0\iff z=ax+by$$ Now composing $\theta$ on both sides we have \begin{equation*}
	a\theta(x)+b\theta(y)-\theta(z)=0\iff ay+bz-(x+y)=0\implies {-x+(a-1)y+bz=0}\label{compose1}
\end{equation*}Now replacing value of $z$ here we have $$-x+(a-1)y+bz=0\iff -x+(a-1)y+b({ax+by})=0\iff (ab-1)x+(a+b^2-1)y=0$$\textbf{Case 1 ($\boldsymbol{ab-1,\ a+b^2-1\neq 0}$):} If both of $ab-1$ and $a+b^2-1$ is nonzero then $y=\frac{1-ab}{a+b^2-1}x\implies x$ is an eigenvector of $\theta$. This is not possible by \lemref{noeigenvec}.  So at least one of them is zero. Suppose exactly one of them zero.\vspace*{2mm} \parinf

\textbf{Case 2 ($\boldsymbol{ab-1=0,\ a+b^2-1\neq 0}$):} Then $(a+b^2-1)y=0\implies y=0$ then we have $ \theta(z)=0$ which contradicts \lemref{znotgo0}.\vspace*{2mm}

\textbf{Case 3 ($\boldsymbol{ab-1\neq0,\ a+b^2-1= 0}$):} Then $(ab-1)x=0\implies x=0$. But given that $x\neq0$. Therefore this case is not possible.\vspace*{2mm}

\textbf{Case 4 ($\boldsymbol{ab-1=a+b^2-1=0}$):} In this case$$ab-1=0\iff b=\frac1a\implies a+b^2-1=0\iff a+\frac1{a^2}-1==0\iff a^3+1-a^2=0$$Consider the polynomial $g(w)=w^3-w^2+1$. So $a$ is a root of $g(w)$. Now let again $a=\frac{s}{t}$ in their lowest form. Then $$g\lt(\frac{s}{t}\rt)=\frac{s^3}{t^3}-\frac{s^2}{t^2}+1=0\iff s^3-s^2t+t^3=0$$Call $g'= s^3-s^2t+t^3$. Then we have $$s\mid g'-s^3+s^2t\implies s\mid t^3$$Since $gcd(s,t)=1$ we have $s=\pm1$. Again $$t\mid g'-t^3+s^2t\implies t\mid s^3\implies t=\pm1$$Hence we have $a=\pm 1$. But $1$ or $-1$ both of them are  not  root of $g(w)$. Therefore both $ab-1$ and $a+b^2-1$ can not be both zero. \parinn\vspace*{5mm}

Therefore none of cases is possible. Hence contradiction. Such $a,b$ does not exist. Therefore $x,y,z$ are linearly independent. 
}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
}{p5% problem reference text
}
Show that the set of real numbers $\mathbb{R}$ with standard operations forms a vector space over the field of rationals $\mathbb{Q}$. This is an example of an infinite-dimensional vector space, as we shall now see in two different ways.
\begin{itemize}
	\item Show that for any $k>0$ and any primes $p_1, \ldots, p_k$, the real numbers $\log p_1, \ldots, \log p_k$ are linearly independent over $\mathbb{Q}$.
	\item Show that for any $k>0$ there is a one-to-one function mapping $\mathbb{Q}^k$ to $\mathbb{Q}$.
\end{itemize}

For both of the above, why do we get that $\mathbb{R}$ forms an infinite-dimensional vector space over $\mathbb{Q}$ ?
\end{problem}
\solve{
	First we will prove $\bbR$ forms a vector space over $\bbQ$. We already know $(\bbR,+)$ is an abelian group. So we only need to show that it follows the multiplication and distributivity property.
	\begin{itemize}
		\item \textbf{Multiplication:} For any $\alpha\in\bbQ$ , $x\in \bbR$, $\alpha\in\bbQ\implies \alpha\in\bbR$. Hence $\alpha x\in \bbR$ as multiplication of two reals is real. So if $\alpha =1$ then $$1\cdot x=x$$ and for any $\alpha,\beta\in\bbQ\implies \alpha,\beta\in\bbR$ we have $$\alpha(\beta x)=\alpha\beta x=(\alpha\cdot\beta)x$$Therefore it follows the multiplication property.
		\item \textbf{Distributivity:} For all $x,y\in \bbR$ and $\alpha\in \bbQ$ we have $\alpha(x+y)=\alpha x+\alpha y$ as $\alpha\in\bbQ\implies \alpha\in\bbR$ and $\bbR$ follows the distributive property. Similarly for any $\alpha,\beta\in \bbQ\implies \alpha,\beta\in\bbR$ and $x\in \bbR$ we have $(\alpha+\beta)x=\alpha x+\beta x$. Hence $\bbR$ follows the distributive property over $\bbQ$. 
	\end{itemize}
	Therefore $\lt(\bbR,+,\cdot\rt)$ follows all the properties of a vector space over $\bbQ$. . Hence $\bbR$ is indeed a vector space over $\bbQ$.
	
	Now we will see two different ways to prove that $\bbR$ is an infinite-dimensional vector space over $\bbQ$. 
	\begin{itemize}	
		
		\item For any $k>0$ consider the function $f_k:\bbQ^k\to \bbQ$ where for any $(q_1,\dots, q_k)\in\bbQ$. Let $n_i$ denote the $i^{th}$ prime number. Let $q_i=\frac{a_i}{b_i}$ where $a_i\in\bbZ$, $b_i\in\bbN$, $b_i\neq 0$ and $gcd(a_i,b_i)=1$. Then we define the map $$f_k(q_1,\dots, q_k)=\prod_{i=1}^k n_{2i-1}^{a_i}n_{2i}^{b_i}$$We have to show that this map is injective. Supose $f(p_1,\dots,p_k)=f(q_1,\dots, q_k)$. Let $p_i=\frac{a_i}{b_i}$ and $q_i=\frac{c_i}{d_i} $ with $a_i,b_i,c_i,d_i\in\bbZ$ with $b_i,d_i\neq 0$ for all $i\in[k]$ and $gcd(a_i,b_i)=1=gcd(c_i,d_i)$. Now \begin{align*}
			f(p_1,\dots,p_k)=f(q_1,\dots, q_k) & \iff \prod_{i=1}^k n_{2i-1}^{a_i}n_{2i}^{b_i}=\prod_{i=1}^k n_{2i-1}^{c_i}n_{2i}^{d_i}\\
			& \iff \prod_{i=1}^k n_{2i-1}^{a_i-c_i}n_{2i}^{b_i-d_i}=1
		\end{align*}Hence we are getting product of some integral powers of first $k$ primes is 1. This is not possible unless all the powers are zero because primes doesn't divide each other. So unless the powers are zero there is no way canceling prime power by a bunch of other prime powers. But if all the prime powers are zero then we have $a_i-c_i=0\iff a_i=c_i$ and $b_i-d_i=0\iff b_i=d_i$ for all $i\in[k]$. This means $p_i=q_i$ for all $i\in[k]$. Hence $f_k$ is injective. Therefore $f_k$ is injective for all $k\in \bbN$. Therefore there is an injective function for all $k>0$ mapping $\bbQ^k$ to $\bbQ$. 
	\vspace*{2mm}
	
	\textbf{Proof of $\boldsymbol{\bbR}$ is Infinite-Dimensional over $\boldsymbol{\bbQ}$:} First we will show that any $n-$dimensional vector space over $\bbQ$ is isomorphic to $\bbQ^n$. Then if $\bbR$ is finite dimensional then $R\cong \bbQ^n$ for some $n\in\bbN$. Then we will argue that by the above theorem we have an one-one function from $f:\bbR\to \bbQ$. Then we will show this is not possible.\parinn
	
	\begin{lemma}\label{vtoqiso}
		If $V$ is  a $n-$dimensional vector space $V$ over $\bbQ$ then $V\cong \bbQ^n$.
	\end{lemma}
\begin{proof}
	Let $B=\{b_1,\dots,b_n\}$ be a basis of $V$. Now we take the standard basis  $B_Q=\{v_1,\dots,v_n\}$ for $\bbQ^n$ where $v_i$ has $1$ in the $i^{th}$ place and  $0's$ in the rest of the positions. Then we know there is unique $\theta\in L(V,\bbQ^n)$ such that $\theta(b_i)=v_i$ for all $i\in[n]$. We will show that this $\theta$ is a bijection also.
	
	 Let $x,y\in V$ such that $\theta(x)=\theta(y)$. Now $\exs\ x_i\in \bbQ$ for all $i\in[n]$ not all zero such that  $x=\sum\limits_{i=1}^nx_ib_i$ and $\exs \ y_i\in\bbQ$ not all zero such that $y=\sum\limits_{i=1}^ny_ib_i$. Now $$\theta(x)=\theta(y)\iff \theta\lt(\sum\limits_{i=1}^nx_ib_i\rt)=\theta\lt(\sum\limits_{i=1}^ny_ib_i\rt)\implies \sum\limits_{i=1}^nx_i\theta(b_i)=\sum\limits_{i=1}^ny_i\theta(b_i)\iff \sum\limits_{i=1}^nx_iv_i=\sum\limits_{i=1}^ny_iv_i$$Hence we have $\sum\limits_{i=1}^n (x_i-y_i)v_i=0$. Since $v_i's $ are linearly independent we have $x_i-y_i=0\implies x_i=y_i$ for all $i\in[n]$. Therefore $x=y$. Hence $\theta$ is injective.
	 
	 Now we will prove $\theta$ is surjective. Let $w\in \bbQ^n$. Then there exists $w_1,\dots w_n\in \bbQ$ not all zero such that $w=\sum\limits_{i=1}^n w_iv_i$. Then consider the vector $u=\sum\limits_{i=1}^nw_ib_i\in V$. Then $$\theta(u)=\theta\lt(\sum\limits_{i=1}^nw_ib_i\rt)=\sum_{i=1}^n w_i\theta(b_i)=\sum_{i=1}^nw_iv_i=w$$Hence for all $w\in \bbQ^n$ there exists some $u\in V$ such that $\theta(u)=w$. Therefore $\theta$ is surjective. 
	 
	 Therefore we get $\theta$ is a linear map which is both injective and surjective. Hence $\theta$ is bijective linear map. Therefore $\theta$ is an isomorphism between $V$ and $\bbQ^n$. Hence $V\cong \bbQ^n$.
\end{proof}

\begin{lemma}\label{qtozinj}
	There is an injective function from $\bbQ$ to $\bbZ$. 
\end{lemma}
\begin{proof}
	Let $\bbQ_+$ denote the set of all positive rational numbers. Then suppose we have an injective function from $f:\bbQ_+\to\bbN$ then consider the function $\phi:\bbQ\to \bbZ$ such that $$\phi(q)=\begin{cases}
		f(q) & \text{when $q>0$}\\
		0 & \text{when $q=0$}\\
		-f(q) & \text{when $q<0$}
	\end{cases}$$Then $\phi$ gives an injective function from $\bbQ\to \bbZ$ if $f$ is injective. 

Therefore now we will construct $f$. Now for any positive rational number $q=\frac{a}{b}$ we will assume $a,b$ are in lowest form i.e. $a,b\in\bbN$, $b\neq 0$ and $gcd(a,b)=1$. So whenever we write $q=\frac{a}{b}$ that means it is in the lowest form. Now for any $q=\frac{a}{b}\in\bbQ_+$ consider the value $a+b$. Take $d=a+b-1\implies d\in\bbN$. We say the rational number $q$ is in the $d^{th}$ diagonal if $q=\frac{a}{b}$ and $a+b=d+1$ or we say the point $(a,b)$ is in the $d^{th}$ diagonal if $a+b=d+1$. Since we are only thinking of positive rational numbers there are finitely many pairs $(x,y)$ where $x,y\in\bbN$ such that $x+y=d$. Hence there are finitely many positive rational numbers $q$ such that the sum of the values of numerator and denominator of $q$ in its lowest form is $d+1$. 

Now an ordered pair $(x,y)$ is in the $d^{th}$ diagonal if $0\leq x\leq d$ and we can write $y=d+1-x$. So $(x,d+1-x)$ for all $x\in[d]$ are in the $d^{th}$ diagonal. So there are $d$ many ordered pairs in the $d^{th}$ diagonal. Hence at most $d$ many rationals can be on the $d^{th}$ diagonal. So we introduce a sequence of numbers $\{T(n)\}_{n\geq 1}$ where $$T(n)=\#\text{ordered pairs in any of the first $n$ diagonals}=\sum_{d=1}^nd=\frac{n(n+1)}2$$Now $T(n)$ as a function from $\bbN\to \bbN$ is it is an injective function. So with this we define $f:\bbQ_+\to\bbN$. For any $q\in\bbQ_+$ with $q=\frac{a}{b}$ $$f(q)=T((a+b-1)-1)+a$$Basically the ordered pair $(a,b)$ is in the $d=(a+b-1)^{th}$ diagonal. So by $(a+b-1)-1$ we exhaust all the ordered pairs which are in any of the first $d-1$ diagonals. After that we go to the $d^{th}$ diagonal and there the $a^{th}$ point is the ordered pair $(a,b)$. That is why we first count all the points in any of the first $(d-1)$ diagonals and after that we count how many steps we need to go to the $a^{th}$ point which is $a$.

 We claim this is an injective function. So suppose $f(q)=f(p)$ for some $p,q\in\bbQ_+$, $ p\neq q$. Let $q=\frac{a}{b}$ and $p=\frac{s}{t}$ in their lowest forms. We have $$f(q)=T(a+b-2)+a=T(s+t-2)+c=f(p)$$Now it will not be the case that $a+b=s+t$ because if it is then that implies $(a,b)$ and $(s,t)$ are in same diagonal and then $f(p)=f(q)\implies a=s\implies b=t\implies p=q$ which is not possible. So $a+b\neq s+t$. WLOG $a+b>s+t$. Then $(a+b)\geq (s+t)+1$. Now $$T(n+1)-T(n)=\frac{(n+1)(n+2)}2-\frac{n(n+1)}2=n+1$$ Since $a+b>s+t\implies a+b-2\geq (s+t-2)+1$ we have $$T(a+b-2)\geq T(s+t-2)+[(s+t-2)+1]=T(s+t-2)+s+t-1$$Therefore $$f(p)=T(s+t-2)+s< T(s+t-2)+(s+t-1)+1<T(a+b-2)+1\leq T(a+b-2)+a=f(q)$$The last inequality is because $a\geq 1$. Therefore $f(p)<f(q)$ but that is not possible since we have $f(p)=f(q)$. Hence contradiction. If $p\neq q $ then $f(p)\neq f(q)$ for all $p,q\in\bbQ_+$. Hence $f$ is injective. And therefore $\phi$ is also injective. Hence there is an injective function from $\bbQ$ to $\bbZ$.
\end{proof}
\begin{lemma}\label{ztoninj}
	There is an injective function from $\bbZ$ to $\bbN\cup \{0\}$. 
\end{lemma}
\begin{proof}
	Consider the function $\tau:\bbZ\to \bbN\cup\{0\}$ such that for any $k\in\bbZ$ $$\tau(k)=\begin{cases}
		0&\text{when $k=0$}\\
		2k & \text{when $k>0$}\\
		2|k|-1 & \text{when $k<0$}
	\end{cases}$$To prove this is an injective function let $\exs$ $m,n\in \bbZ$, $m\neq n$ suppose $\tau(m)=\tau(n)$. Let $\tau(m)$ is even. Then $\tau(n)$ is even. Then $$\tau(m)=2m=2n=\tau(n)\iff m=n$$ This is not possible. So suppose $\tau(m)$ is odd. Hence $\tau(n)$ is odd and $m,n<0$. So $$\tau(m)=-2m+1=-2n+1=\tau(n)\iff m=n$$This is not possible. But there are no other options possible. Hence contradiction. Therefore $\tau$ is an injective function.
\end{proof}
\begin{lemma}\label{n0toninj}
	There is an injective function from $\bbN\cup\{0\}$ to $\bbN$
\end{lemma}
\begin{proof}
	Consider the function $\sg:\bbN\cup\{0\}\to \bbN$ where for any $k\in \bbN\cup \{0\}$, $\sg(k)=k+1$. Clearly this is an injecive function since we are just shifting the value by 1. Hence $\sg$ is an injective function from $\bbN\cup\{0\}$ to $\bbN$. 
\end{proof}

Hence for any $n-$dimensional vector space $V$ over $\bbQ$ there is an isomorphism $\psi$ between $V$ and $\bbQ^n$ by \lemref{vtoqiso}. Then we know that there is an injective function $f_n:\bbQ^n\to\bbQ$. Then using \lemref{qtozinj} we have that there is an injective function $\phi:\bbQ\to \bbZ$. Using \lemref{ztoninj} we have that  there is an injective function $\tau:\bbZ\to\bbN\cup\{0\}$. And then using \lemref{n0toninj} we have an injective function $\sg:\bbN\cup\{0\}\to \bbN$. Hence we have an  function $\zeta_n=\sg\circ\tau\circ\phi\circ f_n\circ \psi$ where $\zeta_n:V\to \bbN$ is an injective function. Therefore for any $n-$dimensional vector space $V$ over $\bbQ$ there is an injective function $\zeta_n:V\to \bbN$.  So if $\bbR$ is a finite dimensional vector space over $\bbQ$ then there is an injective function $\zeta:\bbR\to\bbN$.  So to prove that $\bbR$ is infinite dimensional over $\bbQ$ we will prove that such an injective function can not exist.
\begin{lemma}
	There is no injective function $f:\bbR\to\bbN$
\end{lemma}
\begin{proof}
	Suppose  there is an injective function $f:\bbR\to\bbN$. Hence we can also say there is a surjective map $g$ from $\bbN$ to $\bbR$ because we can simply define $g$ like this: $$g(n)=\begin{cases}
		x& \text{If $\exs\ x\in\bbR$ such that $f(x)=n$}\\
		0 & \text{otherwise}
	\end{cases}$$This $g$ is a surjective function because for all $x\in\bbR$, $f(n)\in\bbN$. Hence for all $x\in \bbR$, $g(f(x))=x$. 

So now consider set of all the real numbers in the $[0,1]$ interval with all its digits are $0$ or $1$. Denote this set to be $S$. Hence $\forall\ x\in S$, $f(x)\in \bbN$. So  we can give an order $\prec$ to $S$ in the following way: for any $x,y\in S$ $$x\prec y\iff f(x)<f(y)$$Therefore we can say $f(S)$ forms an increasing sequence in $\bbN$. Let $\{n_k\}_{k\geq 1}$ is the sequence such that $\forall\ x\in S$, $\exs! k\in\bbN$ such that $g(n_k)=x$ and $i<j\iff n_i<n_j\iff g(n_i)\prec g(n_j)$. Now we will construct an element of $y\in S$. Let for any $x\in S$, $x(n)$ denote the $n^{th}$ digit of $x$ after the decimal point. So we define $y$ like the following $$y(k)=1-g(n_k)(k)$$Certainly since $\forall\ x\in S$ for all $n\in \bbN$, $x(n)\in\{0,1\}$ we have $\forall\ k\in\bbN$, $y(k)\in\{0,1\}$. Therefore $y\in S$. But forall $k\in \bbN$ $g(n_k)\neq y$ since $y$ and $g(n_k)$ differs in at least at the $k^{th}$ digit after the decimal point. Hence $\not\exs\ k\in\bbN$ such that $g(n_k)=y$. That means $\exs\ y\in S$ such that $\not\exs \ n\in\bbN$ so that $g(n)=y$. Hence $g$ is not surjective map. But we showed that if there an injective map $f:\bbR\to\bbN$ then there is an surjective map $g:\bbN\to \bbR$. Hence contradiction. There is no injective map from $\bbR$ to $\bbN$.
\end{proof}
With this lemma we get there is no injective function $f:\bbR\to\bbN$. Therefore $\bbR$ can not be a finite dimensional vector space over $\bbQ$ because otherwise there will be an injective map from $\bbR\to \bbN$. Hence $\bbR$ is an infinite dimensional vector space over $\bbQ$.
	\end{itemize}

}

\end{document}
