\documentclass[a4paper, 11pt]{article}
\usepackage{comment} % enables the use of multi-line comments (\ifx \fi) 
\usepackage{fullpage} % changes the margin
\usepackage[a4paper, total={7in, 10in}]{geometry}
\usepackage{amsmath,mathtools,mathdots,amssymb}
\usepackage{amssymb,amsthm}  % assumes amsmath package installed
\usepackage{float}
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage[shortlabels]{enumitem}
\usepackage{indentfirst}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=magenta,      
	urlcolor=blue!70!red,
	pdftitle={Assignment}, %%%%%%%%%%%%%%%%   WRITE ASSIGNMENT PDF NAME  %%%%%%%%%%%%%%%%%%%%
}
\usepackage[most,many,breakable]{tcolorbox}
\usepackage{tikz}
\usetikzlibrary{quantikz2}
\usetikzlibrary{decorations.pathreplacing,angles,quotes,patterns}
\usetikzlibrary{decorations.shapes}
\usepackage{caption}
%\usepackage{mathpazo}
\usepackage{mathpazo}
\usepackage{libertine}

\definecolor{mytheorembg}{HTML}{F2F2F9}
\definecolor{mytheoremfr}{HTML}{00007B}


\tcbuselibrary{theorems,skins,hooks}
\newtcbtheorem{problem}{Problem}
{%
	enhanced,
	breakable,
	colback = mytheorembg,
	frame hidden,
	boxrule = 0sp,
	borderline west = {2pt}{0pt}{mytheoremfr},
	sharp corners,
	detach title,
	before upper = \tcbtitle\par\smallskip,
	coltitle = mytheoremfr,
	fonttitle = \bfseries\sffamily,
	description font = \mdseries,
	separator sign none,
	segmentation style={solid, mytheoremfr},
}
{p}

\newtheorem{lemma}{Lemma}
\renewenvironment{proof}{\noindent{\it \textbf{Proof:}}\hspace*{1em}}{\qed\bigskip\\}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{physics}
% To give references for any problem use like this
% suppose the problem number is p3 then 2 options either 
% \hyperref[p:p3]{<text you want to use to hyperlink> \ref{p:p3}}
%                  or directly 
%                   \ref{p:p3}

\tikzset{decorate sep/.style 2 args=
	{decorate,decoration={shape backgrounds,shape=circle,shape size=#1,shape sep=#2}}}

\input{letterfonts}

\input{macros}

\setlength{\parindent}{0pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
\textsf{\noindent \large\textbf{Soham Chatterjee} \hfill \textbf{Assignment - 1}\\
	Email: \href{sohamc@cmi.ac.in}{sohamc@cmi.ac.in} \hfill Roll: BMC202175\\
	\normalsize Course: Quantum Algorithmic Thinking \hfill Date: October 20, 2023}
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
\begin{problem}{%problem statement
	}{p1% problem reference text
	}
Find the eigenvectors, eigenvalues, and diagonal representations of the Pauli matrices.		
%Problem		
\end{problem}
	
\solve{
	%Solution
	Pauli matrices are $$I=\mat{1&0\\ 0&1}\quad \sg_x=\mat{0&1\\ 1&0}\quad \sg_y=\mat{0& i \\ -i& 0}\quad \sg_z=\mat{1&0\\ 0&-1}$$ For $I$ for all vectors $v$ $Iv=v$. S0 every vector is an eigenvector and its eigenvalue is 1. Since $I$ is already in its diagonal representation $I$'s diagonal representation is $I$ itself.
	
	Since $\sg_x\mat{1\\0}=\mat{0\\1}$ and $\sg_x\mat{0\\1}=\mat{1\\ 0}$ we have 
	$$\sg_x\lt(\mat{1\\ 0}+\mat{0\\ 1}\rt)=\mat{0\\ 1}+\mat{1\\ 0}\quad \sg_x\lt(\mat{1\\ 0} -\mat{0\\ 1}\rt)=\mat{0\\ 1}-\mat{1\\ 0}=-\lt(\mat{1\\ 0}-\mat{0\\ 1}\rt)$$So the for the eignevalue $1$ the corresponding eignevector is $\mat{1\\ 0}+\mat{0\\ 1}$ and for the eigenvalue $-1$ the corresponding eigenvalue is $\mat{1\\ 0}-\mat{0\\ 1}$.
	
	Since $\sg_y\mat{1\\ 0}=\mat{0\\ -i}$ and $\sg_y\mat{0\\ 1}=\mat{i\\ 0}$ we have 
	$$\sg_y\lt(\mat{1\\ 0}+i\mat{0\\ 1}\rt)=\mat{0\\ -i}+i\mat{i\\ 0} = -1\lt(i\mat{0\\ 1}+\mat{1\\ 0}\rt)\quad \sg_y\lt(\mat{1\\ 0} -i\mat{0\\ 1}\rt)=\mat{0\\ -i}-i\mat{i\\ 0}=-i\mat{0\\ 1}+\mat{1\\ 0}$$So the for the eignevalue $1$ the corresponding eignevector is $\mat{1\\ 0} -i\mat{0\\ 1}$ and for the eigenvalue $-1$ the corresponding eigenvalue is $\mat{1\\ 0}+i\mat{0\\ 1}$.
	
	Since $\sg_z\mat{1\\ 0}=\mat{1\\ 0}$ and $\sg_y\mat{0\\ 1}=-\mat{0\\ 1}$. So the for the eignevalue $1$ the corresponding eignevector is $\mat{1\\ 0}$ and for the eigenvalue $-1$ the corresponding eigenvalue is $\mat{0\\ 1}$.
	
	Now $\sg_x,\sg_y,\sg_z$ has eigenvalues 1 and -1. So if we write in their corresponding eigenbasis then we will obtain the same diagonalized matrices where all the eigenvalues are in the diagonal positions i.e. $\mat{1 &0\\ 0& -1}$
}
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
	}{p2% problem reference text
	}
	Show that a normal matrix is Hermitian if and only if it has real eigenvalues. Show that a positive operator is necessarily Hermitian.
	%Problem		
\end{problem}

\solve{
	%Solution
	\begin{itemize}
		\item Let $A$ is normal and it is hermitian. Then $A=A^{\dagger}$. Let $v$ be an eigenvector of $A$ with eigenvalue $\lm$.  Then $v^{\dagger}Av=v^{\dagger}\lm v=\lm |v|^2$. Also $v^{\dagger}Av=v^{\dagger}A^{\dagger}v=(Av)^{\dagger} v=\lm^{\dagger}v^{\dagger}v=\lm^{\dagger} |v|^2$. So we have $\lm=\lm^{\dagger}$. Which implies $\lm$ is real. Hence all eigenvalues of $A$ are real. \parinn
	
	For the opposite direction we need some lemmas.
	\parinf
	
	\begin{lemma}
		The product of two unitary matrices is unitary
	\end{lemma}
	
	\begin{proof}
		 Let $U,V$ are two unitary matrices then $(UV)^{\dagger}=V^{\dagger} U^{\dagger}$. Now $(UV)(UV)^{\dagger}=U(VV^{\dagger}U^{\dagger})=UIU^{\dagger}=I$. 
	\end{proof}
	
	\begin{lemma}
		If $A$ is any square complex matrix then there is an upper triangular complex matrix $T$ and a unitary matrix $U$ so that $A=UTU^{\dagger}$
	\end{lemma}
	
	 \begin{proof}
	 	Let $A$ is a $n\times n$ matrix. Let $v_1$ be a eigenvector of $A$ with the corresponding eigenvalue $\lm_1$. We can take $x_1$ to be of unit length. Now by Gram-Schmidt process  we can extend $x_1$ to an orthonormal basis $\{x_1,v_2,\dots,v_n\}$; Let $S_0=\mat{x_1 & v_2 & \cdots & v_n}$  then $S_0$ is unitary and $$S_0^{\dagger}AS_0=\mat{\lm_1 & * \\ 0 & A_1}$$ where $A_1$ is an $(n-1)\times (n-1)$ matrix.  Again suppose $x_2$ is an eigenvector of $A_1$ and the corresponding eigenvalue is $\lm_2$. Then again for $A_1$ we extend $x_2$ to an orthonormal basis $\{x_2,\tdv_2,\dots, \tdv_{n-1}\}$ and take $\hat{S}_1=\mat{x_2,\tdv_2,\cdots, \tdv_{n-1}}$ then $S_1$ is also unitary and we have $\hat{S}_1^{\dagger}A_1\hat{S}_1=\mat{\lm_2 & * \\ 0 & A_2}$ where $A_2$ is a $(n-2)\times (n-2)$ matrix.  So we take $S_1=S_0\mat{1 & 0\\ 0 & \hat{S}_1}$. Then $$S_1^{\dagger} AS_1=\mat{\lm_1 & * & *\\ 0 & \lm_2 & *\\ 0 & 0& A_2}$$We continue like this  letting $S_k=S_{k-1}\mat{I_k & 0 \\ 0 & \hat{S}_{k}}$ thus at the end we obtain $U\coloneqq S_n$ such that $U^{\dagger}AU=T$ which is an upper triangular matrix. Hence we have $A=UTU^{\dagger}$
	 \end{proof}
	
\begin{lemma}\label{normdiag}
	 A matrix $A$ is diagonalizable with a unitary matrix if and only if $A$ is normal
\end{lemma}
	
	\begin{proof}
		 Let $A$ is normal. Then by Lemma 2 there  is a unitary matrix $U$ and a upper traingular matrix $T$ such that $A=UTU^{\dagger}$. Then \begin{multline*}
		TT^{\dagger}=U^{\dagger}AU(U^{\dagger}AU)^{\dagger}=U^{\dagger}AUU^{\dagger} A^{\dagger} U	=U^{\dagger}A A^{\dagger} U\\
	=U^{\dagger} A^{\dagger}A U=U^{\dagger} A^{\dagger}UU^{\dagger}A U=(U^{\dagger}AU)^{\dagger}U^{\dagger}AU=T^{\dagger}T
	\end{multline*}Now let $T=(t_{i,j})_{1\leq i,j\leq n}$. Then the first diagonal entry of $TT^{\dagger}$ is $$\sum_{i=1}^n  t_{1,i} \overline{t_{1,i}}=\sum_{i=1}^n |t_{1,i}|^2$$ Now the first diagonal entry of $T^{\dagger}T$ is $t_{1,1}\ov{t_{1,1}}=|t_{1,1}|^2$. These two are equal. Hence for all $2\leq i\leq n$ we have $t_{1,i}=0$. Similarly comparing the second diagonal entry of $TT^{\dagger} $ and $T^{\dagger}T$ we have that all the nondiagonal entries of second row of $T$ is 0.  Continuing like this we have that $T$ is diagonal. 
	\end{proof}
	
\item Suppose that $A$ is any matrix such that there exists an unitary matrix $U$ such that  $U^{\dagger}AU=D$ where $D$ is diagonal. Then \begin{multline*}
		AA^{\dagger}=UDU^{\dagger}(UDU^{\dagger})^{\dagger}=UDU^{\dagger}UD^{\dagger}U^{\dagger}=UDD^{\dagger}U^{\dagger}\\
		=UD^{\dagger}DU^{\dagger}=UD^{\dagger}U^{\dagger}UDU^{\dagger}=(UDU^{\dagger})^{\dagger}UDU^{\dagger}=A^{\dagger}A
	\end{multline*}So $A$ is normal.
	
	
	\parinn
	
	Now coming back to the original question we have that the eigenvalues of $A$ are real. $A$ is normal. Then  there exists an unitary matrix $U$ such that  $U^{\dagger}AU=D$ where $D$ is diagonal. Since all eigenvalues of $A$ are real $D^{\dagger}=D$. Then we have $$A^{\dagger}=(U^{\dagger}DU)^{\dagger}=U^{\dagger}D^{\dagger}U=U^{\dagger}DU=A$$So $A$ is hermitian
	
	\vspace{5mm}
	
	Now suppose $A$ is positive operator. Then for all $v\in V$ we have $$v^{\dagger}Av\geq 0\implies v^{\dagger}Av= (v^{\dagger}Av)^{\dagger}=v^{\dagger}A^{\dagger}v\geq 0\implies v^{\dagger}(A-A^{\dagger})v=0$$Now also we have \begin{multline*}
		(A-A^{\dagger})(A-A^{\dagger})^{\dagger}=(A-A^{\dagger})(A^{\dagger}-A)=AA^{\dagger}-A^{\dagger}A^{\dagger}-AA+A^{\dagger}A\\
		=(A^{\dagger}-A)(A-A^{\dagger})=(A-A^{\dagger})^{\dagger}(A-A^{\dagger})
	\end{multline*}So $A-A^{\dagger}$ is a normal operator. Hence by Lemma 3 there exists an unitary matrix $U$ such that $U^{\dagger}(A-A^{\dagger})U=D$ where $D$ is a diagonal matrix. Now for standard basis for any $e_i$ $$e_i^{\dagger}De_i=e^{\dagger}U^{\dagger}(A-A^{\dagger})Ue_i=(Ue_i)^{\dagger}(A-A^{\dagger})(Ue_i)= 0$$ Now $e_i^{\dagger}De_i$ is the $i$-th diagonal element of $D$ which we got is 0. Since this is true for all $i\in [n]$ we have $D$ is a null matrix. So $$U^{\dagger}(A-A^{\dagger})U=0\iff A-A^{\dagger}=U0U^{\dagger}=0\iff A=A^{\dagger}$$Hence $A$ is hermitian.
	\end{itemize}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
	}{p1% problem reference text
	}
	Suppose that $A$ and $B$ are Hermitian operators. Then show that the commutator $[A, B] = 0$ if and only if there exists an orthonormal basis such that both $A$ and $B$ are diagonal with respect to that basis. 
	%Problem		
\end{problem}

\solve{
	%Solution
	If there exists an orthonormal basis such that both $A$ and $B$ are diagonal with respect to that basis then let we have $P^{\dagger}AP=D_A$ and $P^{\dagger}P-D_B$. Then $$AB-BA=PD_AP^{\dagger}PD_BP^{\dagger}-PD_BP^{\dagger}PD_AP^{\dagger}=PD_AD_BP^{\dagger}-PD_BD_AP^{\dagger}=P(D_AD_B-D_BD_A)P^{\dagger}=0$$The last equality comes because $D_A$ and $D_B$ are diagonal matrices so $D_AD_B=D_BD_A$. 
	
	For the opposite direction suppose $v$ be an eigenvector with corresponding eigenvector $\lm$ of $A$ then $Av=\lm v$. Now $$A(Bv)=BAv=B\lm v=\lm Bv$$Hence for any eigenvector $v$ of $A$ $Bv$ is also an eigenvector and if $Bv$ is zero then still it is an eigenvector of $A$ for same eigenvalue. 
	
	Let $\lm_1,\dots,\lm_k$ be the eigenvalues of $A$. Then the corresponding eigenspaces of $A$ are $V_{\lm_i}$ for $i\in [k]$. Then we have $B(V_{\lm_i})\subseteq V_{\lm_i}$ for all $i\in [k]$. Now let $\beta$ be an eigenvalue of $B$ with corresponding eigenvector is $y$. Then for any $i\in [k]$ we can think $y=y_1+y_2$ where $y_1\in V_{\lm_i}$ and and $y_2\in \bigoplus_{j\neq i}V_{\lm_j}$. Then $By=\beta y=\beta y_1+\beta y_2$. also we have $By=By_2+By_2$. Since $B(V_{\lm_i})\subseteq V_{\lm_i}$ and $B\lt( \bigoplus_{j\neq i}V_{\lm_j} \rt)\subseteq \bigoplus_{j\neq i}V_{\lm_j}$ we can say $By_1=\beta y_1$ and $By_2=\beta y_2$. Now if the $V_{\beta}$ is the corresponding eigenspace fo the eigenvalue $\beta$ then $$V_{\beta}=\lt[ V_{\beta}\cap V_{\lm_i}\rt]\oplus \lt[V_{\beta}\cap \bigoplus_{j\neq i}V_{\lm_j} \rt]=\bigoplus_{i=1}^kV_{\lm_i}\cap V_{\beta}$$Now if $\beta_1,\dots, \beta_l$ are the eigenvalues of $B$ then we have $$\bigoplus_{i=1}^lV_{\beta_i}=\bigoplus_{i=1}^l\lt(\bigoplus_{j=1}^k V_{\lm_j}\cap V_{\beta_i}\rt)=\bigoplus_{\substack{1\leq i\leq l\\ 1\leq j\leq k}}V_{\beta_i}\cap V_{\lm_j}$$Let us denote $V_{i,j}=V_{\beta_i}\cap V_{\lm_j}$ then for each $V_{i,j}$ we take an orthogonal basis for all $i,j$. Then taking union of all of them we have an orthogoanl basis for both $A$ and $B$ such that both $A$ and $B$ are diagonal. Now for each vector in the basis after normalizing we get an orthonormal basis  such that both $A$ and $B$ are diagonal with respect to that basis. 
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
	}{p1% problem reference text
	}
	Prove that a state $\ket{\psi}$ of a composite system $AB$ is a product state if and only if it has Schmidt number 1. Prove that $\ket{\psi}$ is a product state if and only if the reduced density matrices $\rho_A$ and $\rho_B$ are pure states. 
	%Problem		
\end{problem}

\solve{
	%Solution
	\begin{itemize}
		\item Let the $\ket{\psi}$ is a product state. Then $\exs\ \ket{\psi_1}\in A, \ket{\psi_2}\in B$ such that $\ket{\psi}=\ket{\psi_1}\ket{\psi_2}$. Now by Schmidt Decomposition there exists an orthonormal basis $\{\ket{i_A}\}$ for system $A$ and orthonormal basis $\{\ket{i_B}\}$ for system $B$ such that $$\ket{\psi}=\sum_{i=1}^n\lm_i\ket{i_A}\ket{i_B}$$ where $\lm_i\in \bbR$ such that $\sum_{i=1}^n\lm_i^2=1$. We have there exists at least one $\lm_i\neq 0$. WLOG $\lm_1\neq 0$  Now we also have $$\ket{\psi_1}=\sum_{i=1}^n \lm_{i,A}\ket{i_A}\qquad \ket{\psi_2}=\sum_{i=1}^n\lm_{i,B}\ket{i_B}$$then we have $$\sum_{i=1}^n\lm_i\ket{i_A}\ket{i_B}=\ket{\psi}=\lt(\sum_{i=1}^n\lm_{i,A}\ket{i_A}\rt)\lt(\sum_{i=1}^n\lm_{i,B}\ket{i_B}\rt)=\sum_{1\leq i,j\leq n}\lm_{i,A}\lm_{j,B}\ket{i_A}\ket{j_B}$$Comparing the coefficients we have $\lm_i=\lm_{i,A}\lm_{i,B}$ and for all $\lm_{i,A}\lm_{j,B}=0$ where $i\neq j$. Since $\lm_1\neq 0$ we have $\lm_{1,A},\lm_{1,B}\neq 0$. Since for all $j\neq 1$, $\lm_{1,A}\lm_{j,B}=0$ we have $\lm_{j,B}=0$ for all $2\leq j\leq n$. Similarly since for all $i\neq 1$, $\lm_{i,A}\lm_{1,B}=0$ we have $\lm_{i,A}=0$ for all $2\leq i\leq n$. So we have $\lm_i=0$ for all $2\leq i\leq n$. So $\ket{\psi}=\lm_1\ket{i_A}\ket{i_B}$. Hence $\ket{\psi}$ has Schmidt Number 1.
		\parinn
		
		For the opposite direction $\ket{\psi}$ has Schmidt Number 1. So $\ket{\psi}=\ket{i_A}\ket{i_B}$ Here are $\ket{i_A}$ is a state of system $A$ and $\ket{i_B}$ is a state of system $B$. Hence $\ket{\psi}$ is already in a product state. Hence $\ket{\psi}$ is a product state of the composite system $AB$.
		
		\item $\ket{\psi}$ is a product state. Hence it has Schmidt Number 1. So there exists an orthonormal basis $\{\ket{i_A}\}$ for system $A$ and orthonormal basis $\{\ket{i_B}\}$ for system $B$ such that $\ket{\psi}=\ket{i_A}\ket{i_B}$. Then $$\rho_{AB}=\ket{\psi}\bra{\psi}=\lt(\ket{i_A}\ket{i_B}\rt)\lt(\bra{i_A}\bra{i_B}\rt)=\ket{i_A}\bra{i_A}\otimes \ket{i_B}\bra{i_B}$$Now $$\rho_A=tr_B(\rho_{AB})=tr_B(\ket{i_A}\bra{i_A}\otimes \ket{i_B}\bra{i_B})=\ket{i_A}\bra{i_A}tr(\ket{i_B}\bra{i_B})=\ket{i_A}\bra{i_A}$$and similarly $$\rho_B=tr_A(\rho_{AB})=tr_A(\ket{i_A}\bra{i_A}\otimes \ket{i_B}\bra{i_B})=tr(\ket{i_A}\bra{i_A})\ket{i_A}\bra{i_B}=\ket{i_B}\bra{i_B}$$So $\rho_A$ and $\rho_B$ are pure states. \parinn
		
		Let $\rho_A$ and $\rho_B$ are pure states. Let $\ket{\psi}=\ket{\psi_1}\ket{\psi_2}$ Then $$\ket{\psi}\bra{\psi}=\lt(\sum_{i=1}^n \lm_i\ket{i_A}\ket{i_B}\rt)\lt( \sum_{j=1}^n\lm_j\bra{j_A}\bra{j_B}\rt)=\sum_{i=1}^n\lm_i^2\ket{i_A}\bra{i_A}\otimes \ket{i_B}\bra{i_B}$$There exists at least one $\lm_i\neq 0$. WLOG $\lm_1=\neq 0$. Now $$\rho_A=\tr_B\lt(\sum_{i=1}^n\lm_i^2\ket{i_A}\bra{i_A}\otimes \ket{i_B}\bra{i_B}  \rt)=\sum_{i=1}^n\lm_i^2\ket{i_A}\bra{i_A}tr(\ket{i_B}\bra{i_B})=\sum_{i=1}^n\lm_i^2\ket{i_A}\bra{i_A}$$and $$\rho_B=\tr_A\lt(\sum_{i=1}^n\lm_i^2\ket{i_A}\bra{i_A}\otimes \ket{i_B}\bra{i_B}  \rt)=\sum_{i=1}^n\lm_i^2tr(\ket{i_A}\bra{i_A})\ket{i_B}\bra{i_B}=\sum_{i=1}^n\lm_i^2\ket{i_B}\bra{i_B}$$Since $\rho_A$ and $\rho_B$ are pure states there exists $k,l\in [n]$ such that $\rho_A=\lm_k\ket{k_A}\bra{k_A}$ and $\rho_B=\lm_l\ket{l_B}\bra{l_B}$ since we already know that $\lm_1\neq 0$ we have $k=l=1$ for all $2\leq i\leq n$ $\lm_i=0$. So $\rho_A=\ket{1_A}\bra{1_A}$ and $\rho_B=\ket{1_A}\bra{1_B}$. Hence $\ket{\psi}=\lm_1\ket{1_A}\ket{1_B}$. So $\ket{\psi}$ has Schmidt Number 1. So $\ket{\psi}$ is a product state of the composite system $AB$.
	\end{itemize}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
	}{p1% problem reference text
	}
	Write a self-contained proof that single qubit gates and $CNOT$ gates are universal.
	%Problem		
\end{problem}

\solve{
	%Solution
	\begin{lemma}
		Let $U$ be an unitary matrix acting on $\bbC^d$. Then there are $N\leq \frac{d(d-1)}2$,  2-level unitary matrices i.e. unitary matrices which act on 2 or less dimensional subspaces $U_1,\dots, U_n$ such that $$U_NU_{N-1}\cdots U_2U_1U=I$$.
	\end{lemma}
	\begin{proof}
		We will prove this by induction. Let $d=3$. Then suppose $U=\mat{a & d & g\\ b & e & h\\ c & f & i}$. Then first take $$U_1=\mat{\frac{a^*}{|a|^2+|b|^2} & \frac{b^*}{|a|^2+|b|^2} & 0\\ \frac{b}{|a|^2+|b|^2} & \frac{-a}{|a|^2+|b|^2} & 0\\ 0 & 0 & 1}\implies U_1U=\mat{1 & d' & g'\\ 0 & e' & h'\\ c' & f' & i'}=\mat{a' & d' & g'\\ 0 & e' & h'\\ c' & f' & i'}$$Now we take $$U_2=\mat{\frac{a'^*}{|a'|^2+|c'|^2} & 0 & \frac{c'^*}{|a'|^2+|c'|^2} \\ 0 & 1 & 0\\ \frac{c'}{|a'|^2+|c'|^2} & 0 &  \frac{-a'}{|a'|^2+|c'|^2}}\implies U_2U_1U=\mat{1 & d'' & g''\\ 0 & e'' & h''\\ 0 & f'' & i''}$$Clearly $U_1$ and $U_2$ are unitary matrix. Hence $U_2U_1U$ is unitary matrix. Since $U_2U_1U$ is a unitary matrix and $(U_2U_1U)^{\dagger}=U_2U_1U$ we have $d''=g''=0$. Hence $$U_2U_1U=\mat{1 & 0 & 0\\ 0 & e'' & h''\\ 0 & f'' & i''}$$So we will take $$U_3=(U_2U_1U)^{\dagger}=\mat{1 & 0 & 0\\ 0 & e''^* & h''^*\\ 0 & f''^* & i''^*}$$Hence $U_3U_2U_1U=I\implies U=U_1^{\dagger}U_2^{\dagger}U_3^{\dagger}$. 
		
		Now suppose this statement is true for $d-1$. For $d$ like the above process we need $d-1$ unitary matrices to make the first entry of the first column 1 and the rest entries of the first column to be 0. Let the unitary matrices are $U_1,\dots, U_{d-1}$. So $U_{d-1}\cdots U_1U=\mat{1 & 0 \\ 0 & U'}$ where $U'$ is a $(d-1)\times (d-1)$ matrix. Since $U$ is unitary we have $U'$ is unitary. By induction hypothesis there exists $k\leq \frac{(d-1)(d-2)}2$ matrices $U_1',\dots, U_k'$ such that $U_k'\cdots U_1'U'=I_{d-1}$. Now $\forall \ i\in [k]$ we take the matrices $$\tdU_i=\mat{1& 0\\ 0 & U_i'}$$Then we have $$\lt( \tdU_k\cdots \tdU_1\rt)\lt( U_{d-1}\cdots U_1\rt)U=I_{d}$$ Now $$k+d-1\leq \frac{(d-1)(d-2)}2+d-1=\frac{d-1}2(d-2+2)=\frac{d(d-1)}2$$Hence there exists $N\leq \frac{d(d-1)}2$ unitary matrices $U_1,\dots , U_N$ such that $_N\cdots U_1U=I$.
	\end{proof}
	
	Now if $U$ is an unitary matrix acting on a $n-$qubit system then we can decompose $U$ into product of $2$-level unitary matrices using the previous lemma. So it is enought to see 2-level unitary matrices. Now denote $U$ to be a 2-level matrix on an $n$-qubit system. Suppose $U$ acts non-trivially on the space spanned by the computational basis $\{\ket{x},\ket{y}\}$. where $bin(x)=x_{n-1}\cdots x_0$ and $bin(y)=y_{n-1}\cdots y_0$ are the binar expressions for $x,y$ where $\forall\ i,j\in [n]$ we have $x_i, y_j\in \{0,1\}$. Let $U\ket{x}=a\ket{x}+b\ket{y}$ and $U\ket{y}=c\ket{x}+d\ket{y}$. Therefore $U$ is an $2^n\times 2^n$ matrix where $U$ has 1 in all diagonal positions and 0 in all off diagonal positions except $U_{xx}=a, U_{xy}=c, U_{yx}=b, U_{yy}=d$. Take $\tdU=\mat{a & c\\ b & d}$. Now we will try to reduce $U$ to $\tdU$ using single qubit gates and $CNOT$ gate. $\tdU$ can be thought of as a unitary matrix acting on a single qubit. 
	
	To reduce $U$ to $\tdU$ we first take s sequence of binary numbers $\{ a_1,\dots , a_m\}$ such that $a_1=x$ and $a_m=y$ and for any $i\in [m-1]$, $a_i, a_{i+1}$ differ in exactly one bit. Clearly $m\leq n+1$ since there are $n$ bits. Our main strategy is to find gates providing the sequence of state changes $$\ket{x}=\ket{x_1}\to \ket{x_2}\to \cdots \to \ket{x_{m-1}}$$ then $\ket{x_{m-1}}$ and $\ket{x_m}=\ket{y}$ differs in only one position and then apply $\tdU$ on that specific bit position and then undo the sequence so that $$\ket{x}=\ket{x_1}\leftarrow \ket{x_2}\leftarrow \cdots \leftarrow \ket{x_{m-1}}$$ Now to change the state $\ket{x_i}\to \ket{x_{i+1}}$ let $x_i=x_{i,n-1}\cdots x_{i,0}$ and the difference of $x_i$ and $x_{i+1}$ is at $j$th position. Then $$x_{i+1}=x_{i,n-1}\cdots x_{i,j+1}\ov{x_{i,j}}x_{i,j-1}\cdots x_{i,0}$$ Then we apply $C^{n-1}(X)$ on $j$th bit along  with sandwitching by $X$ gate at $l$th bit, $l\neq j$ if $x_{i,l}=0$. Thus $j$th bit is changed only if the other bits are equal to $\ket{x_i}$ state's bits in their respective positions. Lets denote the gate $C_i^n(X)$ for the change of state   $\ket{x_i}\to \ket{x_{i+1}}$. We apply this this for all $i\in [m-2]$ to finaly get $\ket{x_{m-1}}$
	
	Now let $x_{m-1}$ and $x_m=y$ differs in $k$th position. Let $x_{m-1}=x_{m-1,n-1}\cdots x_{m-1,0}$ then {$$x_m=x_{m-1,n-1}\cdots x_{m-1,k+1}\ov{x_{m-1,k}}x_{m-1,k-1}\cdots x_{m-1,0}$$} Then we apply $C^{n-1}(\tdU)$ where $\tdU$ is applied in $k$-th position along with sandwitching by $X$ gates if at $l$th bit, $l\neq k$ if $x_{m-1,l}=0$. Thus $\tdU$ is applied to $k$th bit only if the rest of the bits are equal to $x_{m-1,n-1},$ $\dots,$ $x_{m-1,k+1},$ $x_{m-1,k-1},$ $\dots,$ $x_{m-1,0}$ respectively. 
	
	\begin{lemma}
		For any unitary matrix $U$ there is an unitary matrix $V$ such that $V^2=U$.
	\end{lemma}
	\begin{proof}
		Since $UU^{\dagger}=I$ we also have $U^{\dagger}U=(UU^{\dagger})^{\dagger}=I^{\dagger}=I$. Hence unitary matrix is normal. Now by \lmref{normdiag} we know normal matrices are diagonalizable. So there is a unitary matrix $V$ such that $V^{\dagger}UV=D$ where $D$ is diagonal. Since all elements of $D$ are complex number for all diagonal element of $D$ there is a square root of that element. Hence we construct a new diagonal matrix $\tdD$ such that square of any diagonal element of $\tdD$ is the same element of $D$ of smae diagonal position. SO $\tdD\tdD=D$. Hence we take $\sqrt{U}=V\tdD V^{\dagger}$. Then $\sqrt{U}\sqrt{U}=V\tdD V^{\dagger}V\tdD V^{\dagger}=V\tdD\tdD V^{\dagger}=VDV^{\dagger}=U$. Hence such matrix exists
	\end{proof}
	
	\begin{lemma}
		For any unitary gate $U$ acting on a single qubit system $C^n(U)$ gate on a $n$ qubit system can be constructed by 3 $C^{n-1}(V)$ and 3 $C(W)$ gates where $V,W$ are unitary matrices. [I took this idea from \href{https://algassert.com/circuits/2015/06/22/Using-Quantum-Gates-instead-of-Ancilla-Bits.html}{algoassert.com}]
	\end{lemma}
	\begin{proof}
		We will prove drawing the circuit for $n=3$. 
	\begin{center}
			\begin{minipage}{0.14\textwidth}
			\begin{quantikz}
				 & \ctrl{3}   &  \\
				 & \control{} &  \\
				 & \control{} &  \\
				 & \gate{U}   &
			\end{quantikz}
	\end{minipage}
	\begin{minipage}{0.05\textwidth}
		$=$
	\end{minipage}
		\begin{minipage}{0.40\textwidth}
		\begin{quantikz}
			 & \ctrl{2}   &                           & \ctrl{2}   &                 & \ctrl{3}        &  \\
			 & \control{} &                           & \control{} &                 & \control{}      &  \\
			 & \targ{}    & \ctrl{1}                  & \targ{}    & \ctrl{1}        &                 &  \\
			 &            & \gate{\sqrt{U}^{\dagger}} &            & \gate{\sqrt{U}} & \gate{\sqrt{U}} &
		\end{quantikz}
	\end{minipage}
	\end{center}
	There are 4 cases arise: \begin{enumerate}
		\item \textbf{OFF, OFF}: If any of the first 2 states is  $\ket{0}$ and the 3rd state is $\ket{0}$ then no gate is applied on the 4th state. 
		\item \textbf{ON, OFF}: If first 2 states are $\ket{1}$ and the 3rd state is $\ket{0}$ then after the first $C^2(X)$ gate the 3rd state becomes $\ket{1}$ so the $\sqrt{U}^{\dagger}$ is applied  on 4th state and after the second $C^2(X)$ the 3rd state becomes $\ket{0}$ so only the last $\sqrt{U}$ is applied on 4th state. But we know $\sqrt{U}^{\dagger}\sqrt{U}=I$ so in the end nothing changes
		\item \textbf{ON, ON}: If first 2 states are $\ket{1}$ and 3rd state is $\ket{1}$ then after the first $C^2(X)$ gate the 3rd state becomes $\ket{0}$ so the $\sqrt{U}^{\dagger}$ is not applied  on 4th state and after the second $C^2(X)$ the 3rd state becomes $\ket{1}$ so both  the last two $\sqrt{U}$ gate are applied on 4th state. Since $\sqrt{U}\sqrt{U}=U$ we can say when all the first 3 states are $\ket{1}$ $U$ is applied to the 4th state.
		\item \textbf{OFF, ON}: If any of the first 2 states is $\ket{0}$ and the 3rd state is $\ket{1}$ then after the first $C^2(X)$ gate the 3rd state doesn't change so it remains $\ket{1}$ so the $\sqrt{U}^{\dagger}$ is  applied  on 4th state and after the second $C^2(X)$ the 3rd state still remains  $\ket{1}$ so the first $\sqrt{U}$ gate is applied but the last $\sqrt{U}$ iis not applied since at least one of the first 2 states is $\ket{0}$
	\end{enumerate}
	We will implement the same for any $n$. Here we are using 2 $C^{n-1}(X)$ gate one $C^{n-1}(\sqrt{U})$ gate and one $C(\sqrt{U})$ and one $C(\sqrt{U}^{\dagger})$ gate. So the lemma is true.
	\end{proof}
	
	With this lemma we can constuct a $C^n(U)$ gate using 2 $C^{n-1}(X)$ gate one $C^{n-1}(\sqrt{U})$ gate and one $C(\sqrt{U})$ and one $C(\sqrt{U}^{\dagger})$ gate. So applying this procedure again and again we can finally reach where we are using only $C(V)$ gates where $V$ is an unitary gate acting on a single qubit.
	
	Let $SU(n)$ define the set of all $n\times n$ unitary matrices with determinant 1. 
	\begin{lemma}
		$\forall\ U\in SU(2)$ there exists $a,b\in\bbC$ and $\theta \in \bbR$ with $|a|^2+|b|^2=1$  such that $$U=\mat{a & b\\ -b^*e^{i\theta} & a^*e^{i\theta}}$$
	\end{lemma}
	\begin{proof}
		Let $U=\mat{a & b\\ c & d}$. We know $U^{\dagger}=U^{-1}$. Now $$U^{-1}=\frac1{\det U}\mat{d & -b\\ -c & a} \qquad U^{\dagger}=\mat{a^* & c^*\\ b^* & d^*}$$So we have $$d=a^*\det U, a=d^*\det U, \text{ and } -b=c^*\det U$$So we have $d=d(\det U)^*\det U=d|\det U|$. So if $d\neq 0$ we have $|\det U|=1=(\det{U})^*\det U=\det U^{\dagger}\det U=\det (UU^{\dagger})$. So we can think $\det U=e^{i\theta}$ So we have $$d=a^* e^{i\theta}\qquad c=-b^*e^{i\theta}$$Hence $U=\mat{a & b\\ -b^*e^{i\theta} & a^*e^{i\theta}}$. Now $$\det U=aa^*e^{i\theta} +bb^*e^{i\theta}=e^{i\theta}(|a|^2+|b|^2)\implies |\det U|=1=|e^{i\theta}| (|a|^2+|b|^2)=|a|^2+|b|^2$$
	\end{proof}
	
	Now since $|a|^2+|b|^2=1$ so we can think $|a|=\sin \theta$ and $|b|=\cos \theta $. So $a=e^{i\lm}\sin \theta$ and $b=e^{i\mu}\cos \theta$. So $$U=\mat{e^{i\lm}\sin \theta & e^{i\mu}\cos\theta\\ -e^{i(\theta-\mu)}\cos\theta & e^{i(\theta-\lm)}}=e^{i\frac{\theta}2}\mat{e^{i(\lm-\frac{\theta}2)}\sin \theta & e^{i(\mu-\frac{\theta}2)}\cos\theta\\ -e^{-i(\mu-\frac{\theta}2)}\cos\theta & e^{-i(\lm-\frac{\theta}2)}\sin\theta}$$So we take $\alpha=\lm-\frac{\theta}2$ and $\beta=\mu-\frac{\theta}2$. Now introduce $\alpha=\phi+\psi$ and $\beta=\phi-\psi$. Then we have $$U=e^{i\frac{\theta}{2}} \mat{e^{i\phi} & 0 \\ 0 & e^{-i\phi}}\mat{\sin\theta & \cos\theta\\ -\cos\theta & \sin\theta}\mat{e^{i\psi} & 0 \\ 0 & e^{-i\psi}}$$Now for any $2\times 2$ matrix $A$ and for any element $x$ we have $xA=(xI)A$. So here we can take the multiplication of $e^{i\frac{\theta}{2}}$ as multiplication of the matrix $e^{i\frac{\theta}{2}}I=\Phi(\frac{\theta}2)$. To write in short we will take $\frac{\theta}2=\om$. So $\Phi(\frac{\theta}2)=\Phi(\om)$. Now for any angle $\gm$ we know $$R_z(\gm)=\mat{e^{i\frac{\gm}2} & 0 \\ 0 & e^{i\frac{\gm}{2}}}\qquad R_y(\gm)=\mat{ \cos \frac{\gm}2 & \sin\frac{\gm}2\\ -\sin \frac{\gm}2 & \cos \frac{\gm}2 }$$ Since $\cos\gm=\sin(\frac{\pi}2-\gm)$ we have $$R_z(2\phi)=\mat{e^{i\phi} & 0 \\ 0 & e^{-i\phi}}\quad R_y(\pi-2\theta)=\mat{ \cos \frac{\pi-2\theta}2 & \sin\frac{\pi-2\theta}2\\ -\sin \frac{\pi-2\theta}2 & \cos \frac{\pi-2\theta}2 }=\mat{\sin\theta & \cos\theta\\ -\cos\theta & \sin\theta} \quad R_z(2\psi)=\mat{e^{i\psi} & 0 \\ 0 & e^{-i\psi}}$$Hence $U=\Phi(\om)R_z(2\phi)R_y(\pi-2\theta)R_z(2\psi)$. Now we need to break $C(U)$ into single qubit gates and $CNOT$ gate. 
	\begin{lemma}
		Let $U\in SU(2)$ then there exists $A,B,C\in SU(2)$ such that $U=\Phi(\delta)AXBXC$ where $ABC=I$ and $X=\sg_x$ for some $\delta\in \bbR$
	\end{lemma}
	\begin{proof}
		By the previous construction there exists $\alpha,\beta,\gm,\delta\in \bbR$ such that $U=\Phi(\delta)R_z(\alpha)R_y(\beta)R_z(\gm)$. Now take $$A=R_z(\alpha)R_y\lt(\frac{\beta}{2}\rt),\quad B=R_y\lt(-\frac{\beta}{2}\rt)R_z\lt(-\frac{\alpha+\gm}2\rt), \quad C=R_z\lt(-\frac{\alpha-\gm}2\rt)$$ Then 
		\begin{align*}
			AXBXC & = R_z(\alpha)R_y\lt(\frac{\beta}2\rt)XR_y\lt(-\frac{\beta}2\rt)R_z\lt(-\frac{\alpha+\gm}2\rt) X R_z\lt(-\frac{\alpha-\gm}2\rt)                     \\
			      & = R_z(\alpha)R_y\lt(\frac{\beta}2\rt)\lt[XR_y\lt(-\frac{\beta}2\rt) X \rt]\lt[XR_z\lt(-\frac{\alpha+\gm}2\rt)X  \rt]R_z\lt(-\frac{\alpha-\gm}2\rt) \\
			      & = R_z(\alpha)R_y\lt(\frac{\beta}2\rt) R_y\lt(\frac{\beta}2\rt)R_z\lt(\frac{\alpha+\gm}2\rt)R_z\lt( -\frac{\alpha-\gm}2\rt)                       \\
			      & = R_z(\alpha)R_y(\beta)R_z(\gm)
		\end{align*}We also need to verify that $ABC=I$. For that $$ABC=R_z(\alpha)R_y\lt(\frac{\beta}2\rt)R_y\lt(-\frac{\beta}{2}\rt)R_z\lt(-\frac{\alpha+\gm}2\rt)R_z\lt(-\frac{\alpha-\gm}2\rt)=R_z(\alpha)R_y(0)R_z(-\alpha)=R_z(\alpha)R_z(-\alpha)=I$$
	\end{proof}
	
	We know if $U_1 $ and $U_2$ are two unitary gates acting on a single qubit  then $C(U_1U_2)=C(U_1)C(U_2)$. Hence $C(U)=C(\Phi(\delta))C(AXBXC)$. Now we can impliment $C(AXBXC)$ where $ABC=I$ like this 
	\begin{center}
		\begin{minipage}{0.2\textwidth}
			\begin{quantikz}
				& \ctrl{1}   &  \\
				& \gate{AXBXC}   &
			\end{quantikz}
		\end{minipage}
		\begin{minipage}{0.06\textwidth}
			$=$
		\end{minipage}
		\begin{minipage}{0.40\textwidth}
			\begin{quantikz}
				 &          & \ctrl{1} &          & \ctrl{1} &          &  \\
				 & \gate{C} & \targ{}  & \gate{B} & \targ{}  & \gate{A} &
			\end{quantikz}
		\end{minipage}
	\end{center}
	So if the control state is $\ket{0}$ then $ABC=I$ is applied on the 2nd state but nothing changes. If the control state is $\ket{1}$ then $AXBXC$ is applied on the 2nd state. Now we will try to simulate $C(\Phi(\delta))$.
	\begin{lemma}
		For any $\Phi(\delta)$ gate where $\delta\in \bbR)$ Take $$D=R_z(-\delta)\Phi\lt(\frac{\delta}2\rt)$$ then $C(\Phi(\delta))=D\otimes I$
	\end{lemma}
	\begin{proof}
		First simplify $D$. $$D=R_z(-\delta)\Phi\lt(\frac{\delta}2\rt)=\mat{e^{-i\frac{\delta}2} & 0 \\ 0 & e^{i\frac{\delta}2}}\mat{e^{i\frac{\delta}2} & 0 \\ 0 & e^{i\frac{\delta}2}}=\mat{1 & 0 \\ 0 & e^{i\delta}}$$Now we know $$C(U)=\ket{0}\bra{0}\otimes I + \ket{1}\bra{1}\otimes \Phi(\delta) =\ket{0}\bra{0}\otimes I+\ket{1}\bra{1}\otimes e^{i\delta}I=\ket{0}\bra{0}\otimes I+e^{i\delta}\ket{1}\bra{1}\otimes I$$Also $$D\otimes  I=\mat{1 & 0\\ 0 & e^{i\delta}}\otimes I=\lt[\ket{0}\bra{0}+e^{i\delta}\ket{1}\bra{1}\rt]\otimes I=\ket{0}\bra{0}\otimes I+e^{i\delta}\ket{1}\bra{1}\otimes I$$Hence we have $C(\delta)=D\otimes I$. 
	\end{proof}
	
	Therefore for $C(\Phi(\delta))$ it is enought to apply the $D$ gate to the control state. 	Hence for any $C(U)$ where $U\in SU(2)$ there exists $\delta\in \bbR$ and $A,B,C\in SU(2)$ such that $U=\Phi(\delta)AXBXC$ where $ABC=I$. Then let $D$ be the gate $D=R_z(-\delta)\Phi\lt(\frac{\delta}2\rt)$. Then we impliment $C(U)$ like this:
	\begin{center}
	\begin{minipage}{0.14\textwidth}
		\begin{quantikz}
			& \ctrl{1}   &  \\
			& \gate{U}   &
		\end{quantikz}
	\end{minipage}
	\begin{minipage}{0.06\textwidth}
		$=$
	\end{minipage}
	\begin{minipage}{0.40\textwidth}
		\begin{quantikz}
			 &          & \ctrl{1} &          & \ctrl{1} & \gate{D} &  \\
			 & \gate{C} & \targ{}  & \gate{B} & \targ{}  & \gate{A} &
		\end{quantikz}
	\end{minipage}
	\end{center}
	Now we have broken down $C(U)$ into single qubit gates and $CNOT$ gates. Therefore combining this full process we finally obtained that for any unitary gate operating on $n$ qubits can be broken down into single qubit gates and $CNOT$ gates. Hence single qubit gates and $CNOT$ gates are universal.
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 6
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
	}{p1% problem reference text
	}
	Let $S$ be a subspace of $\bbZ_2^n$. Define $S^{\perp}=\{t\in \bbZ_2^n\mid t\cdot s=0\text{ for all }s\in S\}$. Let $\ket{S}$ be the quantum stae that represents the uniform superposition over $S$. Compute the values of $H^{\otimes n}\ket{S}$ and $H^{\otimes n}\ket{y+S}$ for any $y\in \{0,1\}^n$.	
	%Problem		
\end{problem}

\solve{
	%Solution
	We have $\ket{S}=\frac{1}{\sqrt{|S|}}\sum\limits_{x\in S}\ket{x}$. Now since $S$ is a subspace of $\bbZ_2^n$ it has a basis. Let $\{x_1,\dots, x_k\}$ is a basis of $S$. Then $\forall\ x\in S$ $\exs\ a_i^x\in \{0,1\}$.for all $i\in [k]$ such that $\sum\limits_{i=1}^ka_i^xx_i=x$. So $|S|=2^k$. Now let $y\in \bbZ_2^n$. Then $\ket{S+y}=\frac1{\sqrt{|S|}}\sum\limits_{x\in S}\ket{x+y}$. So now\begin{align*}
		H^{\otimes n}\ket{S+y} & =\frac1{\sqrt{|S|}}\sum_{x\in S}H^{\otimes n}\ket{x+y}  =\frac1{\sqrt{|S|}}\sum_{x\in S}\lt[\sum_{i=0}^{2^n-1}(-1)^{\la x+y,i\ra}\ket{i}  \rt]                                                                              \\
		& =\frac1{\sqrt{|S|}}\sum_{x\in S}\lt[\sum_{i=0}^{2^n-1}(-1)^{\la y,i\ra}(-1)^{\la x,i\ra}\ket{i}  \rt] \\
		&  =\frac1{\sqrt{|S|}}\sum_{x\in S}\lt[\frac{1}{\sqrt{2^n}} \sum_{i=0}^{2^n-1}(-1)^{\la y,i\ra} (-1)^{\sum\limits_{j=1}^ka_j^x\la x_j,i\ra}\ket{i} \rt]                                                                        \\
		& =\frac1{\sqrt{2^n|S|}}\sum_{i=0}^{2^n-1}(-1)^{\la y,i\ra}\lt[ \sum_{x\in S}\prod_{j=1}^k(-1)^{a_j^x\la x_j,i\ra} \rt]\ket{i}                                                                                                \\
		& =\frac1{\sqrt{2^n|S|}}\sum_{i=0}^{2^n-1}(-1)^{\la y,i\ra}\lt[ \sum_{a_1=0}^1 \sum_{a_2=0}^1\cdots \sum_{a_k=0}^1 \lt(\prod_{j=1}^k(-1)^{a_j\la x_j,i\ra} \rt)\rt]\ket{i}                                                    \\
		& =\frac1{\sqrt{2^n|S|}}\sum_{i=0}^{2^n-1} (-1)^{\la y,i\ra}\lt[\prod_{j=1}^k \lt((-1)^{0\times \la x_j,i\ra}+(-1)^{1\times \la x_j,i\ra}\rt)  \rt]\ket{i}                                                                    \\
		& =\frac1{\sqrt{2^n|S|}}\sum_{i=0}^{2^n-1} (-1)^{\la y,i\ra}\lt[\prod_{j=1}^k \lt(1+(-1)^{ \la x_j,i\ra}\rt)  \rt]\ket{i}                                                                                                     \\
		& =\frac1{\sqrt{2^n|S|}}\sum_{x\in S^{\perp}}(-1)^{\la y,i\ra} \lt[ \prod_{j=1}^k (1+(-1)^0) \rt]\ket{x}                                                                                                                      \\
		& =\frac1{\sqrt{2^n|S|}}\sum_{x\in S^{\perp}}(-1)^{\la y,x\ra}2^k\ket{x}  =\frac{2^k}{\sqrt{2^n\times 2^k}}\sum_{x\in S^{\perp}}(-1)^{\la y,x\ra}\ket{x}=\frac1{\sqrt{2^{n-k}}}\sum_{x\in S^{\perp}}(-1)^{\la y,x\ra}\ket{x}
	\end{align*}
	Since for $H^{\otimes n}\ket{S}$ we have $y=(\underbrace{0,0,\dots, 0}_{n\text{ times}})=\ov{0}$ we have $$H^{\otimes n}\ket{S}=H^{\otimes n}\ket{S+\ov{0}}=\frac1{\sqrt{2^{n-k}}}\sum_{x\in S^{\perp}}(-1)^{\la \ov{0},x\ra}\ket{x}=\frac1{\sqrt{2^{n-k}}}\sum_{x\in S^{\perp}}\ket{x}=\ket{S^{\perp}}$$
	
}

	
\end{document}
