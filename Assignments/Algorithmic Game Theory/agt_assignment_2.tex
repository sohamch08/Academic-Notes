\documentclass[a4paper, 11pt]{article}
\usepackage{comment} % enables the use of multi-line comments (\ifx \fi) 
\usepackage{fullpage} % changes the margin
\usepackage[a4paper, total={7in, 10in}]{geometry}
\usepackage{amsmath,mathtools,mathdots,graphicx,adjustbox,xcolor}
\usepackage{amssymb,amsthm}  % assumes amsmath package installed
\usepackage{float}
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage[shortlabels]{enumitem}
\usepackage{indentfirst}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=doc!80,
	citecolor=myr,
	filecolor=myr,      
	urlcolor=doc!80,
	pdftitle={Assignment}, %%%%%%%%%%%%%%%%   WRITE ASSIGNMENT PDF NAME  %%%%%%%%%%%%%%%%%%%%
}
\usepackage[most,many,breakable]{tcolorbox}
\usepackage{tikz}
\usepackage{caption,complexity,bbm}
\newcommand{\cce}{\ensuremath{\mathsf{CCE}} }
\newcommand{\mne}{\ensuremath{\mathsf{MNE}} }
\newcommand{\pne}{\ensuremath{\mathsf{PNE}} }
%\usepackage{kpfonts}
%\usepackage{libertine}

%\usepackage[T1]{fontenc}
%\usepackage{baskervald}  % Baskerville-like font
%\usepackage[scaled]{beramono}  % Optional: better monospaced font
%\usepackage[utopia]{newtxmath} % Match with Utopia-like math


%\usepackage[T1]{fontenc}  % Ensure proper font encoding
%\usepackage{erewhon}      % Use Erewhon (Utopia-based) for text
%\usepackage[utopia]{newtxmath} % Use Utopia-compatible math fonts


\usepackage[T1]{fontenc}   % Proper font encoding
\usepackage{XCharter}      % XCharter for the main text
\usepackage[varqu,varl]{inconsolata} % Optional: Better monospaced font
\usepackage[charter]{newtxmath} % Use newtxmath with Charter-compatible math
\usepackage{optidef}


\usepackage{physics}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{mathrsfs}
\usepackage{tikz-cd}
\usepackage{float,marvosym}

\definecolor{mytheorembg}{HTML}{F2F2F9}
\definecolor{mytheoremfr}{HTML}{00007B}
\definecolor{doc}{RGB}{0,60,110}
\definecolor{myg}{RGB}{56, 140, 70}
\definecolor{myb}{RGB}{45, 111, 177}
\definecolor{myr}{RGB}{199, 68, 64}

\input{../assignment-problem-box}
\DeclareMathOperator{\nae}{NAE}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\renewenvironment{proof}{\noindent{\it \textbf{Proof:}}\hspace*{1em}}{\qed\bigskip\\}
% To give references for any problem use like this
% suppose the problem number is p3 then 2 options either 
% \hyperref[p:p3]{<text you want to use to hyperlink> \ref{p:p3}}
%                  or directly 
%                   \ref{p:p3}

\DeclareMathOperator{\trac}{\textsf{Trace}}
\DeclareMathOperator{\range}{Range}
\DeclareMathOperator{\mult}{Mult}
\DeclareMathOperator{\supp}{Supp}
\DeclareMathOperator{\opt}{OPT}
\DeclareMathOperator{\spn}{Span}


\input{../../letterfonts}

\input{../../macros}

\setlength{\parindent}{0pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\textsf{\noindent \large\textbf{Soham Chatterjee} \hfill \textbf{Assignment - 2}\\
		Email: \href{soham.chatterjee@tifr.res.in}{soham.chatterjee@tifr.res.in} \hfill Dept: STCS, TIFR\\
		\normalsize Course: Algorithmic Game  Theory \hfill Date: March 11, 2025}
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{%problem statement
		\hfill 10 Marks
	}{p1% problem reference text
}
Consider the bimatrix game $(A, B)$ where $A, B \in \mathbb{R}^{n \times n}$ and, further, $\operatorname{rank}(A)=\operatorname{rank}(B)=k$. Give an algorithm that computes a Nash equilibrium in this game in time poly $\left(n^{O(k)},|A|,|B|\right)$ where, as before, $|x|$ is the bit-complexity of $x$. You may need to use Caratheodory's theorem:

\begin{theorem}
	 Let $S=\left\{x_1, x_2, \ldots, x_n\right\}$ be a set of points in $\mathbb{R}^k$, and $y$ lie in the convex hull of $S$. Then there exists $\bar{S} \subseteq S$ of cardinality $k+1$, so that $y$ lies in the convex hull of the points in $\bar{S}$.
\end{theorem}
\end{problem}
\solve{	
Let $\Dl_i$ denote the set of mixed strategies for player $i$. Now since $\rank(R)=k$ the vector space $V\coloneqq \spn_{\bbR}\{Ry\mid y\in\Dl_2\}$ has dimension $k$. Therefore $V$ is isomorphic to $\bbR^k$. Suppose $f:V\to\bbR^k$ is the isomorphism. Let $R_i$ denote the $i^{th}$ row of $R$ for $i\in[n]$. Suppose $\tdR_i=f(R_i)$. Now for any $y$ the vector $Ry$ is basically the $y$-convex combination the rows $R_i$. Therefore $f(Ry)=\sum\limits_{i=1}^n y_i\tdR_i$. Now by Caratheodory's Theorem we get that $\exs\ S\subseteq \{\tdR_i\mid i\in[n]\}$with $|S|=k+1$ such that $f(Ry)$ is convex combination of $\{\tdR_i\mid i\in S\}$. Hence there exists a probability distribution $y'$ with $y_i'>0\iff i\in S$ such that  $f(Ry)$ is $y'$-convex combination of $\{\tdR_i\mid i\in S\}$ i.e. $$f(Ry)=\sum\limits_{i\in S}y_i'\tdR_i\iff Ry=\sum\limits_{i\in S} y_i'R_i$$Therefore we obtain a new strategy $y'$ for player 2 which is supported on at most $k+1$ pure strategies.  Instead of doing this process for all $\{R_i\mid i\in[n]\}$ whose $y$-convex sum is giving the value $Ry$ if we started with the set of vectors $\{R_i\mid i\in \supp(y)\}$ we would have gotten a $y'$ such that $\supp(y')\subseteq \supp(y)$ with $Ry'=Ry$. Hence we can assume that for any strategy $y\in\Dl_2$ there exists $y'\in \Dl_2$ such that $\supp(y')\subseteq \supp(y)$ and $|\supp(y')|\leq k+1$ with $Ry=Ry'$. Similarly we can also assume if player 1 plays any mixed strategy $x\in\Dl_1$ then by the above process on the rows of $C$ we obtain $x'\in\Dl_1$ such that $\supp(x')\subseteq \supp(x)$ and $|\supp(x')|\leq k+1$ with $C^Tx=C^Tx'$.

Now suppose $(x^*,y^*)$ is an \mne. Then $\exs\ \tdy^*\in\Dl_2$ such that $\supp(\tdy^*)\subseteq \supp(y^*)$ and $|\supp(\tdy^*)|\leq k+1$ with $Ry^*=R\tdy^*$. Now since $\supp(\tdy^*)\subseteq \supp(y^*)$, $\tdy^*$ is a best response to $x^*$. And since $Ry^*=R\tdy^*$ we have ${x^*}^T Ry^*={x^*}^TR\tdy^*$. Therefore $x^*$ is also best response to $\tdy^*$. Now by the same way from $(x^*,\tdy^*)$ we $\exs\ \tdx^*\in\Dl_1$ such that $\supp(\tdx^*)\subseteq \supp(x^*)$ and $|\supp(\tdx^*)|\leq k+1$ with $C^Tx^*=C^T\tdx^*$. Since $\supp(\tdx^*)\subseteq \supp(x^*)$, $\tdx^*$ is best response to $\tdy^*$. And since $C^Tx^*=C^T\tdx^*$ we have $\tdy^*C^Tx^*=\tdy^*C^T\tdx^*$. Therefore $\tdy^*$ is best response to $\tdx^*$. Therefore $(\tdx^*,\tdy^*)$ is also \mne. Therefore from $(x^*,y^*)$ we obtained an $(\tdx^*,\tdy^*)$ which is also an \mne but both of the strategies are supported on at most $k+1$ pure strategies. So we have the following algorithm:\parinf

\begin{enumerate}[label=(\arabic*):]
	\item Choose all possible $S_1,S_2\subseteq [n]$ with $|S_1|,|S_2|\leq k+1$.
	\item For each $(S_1,S_2)$ consider the matrices $A_{S_1,S_2}=(A(i,j))_{i\in S_1,j\in S_2}$ $B_{S_1,S_2}=(B(i,j))_{i\in S_1,j\in S_2}$. 
	\item Run the \textsc{Lemke-Howson Algorithm} on $(A_{S_1,S_2}, B_{S_1,S_2})$ find Nash Equilibrium $(x^*_{S_1,S_2},y^*_{S_1,S_2})$ in the reduced matrices
	\item For each $(S_1,S_2)$ check if $(x^*_{S_1,S_2},y^*_{S_1,S_2})$ satisfies the Nash Equilibrium conditions in the full game and if it satisfies return that strategy.
\end{enumerate}

The all possible choice of  $S_1,S_2\subseteq [n]$ with $|S_1|,|S_2|\leq k+1$ takes at most $2\sum\limits_{i=1}^{k+1}\binom{n}{i}\leq poly(n^{O(k)})$ time. Now each of the reduced matrices can also be computed in $poly(|A|,|B|)$. For each reduced matrix the \textsc{Lemke-Howson Algorithm} runs on $(K=1)\times (k+1)$ matrix. Therefore the algorithm takes at most $poly(k^{O(k)})$ time. Therefore the total running time is $poly(n^{O(k)},|A|,|B|)$.


}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage

\begin{problem}{%problem statement
	\hfill 10 Marks
	}{p2% problem reference text
	}
Recall the single-agent regret-minimization problem with $n$ pure strategies studied in class, for which we showed that the multiplicative weight algorithm with $\epsilon=\sqrt{\ln n / T}$ has regret $2 \sqrt{\ln n / T}$. Modify the algorithm to remove the assumption that $T$ is known to the algorithm, while maintaining a bound of $O(\sqrt{\ln n} / \sqrt{T})$ on the regret.
\end{problem}
\solve{	
Let $\mcA$ be the algorithm for single-agent no regret on input $T$ and the set of $n$ pure strategies gives a no-regret dynamics. So we will have the following algorithm which has no knowledge of $T$:

\begin{algorithm}[H]
	\DontPrintSemicolon
	\SetKwComment{Comment}{// }{}
\KwIn{A set $S$ of $n\geq 2$ actions}
\KwOut{No regret Dynamics}
\Begin{
	$i\longleftarrow0$\;
\While{True}{
	$i\longleftarrow i+1$\;
$t\longleftarrow 2^{i}$\;
$p^t\longleftarrow \mcA(t,S)$\;
\If{It is the end}{\Return{$p^t$}}
}
}
\caption{\textsc{Multiplicative Weight Without Knowing $T$}}
\end{algorithm}


Basically the algorithm has $\lt\lfloor \log T\rt\rfloor+1$ phases during $T$. In phase $k\geq 0$ it consists of steps $2^k,\dots,2^{k+1}-1$ steps i.e. total $2^k$ steps. At beginning of a phase we restart the no-regret algorithm with $t=2^k$. As the last phase may not be complete the algorithm is stopped in the last phase after the number of rounds is over. We will denote $p_{2^k}^t$ be the distribution at the $t^{th}$ iteration in the phase $k$. Now before we go into the calculation of the regret we have to first handle the case of the last phase where from $2^{\lfloor\log T\rfloor}$ to $2^{\lfloor\log T\rfloor+1}$, $T$ can be any value between them. And for all such $T$'s we are running the algorithm with the same $\epsilon=\sqrt{\frac{\ln n}{2^{\lfloor\log T\rfloor}}}$. We have to show that for all $T$ this choice of $\epsilon $ gives the same regret $O\lt(\sqrt{\frac{\ln n}{2^{\lfloor\log T\rfloor}}}\rt)$. 

\begin{lemma}
	For any $T$ for the above  algorithm  in the last phase $\mcA$ will run for $T-2^{\lfloor\log T\rfloor}$ many rounds  with the choice of 
	$\epsilon_1=\sqrt{\frac{\ln n}{2^{\lfloor\log T\rfloor}}}$ 
	instead of 
	$\epsilon_2=\sqrt{\frac{\ln n}{T-2^{\lfloor\log T\rfloor}}}$. 
	Let the regret for any $\epsilon $ is denoted $R_{\eps}$. Then $$R^{T-2^{\lfloor\log T\rfloor}}_{\eps_2}=\Theta\lt(R^{T-2^{\lfloor\log T\rfloor}}_{\eps_1}\rt)$$
\end{lemma}
\begin{proof}
	In the analysis of the algorithm $\mcA$ if it runs for $t$ rounds for any $\epsilon $ we have $$R_{\eps}^t\leq \frac1t\lt(\eps t+\frac1{\epsilon}\ln n\rt)\iff t\cdot R_{\eps}^t\leq \eps T+\frac1{\epsilon}\ln n$$So we will show that $$\eps_1\lt(T-2^{\lfloor\log T\rfloor}\rt)+\frac1{\eps_1}\ln n=\Theta\lt(\eps_2\lt(T-2^{\lfloor\log T\rfloor}\rt)+\frac1{\eps_2}\ln n\rt)$$
	Now\begin{align*}
	&	\eps_2\lt(T-2^{\lfloor\log T\rfloor}\rt)+\frac1{\eps_2}\ln n=\Theta\lt(\eps_1\lt(T-2^{\lfloor\log T\rfloor}\rt)+\frac1{\eps_1}\ln n\rt)\\
	\iff & \sqrt{\frac{\ln n}{T-2^{\lfloor\log T\rfloor}}}\lt(T-2^{\lfloor\log T\rfloor}\rt)+\frac1{\sqrt{\frac{\ln n}{T-2^{\lfloor\log T\rfloor}}}}\ln n=\Theta\lt(\sqrt{\frac{\ln n}{2^{\lfloor\log T\rfloor}}}\lt(T-2^{\lfloor\log T\rfloor}\rt)+\frac1{\sqrt{\frac{\ln n}{2^{\lfloor\log T\rfloor}}}}\ln n\rt)\\
	\iff & 2\sqrt{T-2^{\lfloor\log T\rfloor}}=\Theta\lt(  \frac1{\sqrt{2^{\lfloor\log T\rfloor}}} \lt(T-2^{\lfloor\log T\rfloor}\rt) +\sqrt{2^{\lfloor\log T\rfloor}}\rt)\\
	\iff & 2\sqrt{T-2^{\lfloor\log T\rfloor}}=\Theta\lt(  \frac{T}{\sqrt{2^{\lfloor\log T\rfloor}}} \rt)\\
	\iff & 4(T-2^{\lfloor\log T\rfloor})=\Theta\lt(\frac{T^2}{2^{\lfloor\log T\rfloor}}\rt)\\
	\iff & 4(T-2^{\lfloor\log T\rfloor})=\Theta (T)=\Theta\lt(\frac{T^2}{2^{\lfloor\log T\rfloor}}\rt)
	\end{align*}
Hence $R^{T-2^{\lfloor\log T\rfloor}}_{\eps_2}=\Theta\lt(R^{T-2^{\lfloor\log T\rfloor}}_{\eps_1}\rt)$
\end{proof}

Therefore the regret in the last phase can be at most $O\lt(\sqrt{\frac{\ln n}{T-2^{\lfloor \log T\rfloor}}}\rt)$. Suppose regret is at most $\dl\sqrt{\frac{\ln n}{T-2^{\lfloor \log T\rfloor}}}$ for some $\dl\in\bbN$, $\dl\geq 2$.  Therefore in the last phase we have $$\sum\limits_{t=0}^{2^m-1}\sum\limits_{a\in S}p_{2^{\lfloor \log T\rfloor}}^{t}(a)c^{t+2^m}(a)-\min_{a\in S}\sum_{t=0}^{2^{\lfloor \log T\rfloor}-1}c^{t+2^{\lfloor \log T\rfloor}}(a)\leq \dl\sqrt{\lt(T-2^{\lfloor \log T\rfloor}\rt)\ln n}\leq \dl\sqrt{2^{\lfloor \log T\rfloor}\ln n}$$Now for $k\in\{0,\dots, m-2\}$ by the analysis of $\mcA$ we know $$\sum\limits_{t=0}^{2^k-1}\sum\limits_{a\in S}p_{2^k}^{t}(a)c^{t+2^k}(a)-\min_{a\in S}\sum_{t=0}^{2^k-1}c^{t+2^k}(a)\leq 2\sqrt{2^k\ln n}\leq \dl\sqrt{2^k\ln n}$$Therefore we have $$\sum_{k=0}^{\lfloor \log T\rfloor} \sum\limits_{t=0}^{2^k-1}\sum\limits_{a\in S}p_{2^k}^{t}(a)c^{t+2^k}(a)-\sum_{k=0}^{\lfloor \log T\rfloor} \min_{a\in S}\sum_{t=0}^{2^k-1}c^{t+2^k}(a)\leq \sum_{k=0}^m \dl\sqrt{2^k\ln n}$$Now we have $$\sum_{k=0}^{\lfloor \log T\rfloor} \min_{a\in S}\sum_{t=0}^{2^k-1}c^{t+2^k}(a)\leq \min_{a\in S}\sum_{k=0}^{\lfloor \log T\rfloor} \sum_{t=0}^{2^k-1}c^{t+2^k}(a)$$Therefore we have \begin{align*}
	\sum_{k=0}^{\lfloor \log T\rfloor} \sum\limits_{t=0}^{2^k-1}\sum\limits_{a\in S}p_{2^k}^{t}(a)c^{t+2^k}(a)-\min_{a\in S}\sum_{k=0}^m \sum_{t=0}^{2^k-1}c^{t+2^k}(a) & \leq \sum_{k=0}^{\lfloor \log T\rfloor} \sum\limits_{t=0}^{2^k-1}\sum\limits_{a\in S}p_{2^k}^{t}(a)c^{t+2^k}(a)-\sum_{k=0}^{\lfloor \log T\rfloor} \min_{a\in S}\sum_{t=0}^{2^k-1}c^{t+2^k}(a) \\
	                                                                                                                                            & \leq \sum_{k=0}^{\lfloor \log T\rfloor} \dl\sqrt{2^k\ln n}= \dl\sqrt{\ln n}\sum_{k=0}^{\lfloor \log T\rfloor}\sqrt{2}^k                                                                                                            \\
	                                                                                                                                            & =\dl\sqrt{\ln n}\frac{(\sqrt{2})^{\lfloor \log T\rfloor+1}-1}{\sqrt{2}-1}=O(\sqrt{T\ln n})
\end{align*}
Hence $$\frac1T\lt[	\sum_{k=0}^m \sum\limits_{t=1}^{2^k-1}\sum\limits_{a\in S}p^{t+2^k}(a)c^{t+2^k}(a)-\min_{a\in S}\sum_{k=0}^m \sum_{t=1}^{2^k-1}c^{t+2^k}(a)\rt]\leq O\lt(\sqrt{\frac{\ln n}T}\rt)$$Therefore this algorithm gives the same external regret as the algorithm. Therefore this algorithm has no regret as $T\to\infty$.
}

%\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
		\hfill 10 Marks
	}{p3% problem reference text
	}
We saw in class that any deterministic regret-minimization algorithm, that selects a point distribution $p^t$ at each time $t$, has regret at least $1-1 / n$. Consider the deterministic regret-minimization algorithm that at each time $t$, selects the pure strategy that has least cumulative cost so far. That is, $p^t(a)=1$ for some $a \in \arg \min \sum\limits_{\tau \leq t} c^\tau(a)$. Show the regret of this algorithm (called "Follow-the-Leader") is at most
$$
\frac{(n-1) \mathrm{OPT}}{T}+\frac{n}{T}
$$
\end{problem}
\solve{
	Let $a_t$ denotes the action taken at time $t$. Let the actions are $a_1,\dots, a_n$. Therefore $a_t\in\arg\min\limits_{i\in[n]}\sum\limits_{\tau\leq t}c^{\tau}(a_i)$. Now total cost of the algorithm after $T$ time is $\sum\limits_{t=1}^T c^t(a_t)$. Let $t_i$ denote the last time when the algorithm choose the action $a_i$ for all $i\in[n]$. Let $c_i=\sum\limits_{t=1}^{t_i-1}c^t(a_i)$. Now $\opt=\min\limits_{i\in[n]}\sum\limits_{t=1}^Tc^t(a_i)$. If $a^*=\arg \min\limits_{i\in[n]}\sum\limits_{t=1}^Tc^t(a_i)$ then define $\opt_t=\sum\limits_{\tau\leq t-1}c^{\tau}(a^*)$.
	\begin{lemma}
		$c_i\leq \opt$ for all $i\in[n]$
	\end{lemma}
\begin{proof}
	For any $i\in[n]$ we have $c_i\leq \opt_{t_i}$ since $t_i$ is the last time the action $a_i$ was chosen by the algorithm and henceforth $a_i\in\arg\min\limits_{j\in[n]}\sum\limits_{\tau\leq t_i}c^{\tau}(a_j)$. Since $\opt_t\leq \opt$ for all $i\in[T]$ we have $c_i\leq \opt$. Since $i\in[n]$ is arbitrary we have the lemma.
\end{proof}
\begin{lemma}
	$\sum\limits_{t=1}^T c^t(a_t)\leq \sum\limits_{i=1}^n c_i+\sum\limits_{i=1}^n c^{t_i}(a_i)$.
\end{lemma}
\begin{proof}
	For $i\in[n]$ denote $d_i=\sum\limits_{\substack{t\leq T\\ a_t=a_i}}c^{\tau}(a_i)=\sum\limits_{\substack{t\leq t_i\\ a_t=a_i}}c^{\tau}(a_i)$. Then we have $\forall\ i\in[n]$, $d_i-c^{t_i}(a_i)\leq c_i$ since every summand in $d_i-c^{t_i}(a_i)$ i.e. every summand except the last element appears as a summand in $c_i$. Since $\sum\limits_{i\in[n]}d_i=\sum\limits_{t=1}^T c^t(a_t)$ we have $\sum\limits_{t=1}^T c^t(a_t)\leq \sum\limits_{i=1}^n c_i+\sum\limits_{i=1}^n c^{t_i}(a_i)$.
\end{proof}

Now since $c^t(a_i)\in[0,1]$ for all $i\in[n]$, for all $t\in[T]$. Therefore $$\sum\limits_{t=1}^T c^t(a_t)\leq n\opt+n\implies \sum\limits_{t=1}^T c^t(a_t)-\opt\leq (n-1)\opt+n\implies \frac1T\lt(\sum\limits_{t=1}^T c^t(a_t)-\opt\rt) \leq \frac{(n-1)\opt}T+\frac{n}T$$Hence the regret is at most 
$\frac{(n-1) \mathrm{OPT}}{T}+\frac{n}{T}$

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
\hfill 10 Marks
	}{p4% problem reference text
	}
Recall the value of a zero-sum game: this was the payoff for the row player in any Nash equilibrium of the game. Show that, in fact, this extends to \cce of zero-sum games as well: any \cce has the same payoff for the row-player.
\end{problem}
\solve{
	Suppose $(x^*,y^*)$ is an \mne in the zero sum game. And the payoff obtained by the player 1 is $w^*$. Now we have the lemma
\begin{lemma}
	Let $\mu$ is a \cce. And $\mu_1$ and $\mu_2$ are the marginals of $\mu$ for player 1 and player 2. Then $$\underset{s\sim \mu}{\bbE}[u_i(s)]=u_i(\mu_1,\mu_2)$$
\end{lemma}
\begin{proof}
	Suppose for some $i\in[2]$, $\underset{s\sim \mu}{\bbE}[u_i(s)]\neq u_i(\mu_1,\mu_2)$. So either $\underset{s\sim \mu}{\bbE}[u_i(s)]< u_i(\mu_1,\mu_2)$ or $\underset{s\sim \mu}{\bbE}[u_i(s)]> u_i(\mu_1,\mu_2)$. If $$\underset{s\sim \mu}{\bbE}[u_i(s)]> u_i(\mu_1,\mu_2)\implies -\underset{s\sim \mu}{\bbE}[u_i(s)]<- u_i(\mu_1,\mu_2)\implies \underset{s\sim \mu}{\bbE}[u_{3-i}(s)]<u_{3-i}(\mu_1,\mu_2)$$So it is reduced to the case that $\underset{s\sim \mu}{\bbE}[u_i(s)]< u_i(\mu_1,\mu_2)$. Now there exists $s_1\in S_1$ such that $u_i(\mu_1,\mu_2)\leq u_i(s_1,\mu_2)$. Then  $\exs \ s_1\in S_1$ such that $\underset{s\sim \mu}{\bbE}[u_i(s)]< u_i(s_1,\mu_2)$.  Hence it contradicts the fact that $\mu$ is an \cce. Which is not possible. Contradiction \ctr Therefore $\underset{s\sim \mu}{\bbE}[u_i(s)]=u_i(\mu_1,\mu_2)$.
\end{proof}
Since $(x^*,y^*)$ is an \mne we have $u_1(\mu_1,\mu_2)\leq u_1(x^*,y^*)=w^*\implies \underset{s\sim \mu}{\bbE}[u_1(s)]\leq w^*$. Now we also have $u_2(\mu_1,\mu_2)\leq u_2(x^*,y^*)=-w^*$. Therefore $$\underset{s\sim \mu}{\bbE}[u_2(s)]\leq -w^*\implies -\underset{s\sim \mu}{\bbE}[u_1(s)]\leq -w^*\implies \underset{s\sim \mu}{\bbE}[u_1(s)]\geq w^*$$Therefore we got $ \underset{s\sim \mu}{\bbE}[u_1(s)]=w^*$. Hence any \cce has the same payoff for the row-player.
}

%Therefore from the LP equation for \mne of the zero sum game we have that $\forall\ s_2 \in S_2$  $$({x^*}^TR)_{s_2}\geq w^*\implies $$ Now let $\mu$ is a \cce. Then for all $s_2'\in S_2$ $$\underset{s\sim \mu}{\bbE}[u_1(s)]\geq \underset{s\sim \mu}{\bbE}[u_1(s_1',s_2)]=\underset{s_2\sim \mu_2}{\bbE}[u_1(s_1',s_2)]=u_1(s_1',\mu_2)=-u_2(s_1',\mu_2)$$where $\mu_1$ is the marginal of $\mu$ for player 1.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
\hfill 5 Marks}{p5% problem reference text
	}
 In a 3-player zero sum game, for any pure strategy profile $s$, $\sum\limits_{i=1}^3 u_i(s)=0$. Either give an efficient algorithm for computing an \mne in a 3-player zero-sum game, or prove that computing a \mne in a 3-player zero-sum game is \PPAD-hard.
\end{problem}
\solve{
We will show a polynomial time reduction from \textsf{2NASH} to 3-player zero sum.  Suppose we have a bimatrix game $(R,C)$ where $R,C\in\bbR^{m\times n}$. Let $u_1$ and $u_2$ were the payoff functions of the bimatrix game. We construct a 3-player zero sum game  we add a new third player. Let the payoff functions in the new 3-player are $\tdu_i$ for $i\in[3]$. For the first player and the second player for any strategy profile $s=(s_1,s_2,s_3)$ becomes $$ u_i(s_1,s_2,s_3)=u_i(s_1,s_2)\ \forall\ i\in[2]$$ Now for any strategy profile $s=(s_1,s_2,s_3)$ the payoff for the third player given by $$u_3(s_1,s_2,s_3)=-u_1(s_1,s_2)-u_2(s_1,s_2)$$So we can think that the player 3 has only one strategy $S_3=\{s_3\}$. Hence the new game has payoff matrices $(A,B,C)$ where $A,B,C\in\bbR^{m\times n\times 1}$, where for any $s=(i,j,s_3)$, $i\in[m]$, $j\in[n]$ we have $$A(i,j,s_3)=R(i,j),\qquad B(i,j,s_3)=C(i,j)\qquad C(i,j,s_3)=-R(i,j)-C(i,j)$$game is indeed a 3-player zero sum game. And the reduction from the \textsf{2NASH} game is polynomial time. Since \textsf{2NASH} is \textsf{PPAD}-hard we can conclude that 3-player zero sum games are also  \textsf{PPAD}-hard.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 6
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
		\hfill 10 Marks}{p6% problem reference text
	}
Given a 2-player game $(R, C)$, prove that the following problems are either in \textsf{P} or are \textsf{NP}-complete:
\begin{itemize}
	\item Determine if there exists an $\mne\left(x^*, y^*\right)$ where both players play each pure strategy with positive probability (i.e., $x_i^*>0$ for all $i$, and $y_j^*>0$ for all $j$ ).
	\item Determine if there exists an $\mne\left(x^*, y^*\right)$ where $x_1^*=1$ (i.e., a given pure strategy is played with probability 1 ).
\end{itemize}

\end{problem}
\solve{In the following games we will assume that the row player has $m$ strategies and the column player has $n$ strategies.
\begin{itemize}
	\item Here we have to find an \mne $(x^*,y^*)$ with the property that $\sup(x^*)=[m]$ and $\supp(y^*)=[n]$ i.e. they have full support. Since their support size is full we have $(Ry^*)_k=\arg\max\limits_{i\in[m]}(Ry^*)_i$ for all $k\in[m]$. Hence $(Ry^*)_i=(Ry^*)_k$ for all $i,k\in[m]$. Similarly we have $(C^Tx^*)_j=(C^Tx^*)_l$ for all $j,l\in[n]$. Hence consider the following LP:
	
	\begin{maxi*}{}{0}{}{}
		\addConstraint{(Ry)_i=(Ry)_k}{}{\ \forall\ i,k\in[m]}
		\addConstraint{(C^Tx)_j=(C^Tx)_l}{}{\ \forall\ j,l\in[n]}
		\addConstraint{\sum\limits_{i=1}^mx_i=\sum\limits_{j=1}^ny_i=1}{}{}
		\addConstraint{x>  0,y> 0}
	\end{maxi*}

Any solution of the above LP will give a \mne with full support size. Since LP can be solved in polynomial time this problem is in \textsf{P}.
\item  Here we have to find an \mne $(x^*,y^*)$ with the property that $x^*_1=1$. That means the row player is playing the first pure strategy with  full probability. Since $y^*$ is the best response for $x^*$ we have $$\supp(y^*)\subseteq \arg\max\limits_{j\in[n]}C(1,j)$$So suppose $T=\arg\max\limits_{j\in[n]}C(1,j)$. Since $(x^*,y^*)$ is \mne we have to ensure that $1\in\arg\max\limits_{i\in[m]} (Ry^*)_i$. So consider the following LP:
	\begin{maxi*}{}{0}{}{}
	\addConstraint{}{(Ry)_1\geq (Ry)_i}{\ \forall\ i\in[m]}
	\addConstraint{}{y_j=0}{\ \forall\ j\notin T}
	\addConstraint{\sum\limits_{j\in T}y_j=1}{}{}
	\addConstraint{}{y\geq 0}{}
\end{maxi*}
Any solution of the above LP will give a \mne $(x^*,y^*)$ such that $x^*_1=1$ and the first constraint of LP will ensure $x^*$ is best response for $y^*$ and the second and third condition will ensure $\supp(y^*)\subseteq \arg\max\limits_{j\in[n]}C(1,j)$ i.e. $y^*$ is best response for $x^*$. Since LP can be solved in polynomial time this problem is in \textsf{P}.
\end{itemize}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Problem 7
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problem}{%problem statement
		\hfill 10 Marks}{p7% problem reference text
	}
Players 1 and 2 choose an element of the set $\{1, \cdots, K\}$. If the players choose the same number, then player 2 pays 1 rupee to player 1 ; otherwise no payment is made. Find all pure and mixed strategy Nash equilibrium of this game.
\end{problem}
\solve{
If both players chooses same number then player 2 pays 1 rupee to player 1 otherwise no payment is made. So consider the matrices $R,C\in\{0,1\}^{K\times K}$ where for any $i,j\in[K]$ $$R(i,j)=\begin{cases}
	1& \text{if }i=j\\ 0& \text{otherwise}
\end{cases}\qquad C(i,j)=\begin{cases}
-1& \text{if }i=j\\ 0& \text{otherwise}
\end{cases}$$
\begin{lemma}
	There is no \pne in the bimatrix game $(R,C)$
\end{lemma}
\begin{proof}
	Suppose there is a \pne. Let $(i,j)$ where $i,j\in[K]$ is the \pne. Now if $i=j$ then the payoff of the player 2 is $-1$. But player 2 could play $l\in[K]$, $l\neq i$ and get a pay-off of $0$. Hence this is not an equilibrium. So then $i\neq j$. But then the player 1 is getting a payoff $0$. But instead player $2$ could have played $j$ and gotten a pay-off of $1$.. Hence this also not a \pne. Therefore for al $(i,j)$ where $i,j\in[K]$, $(i,j)$ is not a \pne. But we assumed that there is a \pne. Hence contradiction \ctr So there is no \pne in the bimatrix game
\end{proof}

Since this is a finite game with each player having finitely many strategies. By Nash's theorem there exists a mixed nash equilibrium. 
\begin{lemma}
	Choosing all the numbers uniformly at random for both players is an \mne in the bimatrix game $(R,C)$.
\end{lemma}
\begin{proof}
	First we will show that $(x,y)$ where $x_i=y_j=\frac1K$ for all $i,j\in[K]$ is an \mne. Now in the matrix $R$ it has $1$'s on the diagonal and the rest of the entries are zero and similarly in $C$ it has $-1$'s on the diagonal and the rest of the entries are zero. Then $$Ry=\mat{\frac1K\\ \vdots\\ \frac1K}\qquad C^Tx=-\mat{\frac1K\\ \vdots\\ \frac1K}$$Therefore $\arg\max\limits_{i\in [K]}(Ry)_i=[K]$ and $\arg\max\limits_{j\in [K]}(C^Tx)_j=[K]$. Hence $x$ is indeed a best response to $y$ and $y$ is indeed best response to $x$. Therefore $(x,y)$ is an \mne.
\end{proof}
	
	Now we will show if $(x,y)$ is a mixed strategy of player 1 and 2 respectively. Then  for all $i,j\in[K]$. Now $Ry=y$ and $C^Tx=-x$ and the expected payoff $u_1(x,y)=\sum\limits_{i\in[K]}x_iy_i=-u_2(x,y)$. Since the game is zero sum the value of the game  is $=\min\limits_{y\in \Dl(K)}\max\limits_{i\in[K]}y_i$. Player 1 benefits when their probability distribution $x$ is concentrated where $y$ is highest. So in order to minimize the payoff of player 1, player 2 will try to minimize $\max\limits_{i\in [K]}y_i$. Now for any distribution $y\in \Dl(K)$, $\max\limits_{i\in[K]}y_i\geq \frac1K$. Hence $\max\limits_{i\in[k]}y_i=\frac1K$. Hence $y^*=\frac1K\mathbbm{1}$ where $\mathbbm{1}$ is the all $1$'s vector  minimizes the payoff of player 1 the most. So for any pure strategy $i\in[k]$ of player 1 the expected payoff is $u_1(i,y^*)=y_i^*=\frac1K=u_2(i,y^*)$. So every pure strategy gives the same payoff.
	
	Therefore if $x^*$ is best response to $y^*$ then $\supp(x^*)\subseteq [K]$. Now suppose $\supp(x^*)\subsetneq [K]$. Let $i,j\in [K]$, $i\neq j$ such that  $i\notin \supp(x^*)$ but $j\in \supp{x^*}$. Then $C^Tx^*=-x^*$. So $j\notin\arg\max\limits_{l\in[K]}-x^*_l$ as $-x^*_j<0$ and $-x^*_i=0$. Therefore the $y^*_j$ has to be $0$. But we know $y^*_j>0$. So $y^*$ is not best response to $x^*$. Therefore $\supp(x^*)=[K]$. Now again with the same logic since $C^Tx^*=-x^*$ and $y^*$ is best response of $x^*$ with $y_i^*>0$ for all $i\in[K]$ we have $x^*_i=x^*_j$ for all $i,j\in[K]$. Therefore $x^*=\frac1K\mathbbm{1}$. Therefore the only \mne is $(x^*,y^*)$ with $x_i^*=y_j^*=\frac1K$ for all $i,j\in[K]$.
}
\end{document}
