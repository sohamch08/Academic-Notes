\chapter{Combinatorics}
\section{Twelve Problems: {$n$} Balls in $m$ Bins}
\begin{Theorem}{}{}
	\begin{center}
		\begin{tabularx}{0.9\textwidth}{>{\raggedright}p{0.2\linewidth}|>{\centering\arraybackslash}m{0.2\linewidth} |>{\centering\arraybackslash}m{0.2\linewidth}|>{\centering\arraybackslash}m{0.2\linewidth}}
			& $\leq 1$ balls/bin $(m\geq n)$ & $\geq 1$ balls/bin $(m\leq n)$ & Unrestricted\\\hline
			Identical Balls, Identical Bins& 1 & $P(n,m)$ & $\sum\limits_{i=1}^mP(n,i)$\\[5mm]
			Identical Balls, Distinguishable Bins & $\displaystyle{\binom{m}{n}}$ & $\displaystyle{\binom{m-1}{n-1}}$ & $\displaystyle{\binom{n+m-1}{m-1}}$\\[5mm]
			Distinguishable Balls, Identical Bins & $1$ & $S_2(n,m)$ & $\sum\limits_{i=1}^mS_2(ni)$\\[5mm]
			Distinguishable Balls, Distinguishable Bins & $\displaystyle{\binom{m}{n}n!}$ & $S_2(n,m)m! $ & $m^n$
		\end{tabularx}
	\end{center}
\end{Theorem}
\begin{proof}
	
\end{proof}
\section{Stirling Numbers}
\subsection{Stirling Number of Second Kind}
\begin{Definition}{Stirling Number of The Second Kind}{}
	It is the number of ways to partition the set $[n]$ into $m$ nonempty parts. 
\end{Definition}

Clearly if we take the $n$ balls to be the set $[n]$ the balls become distinguishable and each partition is bin and the order order of the partition doesn't matter the bins are identical. So the it becomes the number of ways $n$ distinguishable balls divided into $m$ identical bins.

Now we will see some recursion relations of the Stirling number of the first kind. 

\begin{lemma}{}{s2recrel1}
	$S_2(n,m)=S_2(n-1,m-1)+mS_2(n-1,m)$
\end{lemma}
\begin{combi-proof}
	We have the balls $[n]$. Then there are two cases. The bin containing ball `1' can has only 1 ball or it can have $\geq 2$ balls. 
	
	For the first case the bin containing ball `1' has only one balls. So the rest of the $n-1$ balls are divided into the rest of the $m-1$ bins. The number of ways this is done is $S_2(n-1,m-1)$.
	
	For the second case the bin containing ball `1' has at least $2$ balls. In that case apart from the ball `1' all the other balls are filled into $m$ identical bins where each bin has at least $1$ ball. So we can think this scenario in other way that is first we fill bins with all the balls except `1' and then we choose where to put the ball `1'. So the number of ways the balls, $\{2,3,\dots, n\}$ i.e. $n-1$ distinguishable balls can be divided into $m$ bins is $S_2(n-1,m)$. Now there are $m$ choices for the ball `1' to be partnered up. Hence for this case there are $mS_2(n-1,m)$ many ways.
	
	Therefore the total number of ways the $n$ distinguishable balls can be divided into $m$ bins so that each bin has at least $1$ ball is $S_(n-1,m-1)+mS_2(n-1,m)$. Therefore we get $S_2(n,m)=S_2(n-1,m-1)+mS_2(n-1,m)$.
\end{combi-proof}

\begin{Theorem}{}{s2recrel2}
	$S_2(n+1,m+1)= \displaystyle\sum\limits_{i=m}^n  \binom{n}{i}  S_2(i,m)$
\end{Theorem}
\begin{combi-proof}
On the $LHS$ we are counting the number of ways to partition $[n+1]$ into $m+1$ parts. 

For the $RHS$ let's focus on the element $n+1$. So we drop the element from $[n+1]$ in the $(m+1)^{th}$ part. The $(m+1)^{th}$ block can have $k$ elements from $[n]$ which are partnered by $n+1$ where $0\leq k\leq n-m$. We have $k\leq n-m$ since all the other $m$ parts have at least 1 element that leaves us $n-m$ elements to choose. So there are $\binom{n}{k}$ ways to choose the $k$ elements. The remaining $n-k$ elements are divided into $m$ parts which can be done in $S_2(n-k,m)$ many choices. So in total we have $\sum\limits+{k=0}^{n-m}S_2(n-k,m)$ ways to divide $[n+1]$ into $m+1$ parts. Therefore we have $$S_2(n+1,m+1)=\sum\limits_{i=0}^{n-m}\binom{n}{i}S_2(n-i,m)=\sum\limits_{i=0}^{n-m}\binom{n}{n-i}S_2(n-i,m)=\sum\limits_{i=m}^{n}\binom{n}{i}S_2(i,m)$$
\end{combi-proof}
\begin{alg-proof}We will prove by Induction. 
	\begin{align*}
		& S_2(n+1,m+1)=\mathcolor{black}{S_2(n,m)}+\mathcolor{blue}{(m+1)S_2(n,m+1)} \\
		             =\ & \mathcolor{black}{\sum_{i=m-1}^{n-1}\binom{n-1}{i}S_2(i,m-1)} +\mathcolor{blue}{ (m+1)\sum_{j=m}^{n-1}\binom{n-1}{j}S_2(j,m)}\\
		             =\ & \mathcolor{black}{\sum_{i=m-1}^{n-1}\binom{n-1}{i}S_2(i,m-1)}+\mathcolor{red!80!black}{m\sum_{j=m}^{n-1}\binom{n-1}{j}S_2(j,m)}+\mathcolor{blue}{\sum_{j=m}^{n-1}\binom{n-1}{j}S_2(j,m)}\\
		             =\ & \sum_{i=m}^{n}\binom{n-1}{i-1}S_2(i-1,m-1)+\mathcolor{red!80!black}{m\sum_{j=m}^{n-1}\binom{n-1}{j}S_2(j,m)}+\mathcolor{blue}{\sum_{j=m}^{n-1}\binom{n-1}{j}S_2(j,m)}\\
		             =\ &  \sum_{i=m}^{n}\binom{n-1}{i-1}S_2(i-1,m-1) + \mathcolor{red!80!black}{m\sum_{j=m}^{n-1}\binom{n-1}{j}S_2(j,m)}+\mathcolor{blue}{\sum_{j=m}^{n-1}\lt[\binom{n}j-\binom{n-1}{j-1}\rt]S_2(j,m)}\\
		             =\ &  \sum_{i=m}^{n}\binom{n-1}{i-1}S_2(i-1,m-1) + \mathcolor{red!80!black}{m\sum_{j=m}^{n-1}\binom{n-1}{j}S_2(j,m)}+\mathcolor{blue}{\sum_{j=m}^{n-1}\binom{n}jS_2(j,m)}-\sum_{j=m}^{n-1}\binom{n-1}{j-1}S_2(j,m)\\
		             =\ &  \sum_{i=m}^{n}\binom{n-1}{i-1}S_2(i-1,m-1) + \mathcolor{red!80!black}{m\sum_{j=m}^{n-1}\binom{n-1}{j}S_2(j,m)}+\mathcolor{blue}{\sum_{j=m}^{n-1}\binom{n}jS_2(j,m)} {-\sum_{j=m}^{n-1}\binom{n-1}{j-1}\bigg[S_2(j-1,m-1)+mS_2(j-1,m)\bigg]}\\
		             =\ & S_2(n-1,m-1)+\cancel{ \sum_{i=m}^{n-1}\binom{n-1}{i-1}S_2(i-1,m-1)} + \mathcolor{red!80!black}{m\sum_{j=m}^{n-1}\binom{n-1}{j}S_2(j,m)}+\mathcolor{blue}{\sum_{j=m}^{n-1}\binom{n}jS_2(j,m)}-\cancel{\sum_{j=m}^{n-1}\binom{n-1}{j-1}S_2(j-1,m-1)}\\
		             & \hskip0.75\textwidth-\mathcolor{red!80!black}{m\sum_{j=m}^{n-1}\binom{n-1}{j-1}S_2(j-1,m)}\\
		             =\ &  S_2(n-1,m-1)+\mathcolor{red!80!black}{m\sum_{j=m}^{n-1}\binom{n-1}{j}S_2(j,m)} + \mathcolor{blue}{\sum_{j=m}^{n-1}\binom{n}jS_2(j,m)}-\mathcolor{red!80!black}{m\sum_{j=m+1}^{n-1}\binom{n-1}{j-1}S_2(j-1,m)}\\
		             =\ &  S_2(n-1,m-1) + \mathcolor{red!80!black}{m\sum_{j=m}^{n-1}\binom{n-1}{j}S_2(j,m)}+\mathcolor{blue}{\sum_{j=m}^{n-1}\binom{n}jS_2(j,m)}-\mathcolor{red!80!black}{m\sum_{j=m}^{n-2}\binom{n-1}{j}S_2(j,m)}\\
		             =\ &  S_2(n-1,m-1)+ {mS_2(n-1,m)}\mathcolor{blue}{\sum_{j=m}^{n-1}\binom{n}jS_2(j,m)}\\
		             =\ & S_2(n,m)+ \mathcolor{blue}{\sum_{j=m}^{n-1}\binom{n}jS_2(j,m)}= \sum_{j=m}^{n}\binom{n}jS_2(j,m)
	\end{align*}
\end{alg-proof}
\subsection{Stirling Number of First Kind}
\begin{Definition}{Stirling Number of The First Kind}{}
It is the number of permutations of $[n]$ with exactly $m$ cycles. The \textit{signed version} of Stirling number of the first kind is $(-1)^{n-m}S_1(n,m)$.
\end{Definition}
Now we will see some recursion relations of the Stirling number of the first kind. 
\begin{lemma}{}{s1recrel1}
	$S_1(n,m)=S_1(n-1,m-1)+(n-1)S_1(n-1,m)$
\end{lemma}
\begin{combi-proof}
	The $LHS$ is the number of permutations of $[n]$ into $m$ cycles by Definition. 
	
	In the $RHS$ we can break the permutations into two different kinds: permutations where $1\mapsto1$ and permutations where $1\not\mapsto 1$. For the permutations $1\mapsto1$ this alone forms a cycle. So the rest of the $n-1$ elements have to be permuted into $m-1$ cycles. Hence the number of such permutations is $S_1(n-1,m-1)$.
	
	For permutations where $1\not\mapsto 1$ take any permutation $\sg$. We will consider the permutation $\sg'$ on the elements $\{2,\dots, n\}$ where if $\sg(k)=1$ then $\sg'(k)=\sg\circ\sg(k)$ and otherwise for all $k\in \{2,\dots n\}$, $\sg'(k)=\sg(k)$. So $\sg'$ is now a permutation of $\{2,\dots, n\}$. For all such permutations where $1\not\mapsto 1$ we get a new unique permutation $\sg'$. So the number of cycles in $\sg$ is same as $\sg'$. Hence it is enough to for now count the number of permutations of $\{2,\dots,n\}$ into $m$ cycles  is $S_1(n-1,m)$. Now for any such permutation $\pi$ we can create new $n-1$ many permutations where $\forall\ i\in\{2,\dots, n\}$ where  $\pi_i(i)=1$, $\pi_i(1)=\pi(i)$. In this way for each permutation we get $n-1$ new permutations. Hence the number of permutations where $1\not\mapsto 1$ is $(n-1)S_2(n-1,m)$. 
	
	Hence total number of permutations of $[n]$ into $m$ cycles is $S_1(n-1,m-1)+(n-1)S_1(n-1,m)$. Therefore we get the lemma. 
\end{combi-proof}

\begin{lemma}{}{s1prop3}
	$S_1(n,m)\displaystyle\binom{m}{k}=\sum_{j=k}^{n+k-m}\binom{n}{j}S_1(j,k)S_1(n-j,m-k)$
\end{lemma}
\begin{combi-proof}
	In $LHS$, $S_1(n,m)$ is the number of permutations on $[n]$ with exactly $m$ cycles. Hence $S_1(n,m)\binom{m}{k}$ is the number of ways to choose $k$ cycles among the $m$ cycles from permutations on $[n]$ with exactly $m$ cycles. This is same as first constructing the chosen $k$ cycles with some elements of $[n]$ and then with the rest of elements construct the rest $m-k$ cycles.
	
	In $RHS$ first we select  $j$ elements for the $k$ cycles from $n$ in $\binom{n}{j}$ ways. Then for the chosen $j$ elements we create $k$ cycles in $S_1(j,k)$ ways. So the number of ways we can create $k$ cycles by $j$ elements from $[n]$ is $\binom{n}{j}S_1(j,k)$ ways. Now for the rest of the elements we create the rest $m-k$ cycles which we can do in $S_1(n-j,m-k)$. Therefore the number of ways to construct $k$ cycles and with the rest of the elements construct the remaining $m-k$ cycles with elements from $[n]$ is $\sum\limits_{j=k}^{n+k-m}\binom{n}{j}S_1(j,k)S_1(n-j,m-k)$. Therefore we have $$S_1(n,m)\displaystyle\binom{m}{k}=\sum_{j=k}^{n+k-m}\binom{n}{j}S_1(j,k)S_1(n-j,m-k)$$
\end{combi-proof}
\begin{Theorem}{}{}
	$S_1(n+1,m+1)=\displaystyle\sum_{j=m}^n\binom{j}{m}S_1(n,j)$.
\end{Theorem}
\begin{combi-proof}
Consider the permutations on $[n]$ which has at least $m$ cycles. So take a permutation $\sg$ which has $j$ cycles where $m\leq j\leq n$. So for any cycle consider the smallest element in that cycle to be the leading element. So let the permutation is $$\sigma=(a_1\ldots a_{\ell_1})(a_{\ell_1+1}\ldots a_{\ell_2})\ldots(a_{\ell_{j-1}+1}\ldots a_j)$$Now among these $j$ cycles we choose $m$ cycles in $\binom{j}{m}$ ways. Let the first $m$ cycles are chosen. Then we create the last $(m+1)^{th}$ cycle using the $n+1$ in the following way $$\matp{n+1 & a_{\ell_{m}}+1& \dots& a_{\ell_{m+1}}&a_{\ell_{m+1}}+1&\dots&a_j}$$Hence for each chosen set of $m$ cycles we can join the rest of the cycles and $n+1$ to get the $(m+1)^{th}$ cycle. So now the number of permutations on $[n]$ with $j$ cycles is $S_1(n,j)$. Then we can choose the $m$ cycles among $j$ cycles in $\binom{j}{m}$ ways. So the number of permutations on $[n+1]$ with $m+1$ cycles is $\sum\limits_{j=m}^n\binom{j}{m}S_1(n,j)$. Therefore we have $$S_1(n+1,m+1)=\displaystyle\sum_{j=m}^n\binom{j}{m}S_1(n,j)$$
\end{combi-proof}
\begin{alg-proof}
	First we will prove an identity of $S_1(n+1,m+1)$ then we will dive into the prove of this expression. We will show that  $S_1(n+1,m+1)=\sum\limits_{k=m}^n\frac{n!}{k!}S_1(k,m)$. We can use induction on $n+m+2$\begin{align*}
		S_1(n+1,m+1) & =S_1(n,m)+nS_1(n,m+1)                                          \\
		             & =S_1(n,m) +n\sum_{k=m}^{n-1}\frac{(n-1)!}{k!}S_1(k,m)          \\
		             & = \frac{n!}{n!}S_1(n,m) +\sum_{k=m}^{n-1}\frac{n!}{k!}S_1(k,m) \\
		             & =\sum_{k=m}^{n}\frac{n!}{k!}S_1(k,m)
	\end{align*}
	Now we will prove this inductively. 
	\begin{align*}
		\sum_{j-m}^n\binom{j}{m}S_1(n,j) & = \sum_{j=m}^n\sum_{k=m}^{n+m-j}\binom{n}{k}S_1(k,m)S_1(n-k,j-m) & [\text{Using \lmref{s1prop3}}]                                                                       \\
		                                 & = \sum_{k=m}^n\binom{n}{k}S_1(k,m)\sum_{j=m}^{n+m-k}S_1(n-k,j-m) &  \\
		                                 & = \sum_{k=m}^n\binom{n}{k}S_1(k,m)\sum_{j=0}^{n-k}S_1(n-k,j)     &  \\
		                                 & = \sum_{k=m}^n\binom{n}{k}S_1(k,m)(n-k)!                         & \lt[\text{Since $\displaystyle\sum_{j=0}^{n-k}S_1(n-k,j)$ is  number of permutations on $[n-k]$}\rt] \\
		                                 & \sum_{k=m}^n\frac{n!}{k!}S_1(k,m)                                &  \\
		                                 & = S_1(n+1,m+1)                                                   &
	\end{align*}

\end{alg-proof}

Now we will show you a property of the signed Stirling number of the first kind.
\begin{Theorem}{}{}
	$S_1(n,m)=\displaystyle\sum\limits_{i=m}^n(-1)^{i-m}\binom{i}{m}S_1(n+1,i+1)$
\end{Theorem}
\begin{proof}
	\begin{align*}
		\sum_{i=m}^n(-1)^{i-m}\binom{i}{m}S_1(n+1,i+1) & = (-1)^{i-m}\binom{i}{m}\sum_{j=i}^n\binom{j}{i}S_1(n,j)\\
		& = \sum_{j=m}^nS_1(n,j)\sum_{i=m}^j (-1)^{i-m}\binom{i}{m}\binom{j}{i}\\
		& = \sum_{j=m}^n S_1(n,j)\sum_{i=m}^j (-1)^{i-m}\binom{j}{m}\binom{j-m}{i-m}\\
		& = \sum_{j=m}^n \binom{j}{m}S_1(n,j)\sum_{i=0}^{j-m} (-1)^{i}\binom{j-m}{i}\\
		& = \sum_{j=m+1}^n \binom{j}{m}S_1(n,j)\underbrace{\sum_{i=0}^{j-m} (-1)^{i}\binom{j-m}{i}}_{=0}+\binom{m}{m}S_1(n,m)(-1)^0\binom{0}{0}\\
		& = S_1(n,m)
	\end{align*}
\end{proof}
\subsection{Connecting the Two Stirling Numbers}
\begin{Theorem}{}{}
	Let $S_1$ and $S_2$ be $k\times k$ matrix where for any $n,m\in [k]$ with $n\geq m$ we have $(S_1)_{n,m}=(-1)^{n-m}S_1(n,m)$ and $(S_2)_{n,m}=S_2(n,m)$ and $0$ otherwise then $S_1S_2=I$i.e. $$\displaystyle\sum\limits_{i=m}^n(-1)^{n-i}S_1(n,i)S_2(i,m)=\mathbbm{1}(n=m)$$
\end{Theorem}
\begin{proof}
We will induct on $n+m$. Then we have \begin{align*}
	\sum\limits_{i=m}^n(-1)^{n-i}S_1(n,i)S_2(i,m) & = \sum_{i=0}^{\infty} (-1)^{n-i}(S_1(n-1,i-1)+(n-1)S_1(n-1,i))S_2(i,m)\\
	& = \sum_{i=0}^{\infty} (-1)^{n-i}S_1(n-1,i-1)S_2(i,m)+ (n-1)\sum_{i=0}^{\infty} (-1)^{n-i}S_1(n-1,i)S_2(i,m)\\
	& = \sum_{i=0}^{\infty} (-1)^{n-i}S_1(n-1,i-1)[S_2(i-1,m-1)+mS_2(i-1,m)] - (n-1)\mathbbm{1}(n-1=m)\\
	& = \sum_{i=0}^{\infty} (-1)^{n-i}S_1(n-1,i-1)S_2(i-1,m-1)+m\sum_{i=0}^{\infty} (-1)^{n-i}S_1(n-1,i-1)S_2(i-1,m)\\
	& \hskip0.6\textwidth-(n-1)\mathbbm{1}(n-1=m)\\
	& = \mathbbm{1}(n=m)+m\mathbbm{1}(n-1=m)-(n-1)\mathbbm{1}(n-1=m)\\
	& =  \mathbbm{1}(n=m)+(m-n+1)\mathbbm{1}(n-1=m)= \mathbbm{1}(n=m)
\end{align*}
\end{proof}
\section{Inclusion Exclusion Principle}
\begin{Theorem}{Inclusion-Exclusion Principle}{}
	Let $A_1,\dots, A_n$ be finite sets. Then $$\lt|\bigcup_{i=1}^nA_i\rt|=\sum_{J\subseteq [n], J\neq\emptyset}(-1)^{|J|+1}\lt|\bigcap_{j\in J}A_j\rt|$$
\end{Theorem}
\begin{proof}
	We will prove this using induction on $n$.\begin{align*}
		\lt|\bigcup\limits_{i=1}^{n}A_i\rt| & = \lt|\bigcup_{i=1}^{n-1} A_i\rt|+  |A_{n}|-  \lt|\lt(\bigcup_{i=1}^{n-1} A_i \rt)\cap A_{n}\rt|                                                                                                                                                                                                  \\
		                                    & =  \mathcolor{red!80!black}{\lt|\bigcup\limits_{i=1}^{n-1}A_i\rt|}+|A_n|\mathcolor{blue!80!black}{-\lt|\bigcup_{i=1}^{n-1}(A_i\cap A_n)   \rt|                                                                                                                     }                                       \\
		                                    & = \mathcolor{red!80!black}{\sum_{J\subseteq [n-1],\; J\neq\emptyset}(-1)^{|J|+1}\lt|\bigcap_{j\in J}A_j\rt| }+|A_n|\mathcolor{blue!80!black}{-\sum_{J\subseteq[n-1],\; J\neq\emptyset} (-1)^{|J|+1}\lt|A_n\cap\lt(\bigcap_{j\in J}A_j\rt)\rt|    }                                                               \\
		                                    & =  \mathcolor{red!80!black}{\sum_{J\subseteq [n-1],\; J\neq\emptyset}(-1)^{|J|+1}\lt|\bigcap_{j\in J}A_j\rt| }+|A_n|\mathcolor{blue!80!black}{-\sum_{\substack{J\subseteq[n]\\ J\neq\{n\},\; n\in J}} (-1)^{|J|+1}\lt|A_n\cap\lt(\bigcap_{j\in J-\{n\}}A_j\rt)\rt|                     }                         \\
		                                    & = \mathcolor{red!80!black}{ \sum_{J\subseteq [n-1],\; J\neq\emptyset}(-1)^{|J|+1}\lt|\bigcap_{j\in J}A_j\rt|       }   +\sum_{J=\{n\}}(-1)^{|J|+1}\lt|\bigcap_{j\in J} A_j \rt|       \mathcolor{blue!80!black}{+\sum_{\substack{J\subseteq[n]\\ J\neq\{n\},\; n\in J}} (-1)^{|J|+1}\lt|\bigcap_{j\in J}A_j\rt|}\\
		                                    &= \mathcolor{red!80!black}{ \sum_{\substack{J\subseteq [n]\\J\neq\emptyset,\; n\notin J}}(-1)^{|J|+1}\lt|\bigcap_{j\in J}A_j\rt|       }   +\sum_{J=\{n\}}(-1)^{|J|+1}\lt|\bigcap_{j\in J} A_j \rt|       \mathcolor{blue!80!black}{+\sum_{\substack{J\subseteq[n]\\ J\neq\{n\},\; n\in J}} (-1)^{|J|+1}\lt|\bigcap_{j\in J}A_j\rt|}\\
		                                    &= \sum_{J\subseteq [n],\; J\neq\emptyset}(-1)^{|J|+1}\lt|\bigcap_{j\in J}A_j\rt|
	\end{align*}
Hence by mathematical induction we have the theorem.
\end{proof}
\begin{corollary}{}{}
	If $\forall\ i\in[n]$, $A_i=\{0\}$. Then $$1=\sum_{i=0}^n(-1)^{i+1}\binom{n}{i}$$
\end{corollary}
\begin{proof}
	Using the Inclusion-Exclusion Principle we have $$1=\lt|\bigcup_{i=1}^nA_i\rt|=\sum_{J\subseteq [n], J\neq\emptyset}(-1)^{|J|+1}\lt|\bigcap_{j\in J}A_j\rt|=\sum_{J\subseteq [n], J\neq\emptyset}(-1)^{|J|+1}=\sum_{i=1}^n(-1)^{i+1}\binom{n}{i}$$
\end{proof}
\begin{corolary}{}{}
	There are $\sum\limits_{k=0}^n\binom{m}{k}(-1)^k(m-k)^n$ onto functions from $[n]\to [m]$
\end{corolary}
\subsection{Strong Inclusion-Exclusion Principle}
\begin{Theorem}{Strong Inclusion-Exclusion}{sie}
	Let $f:2^{[n]}\to \bbR$. Define $g:2^{[n]}\to \bbR$ on a subset $T\subseteq [n]$ to be as follows $$g(T)=\sum_{S\subseteq T}f(S)\quad T\subseteq [n]$$Then $$f(T)=\sum_{S\subseteq T}(-1)^{|T|-|S|}g(S)$$
\end{Theorem}
\subsection{Mobius Inversion}
Now we derive a weak version of Mobius Inversion Theorem directly using \hyperref[th:sie]{Strong Inclusion Exclusion Principle}. If $f$ is a function from all product of primes to $\bbR$ and $g(n)=\sum\limits_{d\mid n}f(d)$ then we have $$f(n)=\sum\limits_{d\mid n}(-1)^{\#\text{divisors of $\lt(\frac{n}d\rt)$}}g(d)=\sum_{d\mid n}(-1)^{\#\text{divisors of $(d)$}}g\lt(\frac{n}d\rt)$$We we define a new function $\mu:\bbN\to \{-1,0,1\}$  such that $$\mu(n)=\begin{cases}
	0 & \text{If $n$ is not a product of distinct primes}\\
	(-1)^{\#\text{prime divisors of $n$}} & \text{If $n$ is a product of distinct primes}
\end{cases}$$So $\mu$ gets rid of the all the natural numbers $n$ which is not a product of distinct primes. 
So now we have the Mobius Inversion Theorem
\begin{Theorem}{Mobius Inversion}{mi}
	Let $f:\bbN\to \bbR$ and define $g:\bbN\to \bbR$ such that $g(n)=\sum\limits_{d\mid n}f(d)$ then if the  function $\mu:\bbN\to \{-1,0,1\}$   is defined as above then we have $$f(n)=\sum_{d\mid n}\mu(d)\; g\lt(\frac{n}d\rt)$$
\end{Theorem}
\subsection{Euler Totient Function}
\begin{Definition}{Euler Totient Function}{}
	Euler Totient Function, $\phi:\bbN\to\bbN$, $\phi(n)$ is the number of integers $m\leq n$ such that $gcd(m,n)=1$.
\end{Definition}
\begin{lemma}{}{}
	For any $n\in \bbN$, $$n=\sum_{d\mid n}\phi(d)$$
\end{lemma}
\begin{proof}
		Consider the list of numbers $S=\lt\{\frac1n,\frac2n,\dots,\frac{n}{n}\rt\}$. If we express every number in $S$ as simplified form i.e. $\frac{p}{q}$ form where $gcd(p,q)=1$. Then the denominators are all the divisors of $n$. 
	
	
	Then for any $k\in[n]$ we have $$\frac{k}{n}=\frac{\ \frac{k}{gcd(k,n)}\ }{\ \frac{n}{gcd(k,n)}\ }$$Denote $d_k\coloneqq\frac{n}{gcd(k,n)}$ then $d_k$ is a factor of $n$. And since $gcd\lt( \frac{k}{gcd(k,n)}, \frac{n}{gcd(k,n)} \rt)=1$ we have $\frac{k}{gcd(k,n)}\in \bbZ_{d_k}^*$. Let $k\in\bbZ_{d}^*$ then suppose $l$ is such that $d\times l=n$ then the fraction $\frac{k}{d}=\frac{k\times l}{n}\in S$ and its simplified form is in fact $\frac{k}{d}$.
	
	Hence for any $d\mid n$, the number of fractions with denominator $d$ is $\varphi(d)$, since for all such fractions the numerators are the elements of $\bbZ_{d}^*$. Therefore we have $\sum\limits_{d\mid n} \varphi(d)=n$.
	
\end{proof}
\begin{alternate-proof}
	$$n  = \sum_{i=1}^n 1 = \sum_{d\mid n}\ \sum_{\substack{i\leq n,\\ gcd(i,n)=d}}1=\sum_{d\mid n} \sum_{\substack{d\mid i,\ i\leq n,\\ gcd\lt(\frac{i}d,\frac{n}d\rt)=1}}1=\sum_{d\mid n}\ \sum_{\substack{j\leq \frac{n}d,\\ gcd\lt(\frac{n}d,j\rt)=1}}1= \sum_{d\mid n}\phi\lt(\frac{n}d\rt)=\sum_{d\mid n}\phi(d)$$
\end{alternate-proof}

Since $n=\sum\limits_{d\mid n}\phi(d)$ this is already in the form $g(n)=\sum\limits_{d\mid n}f(d)$. Hence take $g\bbN\to \bbR$ to be identity function and take $f$ to be the Euler Totient function. Then by \hyperref[th:mi]{Mobius Inversion} we have $$\phi(n)=\sum_{d\mid n}\mu(d)\; g\lt(\frac{n}d\rt)=\sum_{d\mid n}\mu(d)\frac{n}d\implies \frac{\phi(n)}{n}=\sum_{d\mid n}\frac{\mu(d)}{d}$$

\section{Generating Function}
\begin{Question}{}{}
	What is the number of non-negative solutions of $x_1+x_2+x_3+x_4=5$ for which $x_1+x_2$ is even?
\end{Question}
\begin{solution}
	$x_1+x_2$ is even. So it can be $0$ or $2$ or $4$. In that case $x_3+x_4$ can be $5$ or $3$ or $1$ respectively. For any $k$, $x+y=k$  in $k+1$ ways where $x,y$ are non-negative. Then the total number of solutions is $1\times 6+3\times 4+5\times 2=28$.
	
	Another way of solving this is consider the power series $$A(x)=1+3x^2+5x^4+\cdots=\sum_{i=0}^{\infty}a_ix^i\qquad B(x)=1+2x+3x^2+\cdots=\sum_{i=0}^{\infty}b_ix^i$$Where \begin{align*}
		a_i=\begin{cases}
			\#\text{solutions to $x_1+x_2=i$}& \text{when $i$ is even}\\
			0 & \text{when $i$ is odd}
		\end{cases},  &&  b_i=		\#\text{solutions to $x_1+x_2=i$}
	\end{align*}
Then for $A\cdot B=C=\sum\limits_{i=0}^{\infty}c_ix^i$, $c_i=\#$solutions to $x_1+x_2+x_3+x_4=i$ where $x_1+x_2$ is even.
\end{solution}
\begin{Question}{}{}
	What is the number of subsets of $[n]$ of size $k$?
\end{Question}
\begin{solution}
	Suppose there are $n$ variables $x_1,\dots, x_n$. For each subset $S\subseteq [n]$ where $|S|=k$, we assign $x_i=1$ if $i\in S$ and otherwise assign $x_i=0$. Hence the number of subsets of $[n]$ of size $k$ is same as the number of solutions of $\sum\limits_{i=1}^nx_i=k$. 
	
	Consider the following generating function $$(1+x)^n=\sum_{i=0}^n \binom{n}ix^i=\sum_{i=0}a_ix^i$$Here for each $i$, $a_i=\#$solutions for $\sum\limits_{i=1}^nx_i=k$. Therefore number of subsets of $[n]$ of size $k$ is $\binom{n}k$. 
\end{solution}
\begin{Question}{}{}
	How many partitions of $n$ are there?
\end{Question}
\begin{solution}
	We can find a nice generating function for number of partitions of $n$. We have $$\sum_{n\geq 0}P(n)x^n=\prod_{r=1}^{\infty}\sum_{i=0}^{\infty}x^{i\cdot r}$$For each $r\geq 1$ for any $i\geq 0$ think of $x^{i\cdot r}$ as the number of $r$'s in a partition of $n$ is $i$. So if $P$ is a partition of $n$ then suppose $n_i$ be the number of $i$'s in $P$. Hence we have $\sum\limits_{i=1}^ni\cdot n_i=n$ Then the corresponding term $x^n$ is generated by the $\prod\limits_{i=1}^nx^{i\cdot n_i}$ where $x^{i\cdot n_i}$ comes form the $\sum\limits_{j=0}^{\infty}x^{j\cdot n_i}$. Hence $$\sum_{n\geq 0}P(n)x^n=\prod_{r=1}^{\infty}\sum_{i=0}^{\infty}x^{i\cdot r}=\prod_{r=1}^{\infty}\frac1{1-x^r}$$
\end{solution}
\subsection{Well Formed Parenthesis and Catalan Number}
\begin{Definition}{Well Formed Parenthesis}{}
	A sequence of parenthesis is well formed if $\#($ $=$ $\#)$ and any prefix has at least as many $($ as $)$.
\end{Definition}
Now consider for any $i\geq 0$, \begin{align*}
	a_i&=\#\text{Well formed parenthesis of length $2i$}\\
	b_i&=\#\text{Well formed parenthesis such that the fist matches the last and length $2i$}
\end{align*}
\begin{Definition}{Catalan Number}{}
	The $n^{th}$ Catalan Number is the number of  well formed parenthesis of length $2n$, i.e. $a_i$. 
\end{Definition}
\begin{observation}
	$b_n=a_{n-1}$. 
\end{observation}
Since for $b_n$ the first matches with the last. So the internal $2(n-1)$ parenthesis forms a well formed parenthesis and that can be in $a_{n-1}$ ways.

\begin{observation}
	$a_n=\sum\limits_{i=1}^nb_ia_{n-i}=\sum\limits_{i=1}^n a_{i-1}a_{n-i}$. 
\end{observation}
Since there are $2n$ parenthesis the first $($ is matched with a $)$ at any of the  $n$ $)$'s since inside them all the parenthesis are forms well formed parenthesis. Hence we consider each case where the first $($ matched with $i^{th}$ $)$ differently. If the first $($ is matched with $i^{th}$ $)$ then inside them there is $2(i-1)$ length well formed parenthesis and we can think of this case as $b_i$ and the rest $2n-2i$ many parenthesis forms all possible well formed parenthesis which can be done in $a_{n-i}$ ways. So the number of ways the first $($ is matched with $i^{th}$ $)$ is $b_ia_{n-i}$ ways.  

Now define the power series $A(x)=\sum\limits_{i\geq 0}a_ix^i$. Then we have $$A^2(x)=\sum_{i\geq 0}\lt( \sum_{j=0}^ia_ja_{i-j} \rt)x^i$$This is almost in the form $\sum\limits_{i=1}^n a_{i-1}a_{n-i}$ for coefficient of $x^i$. So we do the following $$xA^2(x)=x\sum_{i\geq 0}\lt( \sum_{j=0}^ia_ja_{i-j} \rt)x^i=\sum_{i\geq 0}\lt( \sum_{j=0}^ia_ja_{i-j} \rt)x^{i+1}=\sum_{i\geq 0}\lt( \sum_{j=1}^{i+1}a_{j-1}a_{i+1-j} \rt)x^{i+1}=\sum_{i\geq 0}a_{i+1}x^{i+1}=A(x)-1$$
Hence we get a quadratic equation for $A(x)$ which is $A^2(x)x-A(x)+1=0$. Therefore $$A(x)=\frac{1\pm\sqrt{1-4x}}{2x}$$Now $$\sqrt{1-4x}=1+\frac12(-4x)+\frac{\frac12\times \lt(\frac12-1\rt)}{2!}(-4x)^2+\frac{\frac12\lt(\frac12-1\rt)\lt(\frac12-2\rt)}{3!}(-4x)^3+\cdots=\sum_{i\geq 0}\binom{\frac12}{i}(-4x)^i$$Therefore $$\frac{1+\sqrt{1-4x}}{2x}= \frac1x+\sum_{i\geq 1}2\binom{\frac12}{i}(-1)^{i}(4x)^{i-1} $$Now as $x\to 0$ we have  $\frac{1+\sqrt{1-4x}}{2x}$ does not exists but we have $$\frac{1-\sqrt{1-4x}}{2x}=\sum_{i\geq 1}2\binom{\frac12}{i}(-4x)^{i-1}=\sum_{i\geq 0}2\binom{\frac12}{i+1}(-4x)^{i}\quad \text{and}\quad \lim_{x\to 0}\sum_{i\geq 0}2\binom{\frac12}{i+1}(-4x)^{i}=2\binom{\frac12}{0+1}(-4)^{0}=2\frac12=1=a_0$$Therefore we have $$A(x)=\frac{1-\sqrt{1-4x}}{2x}=\sum_{i\geq 0}2\binom{\frac12}{i+1}(-4x)^{i}$$Now $$a_i=2\binom{\frac12}{i+1}=2\times (-4)^i\frac{\prod\limits_{j=0}^i \lt(\frac12-j\rt)}{(i+1)!}=\frac{2\times (-4)^i}{2^{i+1}}\frac{\prod\limits_{j=0}^i \lt(1-2j\rt)}{(i+1)!}= 2^i\frac{\prod\limits_{j=0}^i \lt(2j-1\rt)}{(i+1)!}=\frac1{i+1}\binom{2i}{i}$$Hence the $n^{th}$ Catalan Number is $\frac{1}{n+1}\binom{2n}n$. 

\subsection{Generating Function of Stirling Number of First Kind}

Take the generating function for $S_1(m,m)$ to be $\sum\limits_{m=0}^nS_1(n,m)x^m$. Then we have the following theorem
\begin{Theorem}{}{}
	$$\sum\limits_{m=0}^nS_1(n,m)x^m=\prod_{m=0}^{n-1}(x+m)$$
\end{Theorem}
\begin{proof}
	We will prove this by proving that the coefficients of $RHS$ follows the recursion relation \lmref{s1recrel1}  and also the initial conditions are same as Stirling Number of the First Kind. For $n=1$, we have $$S_1(1,0)+S_1(1,1)x=0+x$$Hence it is satisfied. For any $n$, $S(n,n)=1$ and the coefficient of $x^n$ in $\prod_{m=0}^{n-1}(x+m)$ is also $1$. Therefore the initial conditions are satisfied. Now we will show that \lmref{s1recrel1} is followed. We will use induction on $n$. The base case is already followed. \begin{align*}
		\prod_{m=1}^{n}(x+m-1) & = x\prod_{m=1}^{n-1}(x+j-1)+(n-1)\prod_{j=1}^{n-1}(x+j-1)\\
		& = x\sum_{m=0}^{n-1}S_1(n-1,m)x^{m}+(n-1)\sum_{m=0}^{n-1}S_1(n-1,m)x^m & [\text{Induction Hypothesis}]\\
		& = \sum_{m=1}^{n}S_1(n-1,m-1)x^{m}+(n-1)\sum_{m=0}^{n}S_1(n-1,m)x^m\\
		& = \sum_{m=0}^{n}S_1(n-1,m-1)x^{m}+(n-1)\sum_{m=0}^{n}S_1(n-1,m)x^m\\
		& = \sum_{m=0}^n\lt(S_1(n-1,m-1)+(n-1)S_1(n-1,m)\rt)x^m= \sum_{m=0}^nS_1(n,m)x^m
	\end{align*}
\end{proof}
For signed Stirling number of the first kind we have the following generating function. 
\begin{Theorem}{}{}
	$$\sum\limits_{m=0}^n(-1)^{n-m}S_1(n,m)x^m=\prod_{m=0}^{n-1}(x-m)$$
\end{Theorem}

\subsection{Exponential Generating Function}
Previously for any sequence $\{a_n\}_{n\geq 0}$ we constructed the generating function for this sequence by taking $$A(x)=\sum_{n=0}^{\infty}a_nx^n$$But in this case we will construct the exponential generating function like this $$\hat{A}(x)=\sum_{n=0}^{\infty}a_n\frac{x^n}{n!}$$
\begin{lemma}{}{}
	$$\sum_{n=0}^{\infty}S_2(n,m)\frac{x^n}{n!}=\frac{1}{n!}(e^x-1)^m$$
\end{lemma}
\begin{proof}We will prove using induction on $m$.
	\begin{align*}
		\frac{1}{m!}(e^x-1)^m & = \frac{e^x-1}{m}\times \frac1{(m-1)!}(e^x-1)^{m-1}\\
	& = \frac1m\lt(  \frac{e^x}{(m-1)!}(e^x-1)^{m-1}-\frac1{(m-1)!}(e^x-1)^{m-1}  \rt)\\
	& = \frac1m\lt( \sum_{n=0}^{\infty}S_2(n+1,m)\frac{x^n}{n!}-\sum_{n=0}^{\infty}S_2(n,m-1)\frac{x^n}{n!} \rt)&\lt[\frac{e^x(e^x-1)^{m-1}}{(m-1)!}=\frac{d}{dx}\frac{(e^x-1)^{m}}{m!}=\sum_{n=0}^{\infty} S_2(n+1,m)\frac{x^n}{n!} \rt]\\
	& = \frac1m\sum_{n=0}^{\infty}(S_2(n+1,m)-S_2(n,m-1))\frac{x^n}{n!}\\
	&= \frac1m\sum_{n=0}^{\infty}mS_2(n,m)\frac{x^n}{n!}\\
	&= \sum_{n=0}^{\infty}S_2(n,m)\frac{x^n}{n!}
	\end{align*}Hence by mathematical induction we have the lemma.
\end{proof}
\begin{Definition}{Derangement}{}
	A derangement is a permutation $\pi$ such that $\pi(i)\neq i$ for all $i$
\end{Definition}
Let $d_n$ denote the number of derangements on $[n]$. 
\begin{lemma}{}{}
	$d_n=(n-1)(d_{n-1}+d_{n-2})$
\end{lemma}
\begin{proof}
	content...
\end{proof}

Now define the exponential generating function for derangements to be $D(x)=\sum\limits_{n=0}^{\infty}\frac{d_n}{n!}x^n$. Hence we have $$D'(s)=\sum_{n=0}^{\infty}\frac{d_{n+1}}{n!}x^n=\sum_{n=0}^{\infty}\frac{d_n+d_{n-1}}{(n-1)!}x^n=x\lt(\sum_{n>0}\frac{d_n}{(n-1)!}x^n+\sum_{n>0}\frac{d_{n-1}}{(n-1)!}x^{n-1}    \rt)=x(D'(x)+D(x))$$Therefore we get the differential equation  $D'(x)=x(D'(x+D(x))$. Hence we have $$\frac{D'(x)}{D(x)}=\frac{x}{1-x}\implies \log D(x)=-x-\log (1-x)+C$$where $C\in\bbR$. Now for $x=0$, $D(0)=0$. Hence $C=0$. Therefore $$\log D(x)=-x-\log(1-x)\implies D(x)=\frac{e^{-x}}{1-x}=\lt(\sum_{n=0}^{\infty}\frac{(-1)^n}{n!}x^n\rt)\lt(\sum_{n=0}^{\infty}x^n\rt)=\sum_{n=0}^{\infty}\lt( \sum_{k=0}^n\frac{(-1)^k}{k!} \rt)x^n=\sum_{n=0}^{\infty}\frac{x^n}{n!}n!\lt( \sum_{k=0}^n\frac{(-1)^k}{k!} \rt)$$Therefore we have $ d_n=n!\lt( \sum\limits_{k=0}^n\frac{(-1)^k}{k!} \rt)$.


\section{Partitions}

\section{Partially Ordered Sets (Poset)}
\dfn{Partially Ordered Sets (Posets)}{
Let $U$ be a set. A relation $\leq$ on $U$ is a partial order if  we have \begin{enumerate}[label=\bfseries\protect\circled{\roman*},align=left]
	\item \textbf{Reflexive:} $x\leq x$ for all $x\in U$
	\item \textbf{Transitive:} $x\leq y$, $y\leq z\implies x\leq z$, $\forall \ x,y,z\in U$
	\item \textbf{Anti-symmetric} $x\leq y$, $y\leq x\implies x=y$
\end{enumerate}Then the pair $(U,\leq)$ is called a partially ordered set
}
\begin{adjustbox}{minipage={\linewidth}, valign=t}
	
	\begin{wrapfigure}{t}{0.35\linewidth}
		
		\centering
	\begin{tikzpicture}[scale=0.8]
		% Define the positions of each subset
		\node (empty) at (0, 0) {$\emptyset$};
		\node (1) at (-2, 2) {$\{1\}$};
		\node (2) at (0, 2) {$\{2\}$};
		\node (3) at (2, 2) {$\{3\}$};
		\node (12) at (-2, 4) {$\{1, 2\}$};
		\node (13) at (0, 4) {$\{1, 3\}$};
		\node (23) at (2, 4) {$\{2, 3\}$};
		\node (123) at (0, 6) {$\{1, 2, 3\}$};
		
		% Draw the edges between nodes to represent the inclusion relation
		\draw[-latex] (empty) -- (1);
		\draw[-latex] (empty) -- (2);
		\draw[-latex] (empty) -- (3);
		\draw[-latex] (1) -- (12);
		\draw[-latex] (1) -- (13);
		\draw[-latex] (2) -- (12);
		\draw[-latex] (2) -- (23);
		\draw[-latex] (3) -- (13);
		\draw[-latex] (3) -- (23);
		\draw[-latex] (12) -- (123);
		\draw[-latex] (13) -- (123);
		\draw[-latex] (23) -- (123);
	\end{tikzpicture}
	\caption{Hasse Diagram of $\lt(2^{[3]},\subseteq \rt)$}
		
		\vspace{-2\baselineskip}
		
	\end{wrapfigure}
	
	\vspace*{0.15em}
	We will now define some terms which will be used a lot in this section:
	\begin{enumerate}
		\item \textit{Total order} of a set $U$  is partial order  such that for all $x,y\in U$, either $x\leq y$ or $y\leq x$  (or both)
		\item If $x\leq y$ and $x\neq y$ then $x<y$
		\item $x\leq y\equiv y\geq x$
		\item For any $x,y\in U$ if neither $x\leq y$ nor $y\leq x$ then $x$ and $y$ are \textit{incomparable} and denoted by $x\| y$.
		\item A \textit{chain} is a totally ordered subset of $U$.
		\item The \textit{Height} of $U$, $h(U)$ is the length of the longest chain in $U$.
		\item An \textit{anti-chain} is a subset of incomparable elements 
		\item The \textit{Width} of $U$, $w(U)$ is the size of the longest anti-chain in $U$.
		\item The \textit{minimal} elements of $U$ is defined as $\min(U)=\{x\in U\mid \forall\ y\in U,\ x\leq y\text{ or }y\|x\}$
		\item The \textit{maximal} elements of $U$ is defined as $\max(U)=\{x\in U\mid \forall\ y\in U,\ y\leq x\text{ or }y\|x\}$
	\end{enumerate}
	
\end{adjustbox}

\begin{Example}{}{}
	\begin{enumerate}[label=(\alph*)]
		\item $U=[n]$ and $\leq $ is the standard ordering.
		\item $U=2^{[n]}$ and $\leq $ is inclusion. 
	\end{enumerate}
\end{Example}


\begin{assumption*}
	We will assume $U$ is always finite
\end{assumption*}
\begin{lemma}{}{minmax-antichain}
	$\min (U)$ and $\max{(U)}$ are anti-chains, non-empty (if $U$ is non-empty) (possibly intersecting).
\end{lemma}
\begin{proof}
	We will prove for $\min(U)$ and the same type of proof will also work for $\max(U)$. Since $U$ is nonempty and finite $\exs \ x\in U$. Now if $x\notin \min(U)$ then $\exs\ y_1\in U\setminus\{x\}$ such that $y_1<x$. If $y_1\notin U$ then $\exs\ y_2\in U\setminus\{x,y_1\}$ such that $y_2<y_1$. Continuing like this if $y_{|U|-2}\notin U$, $\exs\ y_{|U|-1}\in U\setminus\{x,y_i\colon i\in[|U|-2]\}$. Then $y_{|U|-1}$ is the only element left in $U\setminus\{x,y_i\colon i\in[|U|-2]\}$. Hence $y_{|U|-1}$ is the minimal element of $U$. So $y_{|U|-1}\in \min(U)$. Therefore $\min(U)$ is nonempty.
	
	 Suppose $\min(U)$  not a anti-chain then $\exs,\ x,y\in U$ and $x\neq y$ such that $x\not\| y$. Hence either $x<y$ or $y<x$. WLOG suppose $x<y$. Then $y$ is not a minimal element since $y\not\leq x$. Hence contradiction. $\min(U)$ forms an anti-chain.
	 
	 Let $U=[1]$ with standard ordering $\leq$. Then $\min(U)=\max(U)=[1]$. Hence $\min(U)$ and $\max(U)$ may intersect. 
\end{proof}
\begin{observation*}
	$\min(U)$ and $\max(U)$ are singleton sets  if it is a total order. 
\end{observation*}

\begin{lemma}{}{chainoneminonemax}
	Any maximal chain has an element of $\min(U)$ and an element of $\max(U)$. These elements are same if length of the chain is $1$
\end{lemma}
\begin{Theorem}{Antichain Partitioning}{}
	Every poset $(U,\leq )$ can be partitioned into $h(U)$ many antichains (not less). 
\end{Theorem}
\begin{proof}
	We will first show that $U$ can not be partitioned into fewer than $h(U)$ many antichains. No antichain contains two elements from a chain,  since elements of chains are pairwise com-
	parable and elements of antichains are pairwise incomparable. So each element of the longest chain in $U$ are in distinct antichains. Since the longest chain in $U$ has length $h(U)$, at least $h(U)$ many antichains are needed.
	
	Now for all $x\in U$ define the \textit{depth} of $x$, $d(x)$ in $U$ to be the length of the longest chain that ends at $x$ i.e. $$d(x)=\max\limits_{\textit{chain $C$},\; \max(C)=x}|C|$$Hence by definition we have $d(x)\leq h(U)$ for all $x\in U$. Consider $$A_i=\{x\in U\colon d(x)=i\}\quad\forall\ i\in[h(U)]$$We will show $\forall\ i\in[h(U)]$, $A_i$ is an antichain. The proof of $A_i$ is antichain is similar to \lmref{minmax-antichain}.
\end{proof}
\begin{Theorem}{Dilworth's Theorem}{dilworth}
	Every poset $(U,\leq)$ can be partitioned into $w(U)$ many chains (not less).
\end{Theorem}
\begin{proof}
	Clearly at lest $w(U)$ many chains are needed since any two elements of the longest antichain of $U$ are incomparable and therefore they are in distinct chains and henceforth all the elements of the longest antichain are in distinct chains.
	
	We will show there is such a partition we will induct on $|U|$. Consider the maximal antichain of $U$, $P=\{x_1,\dots, x_{w(U)}\}$. Now we partition $U$ into two posets of smaller size.$$U_1\coloneqq \{x\in U\mid \exs\ y\in P,\ y\leq x\}\qquad U_2\coloneqq \{x\in U\mid \exs\ y\in P,\ x\leq y\}$$ with the same relations as for $U$. Now notice $U_1\cap U_2=P$. Therefore $w(U_1)=w(U_2)=w(U)$. Assuming $P\subsetneq U_1$ and $P\subsetneq U_2$ by inductive hypothesis we can partition $U_1$ and $U_2$ into chains $C^1_1,\dots, C_{w(U_1)}^1$ and $C_1^1,\dots, C_{w(U_2)}^2$ respectively where $C_i^1\cap C_i^2=\{x_i\}$ for all $i\in w(U)$. Hence we can take $C_i=C_1\cup C_2$ and $C_i$ is a chain for all $i\in w(U)$. So we get $w(U)$ many partitions of $U$.
	
	Now we have $U_1=U\iff U=\min(U)$ and $U_2=U\iff U=\min(U)$. So we only have to consider the case where  there is no largest antichain except for $\min(U )$, $\max(P )$ or both.  In that case let $C$ be any maximal chain. Then $C$ has exactly one element of $\min(U)$ and exactly one element of $\max(U)$ by \lmref{chainoneminonemax}. So $w(U\setminus C)=w(U)-1$ since only one element from each largest antichain is removed. Now by induction $U\setminus C$ can be partitioned into $w(U)-1$ many chains. Hence $U$ can be partitioned into $w(U)$ many chains. Hence we are done. 
\end{proof}
\subsection{Subposets and Dimensions}
\dfn{Subposet}{$P=(U,\leq_P)$ is a subposet of $Q=(V,\leq_Q)$ if there is an injective function $f:U\to V$ such that $\forall\ x_1,x_2\in U$, $x_1\leq_Px_2\iff f(x_1)\leq_Qf(x_2)$. The function $f$ is called an \textit{embedding}.} 

We say $Q=(U,\leq_Q)$ is an \textit{extension} of $P=(U,\leq_P)$ iff $\forall\ x_1,x_2\in U$, $x_1\leq_Px_2\iff x_1\leq_Qx_2$. $Q$ is a \textit{linear extension} of $P$ if $\leq_Q$ is a total order. 
\begin{lemma}{}{}
	Let $P_1=(U,\leq _1)$, $P_2=(U,\leq_2)$ be two posets on the same ground set $U$. Then we define $P=P_1\cap P_2\coloneqq (U,\leq)$ with the relation $\leq \coloneqq \leq_1\cap \leq_2$, meaning $$x\leq y\iff x\leq_1y\text{ and }x\leq_2y$$Then $P$ is a poset and $P_1$ and $P_2$ are extensions of $P$.
\end{lemma}
\begin{proof}
	The $\leq $ relation is an partial order relation. Since all pairs that are related via $\leq $ are related via $\leq_1$ and $\leq _2$, $\leq_1,\leq_2$ are extensions of $\leq$.
\end{proof}
\begin{Definition}{$d-$ary Dominance Poset}{}
 For $d\in \bbN$ the set $\bbR^d$ becomes a $d-$ary dominance poset via the \textit{dominance order}, $\leq_{\text{dom}}$ where $x=(x_1,\dots, x_d), y=(y_1,\dots, y_d)\in \bbR^d$ we have $$x\domrel y\iff \forall\ i\in[d],\ x_i\leq y_i$$
\end{Definition}
Then we have the following definition for $d-$dimensional posets $(U,\leq)$.
\begin{Definition}{Dimension of Poset}{}
	The dimension of the poset $(U,\leq)$ is the smallest $d\in \bbN$ such that $(U,\leq)$ is a subposet of  $(\bbR^d,\domrel)$.
\end{Definition}
\begin{Theorem}{}{}
	Let $(U,\leq)$  be a poset and $d>0$, $d\in\bbN$. We have that $U$ is $d-$dimensional if and only if $d$ is the smallest number such that $U$ can be written as intersection of $d-$linear extensions of $U$. 
\end{Theorem}
\begin{proof}
	$``\Leftarrow":$ Let there are $d$-linear extensions of $(U,\leq)$, which are $(U,\leq_1),\dots(U,\leq_d)$ such that $$x\leq y\iff x\leq_i y\ \forall\ i\in[d]$$We will construct an embedding $f:U\to \bbR^d$. For any $x\in U$ we take $f(u)=(r_1,\dots, r_d)$ where $r_i=|\{y\in U\colon y\leq_i x\}|$. Now we will show $f$ is indeed an embedding. Let $u,v\in U$. Then  suppose $f(u)=(r_1^u,\dots,r_d^u)$ and $f(v)=(r_1^v,\dots, r_d^v)$. Now 
	\begin{align*}
		u\leq v&\iff u\leq_i v\ \forall \ i\in[d]\\
		 & \iff \Big(x\in\{y\in U\colon y\leq_i u\}\implies x\leq_i u\leq_i v\implies x\in   \{y\in U\colon y\leq_i v\}  \Big)\ \forall \ i\in[d]\\
		 & \iff r_i^u\leq r_i^v\ \forall \ i\in[d]\\
		 & \iff f(u)\domrel f(v)
	\end{align*}Hence $f$ is indeed a embedding. 

$``\Rightarrow":$ $(U,\leq)$ is $d$-dimensional. There exists an embedding $f:U\to\bbR$. Now $\forall\ x,y\in U$ we have $$x\leq y\iff f(x)\domrel f(y)$$. Now we can assume no two points of $U$ share a coordinate or else we can force this rule changing the values a little. Now we can think $f=(f_1,\dots, f_n)$ where $f_i:U\to \bbR$ for all $i\in[d]$ such that $x\leq y\iff f_i(x)\leq f_i(y)$ for all $i\in[d]$. Then we have the linear extensions of $(U,\leq)$, $(U,\leq_i)$ where $\forall\ x,y\in U$, $x\leq_i y\iff f_i(x)\leq f_i(y)$.  
\end{proof}
\begin{lemma}{}{}
	The dimension of $(2^{[d]},\subseteq)$ is $d$
\end{lemma}
\begin{proof}
	The dimension is at most $d$ because $\{0,1\}^d$ can be mapped to $\bbR^d$. Now we will show that  lower than $d$ embedding is not possible. 
	
	Suppose for the sake of contradiction that $(\{0,1\}^d,\leq )$ can be written as the intersection of $d-1$ linear extensions. Let $(\{0,1\}^d,\leq_i)$ for all $i\in[d-1]$ be the linear extensions of $(\{0,1\}^d,\leq)$. Now consider the pairs of sets $(\{i\},\ov{\{i\}})$ for all $i\in[d]$. Now for all $i\in[d]$, we have $\{i\}\not\leq \ov{\{i\}}$. Hence $\exs\ j\in[d-1]$ such that $\{i\}\not\leq_j\ov{\{i\}}\implies \ov{\{i\}}<_j\{i\}$. 	Therefore $\exs\ i_1,i_2\in[d]$ where $i_1\neq i_2$ such that $\exs\ j\in[d-1]$ such that $\ov{\{i_1\}}<_j\{i_1\}$ and $\ov{\{i_2\}}<_j\{i_2\}$ by Pigeon Hole Principle. Since $i_1\neq i_2$ we have $\{i_1\}\leq \ov{\{i_2\}}\implies \{i_1\}\leq_j\ov{\{i_2\}}$ and $\{i_2\}\leq \ov{\{i_1\}}\implies \{i_2\}\leq_j\ov{\{i_1\}}$. Therefore we have $$\ov{\{i_1\}}<_j\{i_1\}\leq_j \ov{\{i_2\}}<_j\{i_2\}\leq_j\ov{\{i_1\}}$$Hence contradiction \ctr
\end{proof}

\begin{lemma}{}{}
	For all $(U,\leq)$, $\dim U\leq w(U)$.
\end{lemma}
\begin{proof}
	Firstly $U$ can be decomposed into $w(U)$ many chains by \hyperref[th:dilworth]{Dilworth's Theorem}. 
\end{proof}