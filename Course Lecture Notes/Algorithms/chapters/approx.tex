\chapter{Approximation Algorithms using LP}
In this chapter we will study some approximation algorithms using linear programming to  get better approximation ratios of the optimal solution.
\section{Set Cover}
\begin{algoprob}
	\problemtitle{$\prb{Set Cover}$}
	\probleminput{$\mcU$: Universe of all elements $u_1,\dots, u_n$

		$\mcS=\{S_1,\dots, S_m\}$, $S_i\subseteq \mcU$ forall $i\in[m]$

		Function $c:\mcS\to\bbZ_+$}
	\problemquestion{Given $\mcU,\mcS$ and the function $c$ find $T\subseteq [m]$ such that $\bigcup\limits_{i\in T}S_i=\mcU$ to minimize the total cost $c(T)=\sum\limits_{i\in T}c(S_i)$ }
\end{algoprob}
Since the special case of Set Cover is basically the Vertex Cover problem we discussed earlier, we know that Set Cover is $\mathsf{NP}$-hard.
\begin{Theorem}{}{}
	Set Cover is $\mathsf{NP}$-hard.
\end{Theorem}
Since we are going to find approximate solutions using LP let's first write the linear program for Set Cover:
\begin{mini*}
	{}{\sum\limits_{S\in\mcS}c(S)x_S}{}{}
	\addConstraint{\sum\limits_{S:u\in S}x_S}{\geq 1}{\quad\forall\ u\in \mcU}
	\addConstraint{x_S}{\geq 0}{\quad\forall\ S\in \mcS}
\end{mini*}

\subsection{Frequency \texorpdfstring{$f$}{f}-Approximation Algorithm}
Let for any element $u\in\mcU$, $f_u$ is the frequency of the element $u$ in $\mcS$ i.e. $f_u=|\{S\in\mcS\colon u\in S\}|$. Then let $f=\max\{f_u\colon u\in \mcU\}$. Then we want to find a $f$-approximation algorithm for set cover.
\begin{question}
	For vertex cover what is $f$?
\end{question}
For all $e\in E$ we have $f_e=2$ since the elements of universe corresponds to the edges and sets corresponds to vertices and each edge is contained in exactly 2 sets. So $f=2$.

\begin{algorithm}\DontPrintSemicolon
	\KwIn{$\mcU,\mcS,c$}
	\KwOut{$T\subseteq [m]$ such that $\bigcup\limits_{i\in T}S_i=\mcU$ and $\sum\limits_{i\in T}c(S_i)$ is minimized}
	\Begin{
		$T\longleftarrow\emptyset$\;
		$\hat{x}\longleftarrow 0^{|\mcS|}$\;
		Let $x^*$ is the optimal solution of the LP for Set Cover problem\;
		\For{$S_i\in \mcS$}{
			\If{$x^*_{S_i}\geq \frac1f$}{
				$T\longleftarrow T\cup\{i\}$\;
				$\hat{x}_{S_i}\longleftarrow 1$
			}
		}
		\Return{$T$}
	}
	\caption{$f$-Approximate Algorithm}
\end{algorithm}
\begin{lemma}{}{}
	$\hat{x}$ is a feasible solution.
\end{lemma}
\begin{proof}
	For all $e\in \mcU$ there are at most $f$ sets containing $e$. Thus at most $f$ terms in the summation in $LHS$ of the first constraint for each $e\in \mcU$ Thus in $x^*$ at least one such term is $\geq \frac1f$.
\end{proof}
\begin{lemma}{}{}
	$\sum\limits_{S\in \mcS}c(S)\hat{x}_S\leq f\cdot \sum\limits_{S\in\mcS}c(S)x^*_S$
\end{lemma}
\begin{proof}
	In $\hat{x}$ if $\hat{x}_S=1$ that means $x^*_S\geq \frac1f$. Therefore we have the lemma.
\end{proof}

Hence with this algorithm we can get a $f$-approximation for Set Cover problem. But this is not good enough since one element can be in too many sets and then it doesn't give a good approximation. In the next section we will see a new way of getting the same approximation ratio.

\subsection{Frequency \texorpdfstring{$f$}{f}-Approximation Algorithm through Dual Fitting}
First let's wrote the dual of the LP for Set Cover problem:
\begin{center}
	\begin{minipage}{0.35\textwidth}
		\begin{mini*}
			{}{\sum\limits_{S\in\mcS}c(S)x_S}{}{}
			\addConstraint{\sum\limits_{S:u\in S}x_S}{\geq 1}{\quad\forall\ u\in \mcU}
			\addConstraint{x_S}{\geq 0}{\quad\forall\ S\in \mcS}
		\end{mini*}
		\begin{center}
			$\boxed{\text{Primal}}$\vspace*{2mm}

            ``Covering Problem''
		\end{center}
	\end{minipage}	$\iff$\begin{minipage}{0.35\textwidth}
		\begin{maxi*}
			{}{\sum\limits_{u\in\mcU}y_u}{}{}
			\addConstraint{\sum\limits_{u\in S}y_u}{\leq c(S)}{\quad\forall\ S\in\mcS}
			\addConstraint{y_u}{\geq 0}{\quad\forall\ u\in \mcU}
		\end{maxi*}
		\begin{center}
			$\boxed{\text{Dual}}$\vspace*{2mm}

            ``Packing Problem''
		\end{center}
	\end{minipage}
\end{center}
Both the primal and dual are feasible. Let $x,y$ are feasible solutions of the primal and dual respectively. Then by \hyperref[th:weak-duality]{Weak Duality} we have $$\sum\limits_{S\in \mcS}c(S)x_S\geq \sum\limits_{u\in \mcU}y_u$$Let $x^*,y^*$ are the optimal solutions of primal and dual respectively. Then by \hyperref[th:complementary-slackness][Complementary Slackness] $$x_S^*>0\implies \sum\limits_{u\in S}y_u^*=c(S)\qquad y_u^*>0\implies \sum\limits_{S:u\in S}x_S^*=1$$
\begin{Theorem}{Relaxed Complementary Slackness}{relaxed-cs}
    Suppose $x,y$ are feasible solutions of the primal and dual respectively  and the satisfy the following conditions:
    \begin{enumerate}
        \item If $x_j>0$ then $\frac1{\alpha}\cdot c_j\leq  {A^j}^Ty\leq c_j$ where $\alpha\geq 1$.
        \item If $y_i>0$ then $ b_i\leq A_i^Tx\leq \beta\cdot b_i$ where $\beta\geq 1$.
    \end{enumerate}Then $$c^Tx\leq \alpha\beta\cdot b^Ty\leq \alpha\beta\cdot c^Tx^*=\alpha\beta\cdot \operatorname{OPT}$$
\end{Theorem} 
\begin{proof}
	$x,y$ are the feasible solutions of the primal and dual respectively. Suppose first $d$ constraints of the primal are equalities and rest are inequalities and similarly first $l$ constraints of the dual are equalities and rest are inequalities. Then we have \begin{align*}
        c^Tx & =\sum\limits_{j=1}^m c_jx_j \leq\sum_{j=1}^m \lt(\alpha {A^j}^Ty\rt)x_j= \alpha\sum_{j=1}^m\sum_{i=1}^n A_{ij}y_ix_j = \alpha\sum_{i=1}^n \lt(\sum_{i=1}^m A_{ij}x_j\rt)y_i \leq \alpha\sum\limits_{i=1}^m\beta\cdot b_iy_i=\alpha\beta\cdot b^Ty  
    \end{align*}
    Hence we have $c^Tx\leq \alpha\beta\cdot b^Ty\leq \alpha\beta\cdot c^Tx^*=\alpha\beta\cdot \operatorname{OPT}$.
\end{proof}

To show a $f$-approximation algorithm for set cover we will first find $x,y$ feasible primal, dual solution which satisfies:\begin{enumerate}
    \item $x$ is integral.
    \item $x$ satisfies the first condition of \hyperref[th:relaxed-cs]{Relaxed Complementary Slackness} with $\alpha=f$.
\end{enumerate}

\begin{algorithm}
\DontPrintSemicolon
    \KwIn{$\mcU,\mcS,c$}
    \KwOut{$T\subseteq [m]$ such that $\bigcup\limits_{i\in T}S_i=\mcU$ and $\sum\limits_{i\in T}c(S_i)$ is minimized}
    \Begin{
        Initialize $\mcU'\longleftarrow\mcU$, $C\longleftarrow\emptyset$\;
        \While{$\exs\ u\in\mcU'$}{
            Increase $y_u$  until for some $S\in\mcS$ such that $u\in S$ we have $\sum\limits_{u'\in S}y_{u'}=c(S)$\;
            $C\longleftarrow C\cup \lt\{S\in\mcS\colon \sum\limits_{u\in S}y_u=c(S)\rt\}$\;
            \For{$S\in C$}{
                $\mcU'\longleftarrow \mcU'\setminus S$\;
            }
        }
    \Return{$C$}
    }
    \caption{Dual Fitting Algorithm for Set Cover}
\end{algorithm}

From $C$ we con construct $x$ by $x_S=1$ if $S\in C$ and otherwise $x_=0$ for all $S\in\mcS$. Now we have the observations:
\begin{observation*}After the algorithm terminates we have:
    \begin{enumerate}
        \item At the beginning of the loop if $u\in\mcU$, $y_u=0$.
        \item If $x_S=1$ and $u\in S$ then $y_u$ is not increased.
        \item $x_S\in\{0,1\}^{|\mcS|}$ is integral.
    \end{enumerate}
\end{observation*}
\begin{lemma}{}{}
    \begin{enumerate}
        \item $x$ is feasible at the end of the algorithm.
        \item $y$ is feasible at every iteration of the while loop
    \end{enumerate}
\end{lemma}
\begin{proof}
    The algorithm terminates when $\mcU'=\emptyset$. That means all the elements of the universe are covered. Hence the set $C$ output after the algorithm terminates is indeed a set cover. Hence $x$ is a feasible solution.

    At the start of the algorithm $y=0^{|\mcU|}$. Hence $y$ is feasible. Now suppose at any iteration $y$ is feasible. If the algorithm goes through another iteration then there exists an element in $\mcU'$ which is not covered. Let $u\in\mcU'$ which is not covered. Hence $y_u=0$. Since in the previous iteration $y$ was feasible we have $\sum\limits_{S:u\in S}y_u\leq c(S)$. Now we increase $y_u$ to the point we achieve the equality $\sum\limits_{u'\in S}y_{u'}=c(S)$ for all $S\in\mcS$. Therefore even after updating $y_u$ all the constraints of dual are satisfied. Hence $y$ is a feasible solution after another iteration of the while loop. Therefore $y$ is feasible at every iteration of the while loop.
\end{proof}

\begin{lemma}{}{}
    $x,y$ satisfy the \hyperref[th:relaxed-cs]{Relaxed Complementary Slackness} conditions.
\end{lemma}
\begin{proof}
    If for any $S\in\mcS$, $x_S>0$ then we have $\sum\limits_{u\in S}y_u=c(S)$ by the construction of $C$ in the algorithm. Therefore $$x_S>0\implies \sum\limits_{u\in S}y_u=c(S)$$Hence $\alpha=1$.

    Now let for some $u\in\mcU$, $y_u>0$. Since $f$ is the maximum frequency of any element of the universe we have $f\geq \sum\limits_{S:u\in S}x_S\geq 1$. Therefore $$y_u>0\implies f\geq \sum\limits_{S:u\in S}x_S\geq 1$$Hence $\beta=f$. 
\end{proof}

Therefore by \hyperref[th:relaxed-cs]{Relaxed Complementary Slackness} $C$ is an $f$-approximate solution for the set cover problem. In the next sections we will show how to get a better approximation ratio.


\subsection{\texorpdfstring{$O(n\log n)$}{O(nlogn)}-Approximation Algorithm through Randomized Rounding}

\begin{algorithm}\DontPrintSemicolon
	\KwIn{$\mcU,\mcS,c$}
	\KwOut{$T\subseteq [m]$ such that $\bigcup\limits_{i\in T}S_i=\mcU$ and $\sum\limits_{i\in T}c(S_i)$ is minimized}
	\Begin{
		$\hat{x}\longleftarrow 0^{|\mcS|}$\;
		Let $x^*$ is the optimal solution of the LP for Set Cover problem\;
		\For{$S\in \mcS$}{
			Set $\hat{x}_S\longleftarrow 1$ with probability $x^*_S$.
		}
		\Return{$\hat{x}$}
	}
	\caption{$n\log n$-Approximate Algorithm}
\end{algorithm}
\newpage 

\parinf
From the construction of $\hat{x}$ we have $\bbE\lt[\sum\limits_{S\in\mcS}c(S)\hat{x}_S\rt]=\sum\limits_{S\in\mcS}c(S)x^*_S$. Now suppose we fixed an element $u\in\mcU$. Then $$\bbP[u \text{ is not covered}]=\prod\limits_{S:u\in S}\bbP[S\text{ is not selected}]=\prod\limits_{S:u\in S}(1-x^*_S)\leq \prod_{S:u\in S}e^{-x^*_S}=\exp\lt[-\sum\limits_{S:u\in S}x^*_S\rt]\leq e^{-1}$$Hence to reduce the probability of not covering an element of $\mcU$ we repeat the algorithm multiple times. Hence we have the updated algorithm:
\begin{algorithm}\DontPrintSemicolon
	\KwIn{$\mcU,\mcS,c$}
	\KwOut{$T\subseteq [m]$ such that $\bigcup\limits_{i\in T}S_i=\mcU$ and $\sum\limits_{i\in T}c(S_i)$ is minimized}
	\Begin{
		Let $x^*$ is the optimal solution of the LP for Set Cover problem\;
		\For{$i\in [2\log n]$}{
			$C_i\longleftarrow\emptyset$\;
			\For{$S\in \mcS$}{
				Put $S$ in $C_i$ with probability $x^*_S$.
			}
		}
		$C\longleftarrow\bigcup\limits_{i=1}^{2\log n}C_i$\;
		\Return{$C$}
	}
	\caption{$n\log n$-Approximate Algorithm}
\end{algorithm}

Again now we fix an element $u\in \mcU$. Now we will calculate the probability that $u$ is not covered in the union of all $C_i$'s. $$\bbP[u \text{ is not covered by }C]=\bbP[u \text{ is not covered by }C_i\text{ for all }i\in [2\log n]]\leq e^{-2\log n}=\frac{1}{n^2}$$
Hence the probability that $e$ is covered is at least $1-\frac{1}{n^2}$. Therefore $$\bbP[\exs\ e\in\mcU\text{ is not covered by }C]\leq \sum\limits_{u\in\mcU}\frac1{n^2}=\frac1n$$Hence $\bbP[C\text{ is a set cover}]\geq 1-\frac1n$. Now we have to bound the cost of $C$. By Markov's inequality we have $$\bbP\lt[c(C)\geq 6\log n\sum\limits_{S\in\mcS}c(S)x^*_S\rt]\leq \frac13$$

$$\bbP\lt[C\text{ is not a set cover OR cost of C}\geq 6\log n\sum\limits_{S\in\mcS}c(S)x^*_S\rt]\leq \frac1n+\frac13\leq \frac12$$Therefore $$\bbP\lt[C\text{ is  set cover AND }c(S)\leq 6\log n\sum\limits_{S\in\mcS}c(S)x^*_S\rt]\geq 12$$Hence with probability at least $\frac12$ we have a set cover $C$ such that $c(C)\leq 6\log n\sum\limits_{S\in\mcS}c(S)x^*_S$ which gives us an $O(\log n)$-approximation algorithm for Set Cover problem.\parinn


\nt{$O(\log n)$-approximatiobn is also the best we can do for set cover. Doing better than that is $\mathsf{NP}$-hard.}


\newpage

\section{Makespan Minimization}
\begin{algoprob}
	\problemtitle{$\prb{Makespan}$}
	\probleminput{$\mcM$: Set of $m$ machines

		$\mcJ$: Set of $n$ jobs
        
        $P\in\bbN^{m\times n}$: Matrix where $P_{ij}$ is the time taken by machine $i$ to complete job $j$.}
	\problemquestion{Given set of machines $M$, set of jobs $\mcJ$ and the matrix of time taken by $i^{th}$ machine to complete $j^{th}$ job find an assignment $\sg:\mcJ\to \mcM$ of jobs to machines to minimize the  makespan $S_{\sg}=\max\{l_i\colon i\in \mcM\}$ where $l_i=\sum\limits_{j:\sg(j)=i}P_{ij}$ i.e. time taken by machine $i$ to complete all jobs assigned by $\sg$}
\end{algoprob} 
\begin{Theorem}{}{}
    Makespan problem is weakly $\mathsf{NP}$-hard by reduction from subset-sum.
\end{Theorem}

\nt{Weakly $\mathsf{NP}$-hard means there exists a pseudo polynomial time algorithm i.e. if all parameters are polynomially large the algorithm can solve the problem in polynomial time.}
\begin{Theorem}{}{}
    It is $\mathsf{NP}$-hard to approximate within a factor of $1.5$
\end{Theorem}
Here we will show a $2$-approximate solution of makespan optimization. First let's construct the LP for makespan optimization.
\subsection{LP Construction}
We'll use the variable $x_{ij}$ as an indicator for $j^{th}$ job assigned to $i^{th}$ machine. Then here is the LP:
\begin{mini*}
    {}{T}{}{}
    \addConstraint{\sum_{i\in \mcM}x_{ij} }{\geq 1}{\quad\forall\ j\in \mcJ}
    \addConstraint{\sum_{j\in\mcJ}P_{ij}x_j}{\leq T}{\quad\forall\ i\in \mcM}
    \addConstraint{x_{ij}}{\geq 0}{\quad\forall \ i\in\mcM,j\in\mcJ}
\end{mini*} 
So here the first constrain basically says that every job assigned to some machine. The second constraint says that for every machine the total time taken by the machine to complete the jobs should be at most the makespan where $T$ denotes the makespan. But this LP is not good enought. Consider the following example where there is only one job and $P_{i1}=m$ then $\operatorname{OPT}_{LP}=1$ by setting $x_{i1}=\frac1m$ where as actually the optimal makespan is $m$. Hence this LP will not work. We have to strengthen the LP.

So now assume we already know the optimal makespan $T$. Then if any $P_{ij}>T$ then we know that we can't assign the $j^{th}$ job to $i^{th}$ machine. So now we have the new updated LP:

\begin{mini*}
    {}{0}{}{}
    \addConstraint{\sum_{i\in \mcM}x_{ij} }{\geq 1}{\quad\forall\ j\in \mcJ}
    \addConstraint{\sum_{j\in\mcJ}P_{ij}x_j}{\leq T}{\quad\forall\ i\in \mcM}
    \addConstraint{x_{ij}}{\geq 0}{\quad\forall \ i\in\mcM,j\in\mcJ}
	\addConstraint{x_{ij}}{=0}{\quad \text{If }P_{ij}>T \forall\ i\in \mcM\ j\in\mcJ}
\end{mini*} 
This basically checks the feasibility for a specific $T$. Hence now we can do a binary search over $T$'s to find the smallest feasible $T$.
\begin{Theorem}{}{}
	By binary search $O(\log n)$ round we can find the smallest $T$ such that $LP(T)$ is feasible.
\end{Theorem}
